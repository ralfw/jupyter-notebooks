{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungsmodelle entwerfen\n",
    "\n",
    "![](../images/serenity/serenity8.jpg)\n",
    "\n",
    "Flow-Design verfolgt einen verhaltensorientierten Ansatz. Lösungen werden von der SOLL-Funktionalität her angegangen. Für Flow-Design lautet die Frage zuerst: Was soll Software tun?\n",
    "\n",
    "Nicht Datenstrukturen stehen also im Vordergrund, sondern Verhaltensstrukturen. Verhalten konsumiert und produziert Daten. Um zu wissen, wie Daten strukturiert sein sollen, ist also zuerst die Verhaltensproduktion zu klären.\n",
    "\n",
    "Was wie womit getan werden soll, entsteht dabei zunächst in den Köpfen der Entwickler und auf Papier. Die Codierung ist zurückgestellt, bis für ein klar umrissenes Problem die Lösung als Modell vorliegt.\n",
    "\n",
    "Ein Modell versteht Flow-Design dabei ganz allgemein so:\n",
    "\n",
    "> Modell = (Funktion, Beziehung, Funktion)\\*\n",
    "\n",
    "Ein Modell ist eine Menge von Tupeln, in denen je zwei Funktion in Beziehung zueinander gesetzt werden.\n",
    "\n",
    "Wie auch immer Modelle dargestellt werden, aus ihnen müssen programmiersprachliche Funktionen abgeleitet werden können. In Modellen findet sich keine Logik; sie sind deklarativ. Aber ihre Bausteine stehen für Funktionen, die später in der Codierung mit Logik gefüllt werden.\n",
    "\n",
    "Beziehungen zwischen Funktionen können unter anderem sein:\n",
    "\n",
    "* Abhängigkeit: Eine Funktion ruft eine andere auf.\n",
    "* Sequenz: Eine Funktion steht in einem Fluss vor oder nach einer anderen.\n",
    "* Parallelität: Eine Funktion kann/muss parallel zu einer anderen ausgeführt werden.\n",
    "* Aggregation: Zwei Funktionen sind in einem Modul zusammengefasst.\n",
    "* Gemeinsame Daten: Zwei Funktionen nutzen dieselben Daten.\n",
    "* Konkretisierung: Zwei Funktionen stehen in einer Vererbungsbeziehung.\n",
    "\n",
    "Die Deklarativität von Modellen im Flow-Design macht aus, dass ihre Bausteine für angenommene Problemlösungen stehen. Entweder wird dann das Problem an anderer Stelle im Modell durch eine Verfeinerung gelöst. Oder eine im Modell offen gebliebene Annahme wird spätestens in der Codierung mittels Logik erfüllt.\n",
    "\n",
    "![](images/df1.png)\n",
    "\n",
    "Bei all dieser Allgemeinheit in der Definition von Modellen hat Flow-Design allerdings einen klaren Favoriten als Modellierungsansatz. Flow-Design steht für die Überzeugung, dass Softwarelösungen zunächst und ganz fundamental Produktionsprozesse sind, die auf Daten arbeiten und also als Datenflüsse modelliert werden können. Der Entwurf im Flow-Design beginnt daher gemeinhin mit einer Datenflussmodellierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Datenflüssen modellieren\n",
    "\n",
    "Die Datenflussmodellierung beginnt gewöhnlich mit einer in der Analyse ermittelten Interaktion repräsentiert durch ein Nachrichtenpaar und ggf. Seiteneffekte. Ausgangspunkt ist eine Funktionseinheit, die Verhalten zeigen soll in Form einer klar definierten Datentransformation. Sie stellt die Wurzel des Lösungsansatzes dar. Sie repräsentiert die angenommen erfüllten Anforderungen.\n",
    "\n",
    "![](images/df2.png)\n",
    "\n",
    "Wie aufwändig die Lösung eines so gestellten Verhaltensproblems sein mag, ist seiner formalen Darstellung nicht anzusehen. Das ist aber auch nicht nötig, wie sich zeigen wird. Wichtiger ist die einfachheit der Darstellung und ihre Klarheit im Sinne einer Codierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-dimensionale Datenflüsse\n",
    "\n",
    "Eine Funktionseinheit, die Input in Output überführt, ist das kleinstmögliche Datenfluss-Modell. Sie entspricht einem Punkt im dreidimensionalen Raum, ist also 0-dimensional.\n",
    "\n",
    "![](images/df3.png)\n",
    "\n",
    "#### Notation\n",
    "\n",
    "So leichtgewichtig die Notation für solch eine Repräsentanz einer Problemlösung sein mag, so sind doch ein paar Hinweise angebracht:\n",
    "\n",
    "* Eine Funktionseinheit dargestellt als \"Blase\" oder Kreis oder Ellipse, also als \"runde Form\" steht für etwas, das getan werden soll; sie löst ein Problem durch ihre Transformation von Input zu Output. Deshalb ist ihre Benennung mit einem Verb oder einer Verbphrase sinnvoll. Ein Imperativ muss es nicht sein, aber darf es natürlich. Zudem sollte die Benennung relevant für das Umfeld sein, also orientiert an der Domänensprache statt technisch. Außerdem - und vielleicht sogar am wichtigsten - sollte die Bennung keinen Hinweis auf die Lösung(simplementation) enthalten. Die wird im Modell nur gewünscht, nicht gewusst. **Es geht im Modell ums Was und Warum, nicht ums Wie.**\n",
    "* Datenflüsse werden durch Pfeile zur und von der Funktionseinheit angezeigt. Pfeile werden im Flow-Design ausschließlich für diesen Zweck benutzt! Pfeile stellen also keine Abhängigkeiten dar, sondern unidirektionale Datenkanäle, deren Quellen und Senken einander nicht kennen.\n",
    "* Was fließt, wird immer (!) an Pfeilen in Klammern kurz beschrieben. Auch hier geht es vor allem ums Was, nicht ums Wie. Daten werden mit Substantiven benannt. Meist geschieht das in Kleinschreibung und ohne Datentyp, weil der offensichtlich ist. Aber es kann auch ein Datentyp explizit hinzugefügt werden. Oder Daten werden in Großschreibung benannt und stehen damit selbst für einen Datentyp.\n",
    "\n",
    "![](images/df4.png)\n",
    "\n",
    "##### Zustandsbehaftete Funktionseinheiten\n",
    "\n",
    "Funktionseinheiten arbeiten vor allem auf dem Input, der in sie einfließt. Eintreffender Input triggert ihr Verhalten. Aber Funktionseinheiten sind nicht per se *pur*. Flow-Design hat kein Ideal von \"pure functional units\" wie die Funktionale Programmierung \"pure functions\" favorisiert. Flow-Design empfiehlt Zustandslosigkeit bzw. Seiteneffektfreiheit, wo sie sinnvoll und machbar sind. Doch wenn sich das (zunächst) als unintuitiv erweisen sollte, sind Zustand und Seiteneffekte völlig akzeptable - sollten jedoch angezeigt werden.\n",
    "\n",
    "![](images/df5.png)\n",
    "\n",
    "Wie Zustand genau realisiert wird, ist wieder nicht Sache des Modells. Es soll vor allem klar gemacht werden, dass es eine Einflussgröße für die Transformation gibt, die über Nachrichten hinweg relevant ist.\n",
    "\n",
    "Wenn Zustand an gewisser Stelle vermieden werden soll, kann er auch in den Fluss extrahiert werden:\n",
    "\n",
    "![](images/df6.png)\n",
    "\n",
    "Dasselbe gilt für Seiteneffekte. Die werden über einen API hergestellt, der auch in spezifischeren Funktionseinheiten up-/downstream enger gekapselt werden könnte:\n",
    "\n",
    "![](images/df7.png)\n",
    "\n",
    "##### Datenströme\n",
    "\n",
    "Die meisten Funktionseinheiten transformieren eine Input-Nachricht in eine Output-Nachricht. Dabei ist es unerheblich, ob Input oder Output aus einem Datum bestehen oder ein Feld sind, eine Liste oder eine andere Sammlung von vielen Daten.\n",
    "\n",
    "![](images/df8.png)\n",
    "\n",
    "Wenn Sammlungen (*collections*) fließen, kann deren Typ explizit angeben werden - z.B. `(dateiname[])`, `(dateinamen:List<string>)`. Im Allgemeinen ist das jedoch schon zu viel Implementationsdetail für ein Modell. Deshalb ziegt Flow-Design ein schlichtere Angabe für \"mehrere Daten\" vor, die \"in einem Schwung\" ein-/ausfließen: `(dateiname*)`. Der Datenangabe ist einfach nur unmittelbar und in der Klammer ein Sternchen nachzustellen.\n",
    "\n",
    "![](images/df9.png)\n",
    "\n",
    "Eine oft zu vernachlässigende, am Ende jedoch sehr interessante Eigenschaft von Datenflüssen im Gegensatz zu Kontrollflüssen ist jedoch, dass alle Funktionseinheiten im Grunde *gleichzeitig* aktiv sind. Nur weil Daten produziert sind und ausfließen, heißt das nicht, dass eine Funktionseinheit die Kontrolle abgibt. Sie kann auch weiterarbeiten, während der Output zu einer anderen Funktionseinheit fließt und gleichzeitig dort verarbeitet wird. Produzenten und Konsumenten sind grundsätzlich nebenläufig und asynchron - und nur, wenn das nicht wichtig ist, werden sie sequenziell und synchron implementiert.\n",
    "\n",
    "Die grundsätzliche Nebenläufigkeit hat nun zur Folge, dass eine Funktionseinheit nicht nur einmal für einen Input einen Output produzieren kann, sondern mehrfach. Dann entsteht keine *collection* von Nachrichten, sondern ein *stream*. Jedes Element in solch einem  Strom ist eine eigene Nachricht. Angezeigt wird das im Modell durch ein Sternchen *hinter* der Klammer, z.B. `(dateiname)*`.\n",
    "\n",
    "Ströme sind nur relevant zu markieren als Output. Die Anlieferung von Input erfolgt im Grunde immer als Strom. Notiert wird das nur nicht speziell; es ist normal. Auf jede Nachricht im Input-Strom reagiert eine Funktionseinheit dann.\n",
    "\n",
    "![](images/df10.png)\n",
    "\n",
    "#### Übersetzung\n",
    "\n",
    "\"Bubbles don't crash\" - das ist wahr und deshalb ist es Flow-Design wichtig, dass die \"Bubbles\" seiner Modelle möglichst einfach in Code übersetzt werden können, der crashen kann, um Modell-Ideen zu überprüfen.\n",
    "\n",
    "Die naheliegende Übersetzung einer Funktionseinheit ist die in eine Funktion:\n",
    "\n",
    "![](images/df11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int CalcAverage(IEnumerable<int> werte) {\n",
    "    return werte.Sum() / werte.Count();\n",
    "}\n",
    "\n",
    "display($\"Durchschnitt von [1,5,9,3]: {CalcAverage(new[]{1,5,9,3})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert gut, solange für jeden Input-Wert ein Output-Wert bzw. eine Output-Collection erzeugt wird. Und auch mit Tupeln funktioniert es, wenn die Programmiersprache Tupel direkt unterstützt oder man gewillt ist, für ein Tupel einen Datentypen zu definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T head, IEnumerable<T> tail) Split<T>(IEnumerable<T> list)\n",
    "    => (list.First(), list.Skip(1));\n",
    "\n",
    "var result = Split(new[]{2,7,9,3});\n",
    "display($\"head: {result.head}\");\n",
    "foreach(var e in result.tail) display($\"  tail element: {e}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktionen sind natürliche \"Objekte\" im Sinne von Alan Kay, weil sie für eine empfangene Nachricht - *dass* man sie aufruft und mit welchen Parametern man sie aufruft - ein Resulat herstellen, ohne zu wissen, woher sie aufgerufen wurden und wie das Resultat benutzt wird. Das PoMO wird eingehalten.\n",
    "\n",
    "##### Datenströme\n",
    "\n",
    "Allerdings können Funktionen für jedes eintreffende Nachricht, d.h. für jeden Aufruf, nur einmal ein Resultat herstellen (auch wenn das womöglich aus mehreren Elementen besteht). Was aber, wenn Input in einen Strom von Resultaten umzuwandeln ist?\n",
    "\n",
    "Hier bricht die Übersetzung der \"Blase\" in eine Funktion. Bei genauerem Hinsehen ist es stattdessen so, dass die Punkte, wo Pfeile auf eine Funktionseinheit treffen und wo sie sie verlassen, getrennt übersetzt werden:\n",
    "\n",
    "* Ein eintreffender Pfeil wird in eine Funktion mit Parametern übersetzt.\n",
    "* Ein ausgehender Pfeil wird in ein Funktionsresultat oder eine *continuation* übersetzt.\n",
    "\n",
    "Ein Funktionsresultat ist dann möglich, wenn nur einmal ein Output generiert wird. Andernfalls muss Output über einen Funktionszeiger an die Umwelt weitergeschoben werden. Dieser Funktionszeiger muss eine *Prozedur* beschreiben (Funktion ohne Rückgabewert), deren Name nicht auf weitere downstream Verarbeitung des Output hindeutet, da sonst das PoMO verletzt würde.\n",
    "\n",
    "![](images/df12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "quick"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "brown"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fox"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IEnumerable<string> SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "var words = SplitIntoWords(\"the quick brown fox\");\n",
    "foreach(var w in words) display(w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dumpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "on"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wall"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void EnumerateWords(string text, Action<string> onWord)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries).ToList()\n",
    "           .ForEach(onWord);\n",
    "\n",
    "EnumerateWords(\"humpty dumpty sat on a wall\",\n",
    "    word => display(word));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Codierung eines Output-Datenkanals mit einer continuation ist die universellere. Aber sie ist weniger intuitiv und umständlicher. Deshalb zieht Flow-Design die Übersetzung mit Funktionsresultaten vor, wo sie offensichtlich ist oder auch machbar durch Sprachkonstrukte wie Iteratoren (z.B. `IEnumerable<>` in C#).\n",
    "\n",
    "Streams sind Mengen von einzelnen Werten. Wo sie naheliegend und nützlich im Modell sind, sollten sie angemessen in der Übersetzung repräsentiert werden. Das ist mit continuations, also Funktionszeigern in vielen Programmiersprachen möglich, wenn auch ein wenig gewöhnungsbedürftig. Aber die Gewöhnung lohnt sich: die Übersetzung von Modellen wird einfacher, die Testbarkeit des Codes steigt.\n",
    "\n",
    "##### Zustand\n",
    "\n",
    "Zustand bzw. Ressourcenzugriff sind Abhängigkeiten einer Funktionseinheit. Sie werden als Abhängigkeiten übersetzt. Zustand ist dabei eine globale Variable im aggregierenden Modul einer Funktion:\n",
    "\n",
    "![](images/df13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add 1: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 2: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 3: 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Accumulator {\n",
    "    private int _value;\n",
    "    \n",
    "    public int Add(int a) {\n",
    "        _value += a;\n",
    "        return _value;\n",
    "    }\n",
    "}\n",
    "\n",
    "var accu = new Accumulator();\n",
    "display($\"add 1: {accu.Add(1)}\");\n",
    "display($\"add 2: {accu.Add(2)}\");\n",
    "display($\"add 3: {accu.Add(3)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-dimensionale Datenflüsse\n",
    "\n",
    "Einzelne Funktionsheiten werden in Modellen zu Datenflüssen mehrere Funktionseinheiten zusammengesetzt. Flow-Design nennt das auch \"zusammenstecken\" oder \"verdrahten\" in Anlehnung an elektronische Schaltungen, die übrigens ganz natürlich dem PoMO folgen. Aus 0-dimensionalen Modellen werden so 1-dimensionale: viele punktuelle Funktionseinheiten zusammen ergeben einen linearen Fluss.\n",
    "\n",
    "![](images/df14.png)\n",
    "\n",
    "Wenn der Output einer Funktionseinheit in der Form dem Input einer anderen entspricht, können beide in eine producer-consumer Beziehung gebracht werden. Sie spannen dann einen Transformationsfluss auf.\n",
    "\n",
    "Die Übersetzung eines 1-dimensionalen Flusses ist trivial: die Funktionen der einzelnen Funktionseinheiten..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Funktionseinheiten\n",
    "int[] Map(string roman)\n",
    "    => roman.ToCharArray()\n",
    "            .Select(romanDigit => romanDigit switch {\n",
    "                        'I' => 1, 'V' => 5, 'X' => 10,\n",
    "                        'L' => 50, 'C' => 100, 'D' => 500,\n",
    "                        'M' => 1000\n",
    "                    })\n",
    "            .ToArray();\n",
    "\n",
    "int[] Negate(int[] values) {\n",
    "    var negatedValues = (int[])values.Clone();\n",
    "    for(var i=0; i<negatedValues.Length-1; i++)\n",
    "    if (negatedValues[i]<negatedValues[i+1])\n",
    "        negatedValues[i] *= -1;\n",
    "    return negatedValues;\n",
    "}\n",
    "\n",
    "int Sum(IEnumerable<int> values) {\n",
    "    var sum = 0;\n",
    "    foreach(var v in values) sum += v;\n",
    "    return sum;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ...werden schlicht nacheinander aufgerufen. Der Compiler gibt Feedback, ob die Bausteine eines Datenflusses zueinander passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XIV=14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Datenfluss\n",
    "var values = Map(\"XIV\");\n",
    "values = Negate(values);\n",
    "var decimalNumber = Sum(values);\n",
    "\n",
    "display($\"XIV={decimalNumber}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übersetzung verliert das Modell des Datenflusses zwar seine Eigenschaft der grundsätzlichen Asynchronizität seiner Transformationsschritte, doch das ist in den meisten Fällen unerheblich. Datenflüsse sind auch Datenflüsse, wenn sie synchron operieren. Das Modell hat trotzdem einen hohen Wert durch seine Abstraktion.\n",
    "\n",
    "Die Funktionseinheiten, die im 1-dimensionalen Datenfluss verdrahtet werden, sind (zunächst) Operationen. Der Datenfluss stellt ihre Integration dar: alle einzelnen Transformationen bilden in spezifischer Weise zusammengesteckt eine größere Transformation.\n",
    "\n",
    "#### Datenströme\n",
    "\n",
    "Solche Übersetzung von 1-dimensionalen Flüssen als Lösungen von größeren Problemen in Form einer Abfolge von Lösungen kleinerer Probleme funktionieren auch für Ströme von Einzeldaten statt Collections.\n",
    "\n",
    "Datenströme sind nützlich, wenn...\n",
    "\n",
    "* ...die Zahl der zu erzeugenden Output-Datenelemente unbekannt und wahrscheinlich groß ist. In dem Fall soll vielleicht vermieden werden, alle Datenelemente in einer Collection im Hauptspeicher zu sammeln.\n",
    "* ...die Generierung aller Output-Datenelemente erhebliche Zeit in Anspruch nimmt. In dem Fall sollen schon generierte Output-Daten schon downstream in Verarbeitung gehen, während weitere beschafft werden.\n",
    "* ...ein Datenfluss besser zu verstehen und/oder zu übersetzen ist als Strom von Einzeldaten.\n",
    "\n",
    "Als Beispiel dafür mag die Traversierung eines Verzeichnisbaumes dienen, in dem Dateien eines bestimmten Typs gesucht werden, um sie zu analysieren. Zu ermitteln ist die Gesamtanzahl der Worte in relevanten Dateien.\n",
    "\n",
    "![](images/df15.png)\n",
    "\n",
    "Die Zahl der zu prüfenden Dateien ist in so einem Szenario womöglich schwer abzuschätzen und/oder die Lösung ist leichter \"zu denken\", wenn die Analyse sich auf einzelne Dateien konzentriert.\n",
    "\n",
    "Zuerst die Übersetzung der Funktionseinheiten, der Bausteine des Flusses. Jede ist nur eine kleine Operation mit wenigen Zeilen Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "void EnumerateFiles(string path, Action<string> onFilename) {\n",
    "    // Die Logik hier ist aufwändiger als nötig aus didaktischen Gründen, um einen Output-Strom zu erzeugen.\n",
    "    var filenames = System.IO.Directory.GetFiles(path);\n",
    "    foreach(var f in filenames) {\n",
    "        onFilename(f);\n",
    "    }\n",
    "    \n",
    "    var subdirectories = System.IO.Directory.GetDirectories(path);\n",
    "    foreach(var d in subdirectories)\n",
    "        EnumerateFiles(d,\n",
    "              onFilename);\n",
    "}\n",
    "\n",
    "void FilterByEndOfFilename(string filename, string pattern, Action<string> onFilename) {\n",
    "    if (filename.EndsWith(pattern))\n",
    "        onFilename(filename);\n",
    "}\n",
    "\n",
    "string Load(string filename) \n",
    "    => System.IO.File.ReadAllText(filename);\n",
    "\n",
    "string[] SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "void Print(string filename, int numberOfWords) {\n",
    "    display($\"{filename} with {numberOfWords} words\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und dann die Übersetzung des Flusses. Die mag ein wenig gewöhnungsbedürftig sein in der Schachtelung der Lambda-Funktionen als continuations. Doch das verliert sich, wenn man es ein paar Mal geschrieben und gelesen hat. Der Gewinn der Gewöhnung liegt dann darin, eine geradlinige Übersetzung für Datenflüsse mit Strömen zu haben, die in jedem Schritt gut testbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-lücke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 3485 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 3388 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-lücke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EnumerateFiles(\"..\",\n",
    "    filename => FilterByEndOfFilename(filename, \".ipynb\",\n",
    "          filename => {\n",
    "              var text = Load(filename);\n",
    "              var words = SplitIntoWords(text);\n",
    "              Print(filename, words.Length);\n",
    "          })\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EnumerateFiles` erzeugt für eine Input-Nachricht einen Strom von Output-Nachrichten. `FilterByEndOfFilename` hingegen hat die Aufgabe, Input zu verschlucken, falls er nicht dem Filterkriterium entspricht. Das klingt sehr unterschiedlich, ist letztlich jedoch dasselbe: Der Strom dient in beiden Fällen zur Ausgabe einer unbekannten Zahl von Elementen, das können 1 oder 1000 sein - oder auch gar keines.\n",
    "\n",
    "Eine Funktion, die ein Resultat mittels `return` liefert, ist gezwungen, eines zu produzieren, selbst wenn das `null` sein sollte. Eine Funktion, die ihr Resultat stattdessen über eine continuation \"hinausschiebt\", kann auch entscheiden, gar kein Resultat zu liefern! Deshalb ist die Übersetzung von Datenfluss-Funktionseinheiten in Funktionen mit continuation die universellere, wenn auch etwas aufwändigere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dimensionale Datenflüsse\n",
    "\n",
    "Funktionen sind in 0-dimensionalen und 1-dimensionalen Datenflüssen die Container für Logik. Sie komponieren aus \"Logikbausteinen\" ein Verhalten, für das sie stehen.\n",
    "\n",
    "Obwohl 1-dimensionale Datenflüsse leicht zu verstehen sind auch in der Übersetzung in Funktionsaufrufsequenzen, skalieren sie nicht. Mehr als 5 oder vielleicht 10 Funktionseinheiten \"in einer Reihe\" oder Funktionsaufrufe nacheinander, sind aus mehreren Gründen nicht praktikabel:\n",
    "\n",
    "* Im Modell wie im Code sind so lange Sequenzen trotz ihrer formalen Einfachheit nicht mehr gut zu überblicken.\n",
    "* Die Gefahr, dass Datenflüsse das SLA verletzen, steigt mit jeder weiteren Funktionseinheit.\n",
    "* Die Wahrscheinlichkeit, dass es in Datenflüssen Gruppen von Funktionseinheiten mit höherer Kohäsion untereinander gibt als zu anderen, steigt mit jeder weiteren Funktionseinheit.\n",
    "\n",
    "Schon zum oben stehenden Datenfluss zur Analyse von Dateien kann gefragt werden, ob er für das Verständnis eine optimale Länge hat.\n",
    "\n",
    "#### Integrationen als Bedeutungseinheiten\n",
    "\n",
    "Einerseits hat ein Leser bei dem 1-dimensionalen Datenfluss \"alles auf einmal im Blick\". Alle Operationen stehen in einer Reihe. Andererseits muss ein Leser sich die Bedeutung des Ganzen aus den Bedeutungen der Teile erst zusammenreimen. Das ist bei 5 Funktionseinheiten schwieriger als bei 4, 3 oder 1.\n",
    "\n",
    "Was tut der Datenfluss? Kann das mit 1 Funktionseinheit ausgedrückt werden? Selbstverständlich!\n",
    "\n",
    "![](images/df16.png)\n",
    "\n",
    "Die eine Funktionseinheit integriert nun explizit die bisherigen Operationen.\n",
    "\n",
    "Oder gibt es im Datenfluss noch Teile, die wiederum unter einem Begriff zusammengefasst werden können, um ihnen eine eigene Bedeutung zu geben? Beispiele dafür wären:\n",
    "\n",
    "* Alles außer der Ausgabe könnte als Kernlogik zusammengefasst werden. Die Ausgabe eines Ergebnisses ist etwas ganz anderes, als das Ergebnis herzustellen. Dadurch würde die Ergebnisherstellung separat von der Benutzerschnittstelle testbar.\n",
    "* Die Beschaffung der relevanten Dateinamen könnte zusammengefasst werden. Die Traversierung des Dateisystems ist etwas ganz anderes, als mit einer Datei umzugehen.\n",
    "* Laden und Zerlegen einer Datei könnte zusammengefasst werden. Eine Datei als Text zu beschaffen, statt als Byteblock, ist schon eine Abstraktion, die der .NET Framework zur Verfügung stellt. Warum nicht den Dateizugriff weiter abstrahieren und eine Datei als Collection von Worten repräsentieren?\n",
    "\n",
    "Wie man sich entscheidet bei den Zusammenfassungen, ist weniger wichtig, als dass Zusammenfassungen zur Verbesserung der Verständlichkeit und der Testbarkeit möglich und einfach sind. Die eine beste Zusammenfassung wird es wohl nicht geben. Da Integrationen von Teilflüssen jedoch billig herzustellen und auch wieder aufzulösen sind, kann die Integrationshierarchie jederzeit umgestellt werden.\n",
    "\n",
    "Verständnis verändert sich mit der Zeit: Es wird aufgebaut durch Beschäftigung mit Code - aber es wird auch wieder abgebaut, wenn die Beschäftigung abnimmt. Eine Struktur, die dem heutigen Verständnis angemessen ist, passt womöglich nicht mehr optimal zum morgigen Verständnis.\n",
    "\n",
    "In dieser Hinsicht unterliegen Modelle und Code trotz ihrer Immaterialität einem Verschleiß. Ohne, dass Code \"sich bewegte\" oder verändert würde, verliert er an \"Verständlichkeitsqualität\". Das hat zwei Konsequenzen:\n",
    "\n",
    "* Die Diskussion um die allerbeste Struktur sollte begrenzt werden. Die allerbeste Struktur, selbst wenn sie für heute gefunden werden könnte, ist morgen nicht mehr die allerbeste. Nach dem Herstellungszeitpunkt verliert jede auf Verständlichkeit getrimmte Struktur sofort und automatisch an Wert. Warum also bis aufs Letzte optimieren?\n",
    "* Strukturen für Verständlichkeit sollten gewartet werden. D.h. sie sollten proaktiv in angemessenen Wartungsinverallen aufgesucht und dem aktuellen Verständnisstand angepasst werden. Sonst besteht die Gefahr, dass sie zur Unzeit als stark erodiert erfahren werden und viel Mühe beim Verständnis machen.\n",
    "\n",
    "Die obigen Fragen zu möglichen Integrationen sind daher nur Beispiele dafür, dass und wie möglichen Verständlichkeitsverbesserungen nachgespürt werden kann. Nach angemessenem Diskurs muss eine Entscheidung getroffen werden. Die könnte z.B. so aussehen:\n",
    "\n",
    "![](images/df17.png)\n",
    "\n",
    "Ein Datenflussmodell dehnt sich damit sichtbar in 2 Dimensionen aus:\n",
    "\n",
    "* In der ersten Dimension wird Verhalten im Datenfluss erzeugt: am Anfang einfließerder Input wird schrittweise in am Ende ausfließenden Output transformiert.\n",
    "* In der zweiten Dimension findet Abstraktion durch Komposition statt. Kompositionen - Operation wie Integration - fassen verschiedene Teilverhalten zu einem größeren, neuen Gesamtverhalten zusammen. Komposition ist die Abstraktion, die Bequemlichkeit in der Nutzung herstellt.\n",
    "\n",
    "Kompositionen ändern am Verhalten natürlich nichts. Das Verhalten wird immer nur durch Logik (und Verteilung) beeinflusst. Aber Kompositionen ändern an der Verständlichkeit etwas. Deshalb ist auch der Einwand, dass in einer Integrationshierarchie Operationen und Integrationen womöglich nur einmal verwendet werden, unerheblich. Wenn eine Komposition der Verständlichkeit oder Testbarkeit dient, dann muss sie nicht gleichzeitig der kurzfristigen Produktivität dienen. Das ist nämlich der Zweck von Wiederverwendung.\n",
    "\n",
    "#### Übersetzung\n",
    "\n",
    "Sind Integrationen für einen Fluss gefunden, lassen sie sich leicht übersetzen: wie Operationen werden sie zu Funktionen. Das ist einerseits sehr nützlich und intuitiv. Andererseits hat es aber auch einen Nachteil.\n",
    "\n",
    "Integrationen in Funktionen zu übersetzen, liegt nahe, weil die Darstellung im Modell sich nicht von Operationen unterscheidet. Auch weil während des Modellierungsprozesses nicht klar ist, ob Blätter in einer Integrationshierarchie Operationen bleiben oder weiter verfeinert werden, d.h. \"in Integrationen umklappen\", wäre eine unterschiedliche Darstellung bzw. Codierung hinderlich.\n",
    "\n",
    "Andererseits verführt die Übersetzung von Integrationen in Funktionen dazu, Logik in sie \"hineinzuschmuggeln\". Das würde dem IOSP widersprechen und mindestens die Testbarkeit senken.\n",
    "\n",
    "Letztlich überwiegt jedoch für Flow-Design die Einfachheit. Integrationen werden also zu Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-lücke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 4778 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 4776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-lücke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void PrintWordsInFiles(string path, string pattern) {\n",
    "    CountWordsInFiles(path, pattern,\n",
    "        Print);\n",
    "}\n",
    "\n",
    "void CountWordsInFiles(string path, string pattern, Action<string,int> onFile) {\n",
    "    EnumerateRelevantFiles(path, pattern,\n",
    "        filename => {\n",
    "            var words = LoadWordsFromFile(filename);\n",
    "            onFile(filename, words.Length);\n",
    "        });\n",
    "}\n",
    "\n",
    "void EnumerateRelevantFiles(string path, string pattern, Action<string> onFilename) {\n",
    "    EnumerateFiles(\"..\",\n",
    "        filename => FilterByEndOfFilename(filename, pattern,\n",
    "                      onFilename));\n",
    "}\n",
    "\n",
    "string[] LoadWordsFromFile(string filename) {\n",
    "    var text = Load(filename);\n",
    "    return SplitIntoWords(text);\n",
    "}\n",
    "\n",
    "\n",
    "PrintWordsInFiles(\"..\", \".ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jo-Jo Modellierung\n",
    "\n",
    "Im Flow-Design beginnt die Modellierung der Lösung eines Problem außen und beim Gesamtverhalten. Von dort setzt sich durch Zerlegung von größeren in kleinere Probleme nach innen fort. Sie ist verhaltensorientiert und schrittweise verfeinernd, d.h. rekursiv absteigend: Am Anfang steht eine Funktionseinheit als vorläufige Operation. Deren Transformation wird dann jedoch zerlegt in Schritte, die durch nächste vorläufige Operationen in einem Fluss vollständig geleistet wird, so dass die vorherige Funktionseinheit zu einer Integration wird. Und immer so weiter für jedes Blatt im 2-dimensionalen Datenflussbaum - bis man am Ende nicht mehr weiß, wie eine vorläufige Operation weiter zerlegt werden soll. Dann wird aus der vorläufigen Operation eine endgültige.\n",
    "\n",
    "Zumindest verläuft die Modellierung des Verhaltens idealerweise so. In der Praxis jedoch zeigt sich, dass nicht immer outside-in, top-down eine Lösung erkannt wird. Manchmal steht schon am Anfang ein spätere Operation fest und die wird schrittweise an die Wurzel-Funktionseinheit bottom-up angebunden. Oder nach einem ersten Durchstich von der Wurzel bis zu den Operationen scheint es verständlichkeitsfördernd, weitere Integrationsebenen einzuziehen. Oder Kind-Knoten im Kompositionsbaum, die unter verschiedenen Eltern-Knoten hängen, werden horizontal verschoben.\n",
    "\n",
    "![](images/df18.png)\n",
    "\n",
    "Flow-Design ist insofern weder strickt top-down, noch bottom-up, sondern geht in beide Richtungen vor oder schwingt auch mal seitwärts. Das passende Bild für ihre Bewegungsrichtung ist mithin ein Jo-Jo: der geht immer wieder runter und hoch oder bricht auch mal aus und kommt am Ende zur Ruhe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logik in der Integration\n",
    "\n",
    "Das IOSP ist glasklar: Eine Funktionseinheit ist entweder Operation und steht für Verhaltenserzeugung durch Logik. Oder sie ist eine Integration und stellt nur einen Fluss zwischen anderen Funktionseinheiten her, wofür keine Logik nötig ist.\n",
    "\n",
    "Damit formuliert das Prinzip ein Soll, ein Ideal. Und dieses Ideal kann technisch auch immer implementiert werden.\n",
    "\n",
    "Allerdings ist es eben ein Ideal. Das bedeutet, in seiner Reinheit kann es anderen Zielen auch mal im Wege stehen.\n",
    "\n",
    "Flow-Design sieht dieses und andere Prinzipien daher pragmatisch. Ja, es soll stets das Ideal im Sinne von Korrektheit und Evolvierbarkeit angestrebt werden. Dabei soll aber auch Augenmaß bewahrt werden. IOSP, PoMO usw. für langfristig hohe Produktivität sind auszubalancieren mit Maßnahmen für funktionale und nicht-funktionale Qualitäten.\n",
    "\n",
    "Für Flow-Design sind deshalb gelegentliche \"Spuren von Logik\" in eigentlich integrierenden Funktionseinheiten akzeptabel. Nicht wünschenswert, aber ok - wenn man denn weiß, was man da tut.\n",
    "\n",
    "Meistens handelt es sich bei diesen Logik-Einsprengseln um Kontrollstrukturen oder triviale selbsterklärende API-Aufrufe.\n",
    "\n",
    "Als Beispiel mag nochmal die obige Dateianalyse dienen. Mit der Erlaubnis zu etwas Logik in der Integration könnte die Übersetzung anders aussehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-lücke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 124 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 5776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 5776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-lücke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 124 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Schmutzige Integration\n",
    "void PrintWordsInFiles_v2(string path, string pattern) {\n",
    "    foreach(var r in CountWordsInFiles_v2(path, pattern)) // Kontrollstruktur😱\n",
    "        Print(r.filename, r.numberOfWords);\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "IEnumerable<(string filename, int numberOfWords)> CountWordsInFiles_v2(string path, string pattern) {\n",
    "    foreach(var f in EnumerateRelevantFiles_v2(path, pattern)) { // Kontrollstruktur😱\n",
    "        var words = LoadWordsFromFile_v2(f);\n",
    "        yield return (f, words.Length);\n",
    "    };\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "IEnumerable<string> EnumerateRelevantFiles_v2(string path, string pattern) {\n",
    "    foreach(var f in EnumerateFiles_v2(path)) // Kontrollstruktur😱\n",
    "        if (IsRelevantFile(f, pattern)) // Kontrollstruktur😱\n",
    "            yield return f;\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "string[] LoadWordsFromFile_v2(string filename) {\n",
    "    var text = System.IO.File.ReadAllText(filename); // API-Aufruf😱\n",
    "    return SplitIntoWords(text);\n",
    "}\n",
    "\n",
    "\n",
    "// Geänderte Operation für den Aufruf in einer schmutzigen Integration\n",
    "IEnumerable<string> EnumerateFiles_v2(string path) {\n",
    "    // Die Logik hier ist aufwändiger als nötig aus didaktischen Gründen, um einen Output-Strom zu erzeugen.\n",
    "    var filenames = System.IO.Directory.GetFiles(path);\n",
    "    foreach(var f in filenames) {\n",
    "        yield return f; // Statt über eine Continuation wird ein Strom jetzt mittel Iterator erzeugt🤔\n",
    "    }\n",
    "    \n",
    "    var subdirectories = System.IO.Directory.GetDirectories(path);\n",
    "    foreach(var d in subdirectories)\n",
    "        foreach(var f in EnumerateFiles_v2(d))\n",
    "            yield return f; //🤔\n",
    "}\n",
    "\n",
    "// Geänderte Operation für den Aufruf in einer schmutzigen Integration\n",
    "bool IsRelevantFile(string filename, string pattern)\n",
    "    => filename.EndsWith(pattern);\n",
    "\n",
    "\n",
    "PrintWordsInFiles_v2(\"..\", \".ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In jeder einzelnen Methode hält sich die Unsauberkeit in Bezug auf das IOSP in Grenzen. Die Methoden bleiben auch klein. Solange beides gegeben ist, steht aus Sicht von Flow-Design ein wenig \"Schmutz\" nichts entgegen. Wichtiger als die absolute Befolgung des Prinzips sind die Qualitäten, die es befördert, hier: **Verständlichkeit und Testbarkeit. Solange diese Qualitäten auch trotz (oder wegen?) gewisser Unsauberkeit vorhanden sind, ist etwas Logik in einer Integrationsfunktion ok.**\n",
    "\n",
    "[Solche \"Schmutzreste\"](https://ccd-school.de/2017/02/kontrollstrukturen-in-der-integration/) sind vor allem simple Schleifen, auch mal eine Fallunterscheidung oder ein trivialer API-Aufruf. **Wichtig ist, dass diese Logik so einfach ist, dass sie selbst nicht getestet werden muss.** Das ist z.B. hier der Fall:\n",
    "\n",
    "```csharp\n",
    "if (IsRelevantFile(f, pattern))\n",
    "    yield return f;\n",
    "```\n",
    "\n",
    "Die `if`-Anweisung selbst kann nicht falsch geschrieben werden; der Compiler würde das beanstanden. Die eigentliche Logik steckt in der Funktion `IsRelevantFile`, zu der nun eine funktionale Abhängigkeit besteht. Diese Logik ist durch die Auslagerung jedoch leicht testbar.\n",
    "\n",
    "Wenn ein `if` in solcher Weise zur Lesbarkeit einer Integration beiträgt... Warum dann darauf verzichten? Flow-Design will mit seinen Prinzipien leiten, aber nicht darauf reiten.\n",
    "\n",
    "Ähnlich sieht es für `foreach` aus, mit dem der Code auf Continuations verzichten kann, weil C# mit `yield return` es erlaubt, sehr einfach Iteratoren nach und nach mit Elementen zu füllen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offen für Erweiterung, geschlossen für Veränderung\n",
    "\n",
    "Die Vorteile der Einhaltung von IOSP und PoMO liegen zunächst sichtbar in größerer Verständlichkeit und besserer Testbarkeit von Code. Logik wird ganz natürlich in kleine Einheiten \"gezwungen\". Flow-Design verzichtet ganz bewusst auf die Möglichkeit funktionaler Abhängigkeiten, um Produktivitätsqualitäten verlässlicher herzustellen. [Functional dependencies considered harmful!](https://ralfw.de/2019/07/functional-dependencies-considered-harmful/) Freiwillige Selbstbeschränkung beim Schreiben von Code fördert das spätere und häufigere Lesen und Verändern von Code.\n",
    "\n",
    "Der positive Effekt des IOSP entstammt zunächst einer Zuspitzung des SRP: Integration und Operation sind formale Verantwortlichkeiten. Während üblicherweise das SRP inhaltlich bzw. auf das Verhalten angewandt wird, konzentriert sich das IOSP auf die Struktur von Code. Deshalb kann die Einhaltung des IOSP auch leicht überprüft werden, selbst wenn ein Leser mit einer Programmiersprache oder dem angestrebten Verhalten oder der Domäne nur wenig vertraut ist.\n",
    "\n",
    "Weiterhin befördert das IOSP die Einhaltung des SLA. Wenn Funktionen keine funktionalene Abhängigkeiten enthalten, dann liegt das, was sie zusammenfassen (Komposition) im Abstraktionsgrad näher beieinander.\n",
    "\n",
    "Und schließlich kann man das PoMO als eine Steigerung des *Interface Segregation Principle (ISP)* auffassen. Denn wenn downstream Konsumenten upstream Produzenten über einen Funktionszeiger (continuation) bekannt gemacht werden, dann entspricht das einer Abhängigkeit von einem Interface mit nur einer Methode. Es findet eine Funktionsinjektion in eine Funktion im Bedarfsfall statt.\n",
    "\n",
    "Damit aber nicht genug! IOSP und PoMO sind auch ganz im Sinne des *(Polymorphic) Open/Closed Principle (OCP)*! [Robert C. Martin definiert das](https://drive.google.com/file/d/0BwhCYaYDn8EgN2M5MTkwM2EtNWFkZC00ZTI3LWFjZTUtNTFhZGZiYmUzODc1/view) wie folgt:\n",
    "\n",
    "> Modules that conform to the open-closed principle have two primary attributes.\n",
    "> 1. They are “Open For Extension”. This means that the behavior of the module can be extended. That we can make the module behave in new and different ways as the requirements of the application change, or to meet the needs of new applications.\n",
    "> 2. They are “Closed for Modification”. The source code of such a module is inviolate. No one is allowed to make source code changes to it.\n",
    "\n",
    "Flow-Design übersetzt \"module\" dabei allerdings in \"Funktionseinheit\" bzw. \"Funktion\" als eigentlich Verhalten erzeugende Strukturbestandteile. Und Flow-Design konkretisiert, was denn nicht verändert werden sollte: Logik. Logik ist schwer zu verstehen und schwer zu testen. Daher sollte man die Finger davon lassen, sobald sie einmal tut, was sie soll. Veränderungen für neues Verhalten sollten nicht durch Veränderung (modification) von Logik hergestellt werden - sondern durch neue, separate Logik (extension).\n",
    "\n",
    "Dem leistet Flow-Design Vorschub durch den Verzicht auf funktionale Abhängigkeiten. Operationen sieht Flow-Design als geschlossen an; ihre Logik sollte soweit möglich nicht angetastet werden. Integrationen hingegen sind für Flow-Design offen. In Integrationen können Erweiterungen des Verhaltens leicht \"zwischengeschaltet\" werden.\n",
    "\n",
    "Zunächst ein Szenario ohne IOSP: die Umwandlung römischer Zahlen in dezimale noch ohne Berücksichtigung der Subtraktionsregel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman(string romanNumber) {\n",
    "    var decimalNumber = 0;\n",
    "    for(var i=0; i<romanNumber.Length; i++) {\n",
    "        switch(romanNumber[i]) {\n",
    "            case 'I': decimalNumber += 1; break;\n",
    "            case 'V': decimalNumber += 5; break;\n",
    "            case 'X': decimalNumber += 10; break;\n",
    "            // ...\n",
    "        }\n",
    "    }\n",
    "    return decimalNumber;\n",
    "}\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman(\"XVI\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was tun, um auch die Anforderungen der Subtraktionsregel zu erfüllen? Die Logik von `FromRoman` muss *verändert* werden! Das ist riskant/schwierig.\n",
    "\n",
    "Anders liegt der Fall, wenn eine Lösung - auch wenn sie klein ist - sauber modelliert und mit IOSP im Kopf übersetzt wird. Sie sähe dann z.B. so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XIV=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman_OCP(string romanNumber) {\n",
    "    var digitValues = Map(romanNumber);\n",
    "    return digitValues.Sum();\n",
    "}\n",
    "\n",
    "int[] Map(string romanNumber)\n",
    "    => romanNumber.ToCharArray().Select(Map).ToArray();\n",
    "int Map(char romanDigit) => romanDigit switch {\n",
    "    'I' => 1,\n",
    "    'V' => 5,\n",
    "    'X' => 10\n",
    "    // ...\n",
    "};\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman_OCP(\"XVI\")}\");\n",
    "display($\"XIV={FromRoman_OCP(\"XIV\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch leistet die Lösung nicht, was sie soll. Doch ohne Veränderung einer Operation - `Map`, `Sum` - kann das geändert werden mit einer Erweiterung der Integration. Deren Extension besteht im \"Dazwischenschieben\" eines weiteren Funktionsaufrufs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XIV=14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman_OCP_extended(string romanNumber) {\n",
    "    var digitValues = Map(romanNumber);\n",
    "    digitValues = Negate(digitValues); // Erweiterung🤩\n",
    "    return digitValues.Sum();\n",
    "}\n",
    "\n",
    "// Neue Logik, statt veränderter🥳\n",
    "int[] Negate(IEnumerable<int> digitValues) {\n",
    "    var negated = digitValues.ToArray();\n",
    "    for(var i=0; i<negated.Length-1; i++)\n",
    "        if (negated[i]<negated[i+1])\n",
    "            negated[i] *= -1;\n",
    "    return negated;\n",
    "}\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman_OCP_extended(\"XVI\")}\");\n",
    "display($\"XIV={FromRoman_OCP_extended(\"XIV\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Trennung von Integration und Operation reduziert Flow-Design den Aufwand, um dem OCP zu dienen. Erweiterbarkeit ist ein grundlegendes Merkmal von Integrationen. Dass man dafür Code im Fluss der Verhaltensherstellung anfassen muss, ist unerheblich. Das Risiko für Schaden (Regression) dadurch ist vergleichsweise klein. Wahrhaft risikoreiche Veränderungen an Logik sind auf sehr überschaubare Operationen begrenzt.\n",
    "\n",
    "Die erste Frage beim Modellieren eines Lösungsansatzes für neues Verhalten lautet im Flow-Design: Kann das neue Verhalten hergestellt werden, in den lediglich Funktionseinheiten in einem Datenfluss zwischen andere gesetzt werden? Öfter als man denkt, kann darauf mit Ja geantwortet werden. (Und wenn nicht, kann das als Anlass genommen werden, den bisherigen Lösungsansatz nocheinmal zu überdenken, um ihn mittels IOSP näher ans OCP zu bringen.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Design\n",
    "\n",
    "Dem Verständnis eines Systems ist zuträglich, wenn man es aus unterschiedlicher Entfernung betrachten kann. Ist man näher dran, kann man Details untersuchen. Ist man weiter weg, gewinnt man Überblick über den Zusammenhang von Teilen.\n",
    "\n",
    "Geografische Karten erlauben uns, in solcher Weise mit einem Terrain umzugehen. Wir ziehen sie z.B. zur Planung einer Reise in unterschiedlichem Maßstab heran. Eine Karte mit großem Maßstab, z.B. eine Europa-Karte, gibt uns Überblick für eine grobe Routenplanung. Eine topografische Karte hingegen zeigt uns eine eng begrenzte Umgebung mit viel mehr Einzelheiten. Werkzeuge wie Google Maps machen heute den Wechsel des Maßstabs besonders einfach.\n",
    "\n",
    "Für das Studium von Code ist es ebenfalls nützlich, den Maßstab seiner Darstellung wechseln zu können. Das Ganze sollte grob und im Überblick betrachtet werden können; genauso sollte es möglich sein, schrittweise hinein zu zoomen, um mehr und mehr Details zu sehen.\n",
    "\n",
    "Große Maßstäbe stehen für ein hohes Abstraktionsniveau, kleine Maßstäbe für ein niedriges. Um hinein und heraus zoomen zu können, muss Code also unterschiedliche Abstraktionsniveaus aufweisen.\n",
    "\n",
    "Tut er das z.B., wenn er nach dem weit verbreiteten Schichtenmodell strukturiert ist?\n",
    "\n",
    "Als Beispiel ein kleines Programm, dass die Worte in einer Datei zählt. Es besteht aus drei typischen Schichten:\n",
    "\n",
    "* Presentationsschicht/Benutzerschnittstelle: Beschafft den Namen der zu verarbeitenden Datei aus der Umgebung und gibt das Ergebnis aus, das es von der Geschäftslogik bekommt.\n",
    "* Geschäftslogikschicht: Ermittelt das Ergebnis, nachdem es von der Datenzugriffschicht den Dateiinhalt bekommen hat.\n",
    "* Datenzugriffsschicht: Lädt den Inhalt einer Datei.\n",
    "\n",
    "/// schichtenmodell für das beispiel (erstmal nur klassennamen) (100)\n",
    "\n",
    "Funktionale Abhängigkeiten zeigen hier grundsätzlich über die Schichten hinweg von oben nach unten. Ob das kaschiert wird mit DIP/IoC, ist unwesentlich. Und auch Schalen statt Schichten, wie in der Clean Architecture, machen keinen Unterschied. So oder so sind die Aspekte funktional voneinander abhängig zur Laufzeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class Presentation {\n",
    "    public static void CountWords(string filename) {\n",
    "        var numberOfWords = Business.CountWords(filename);\n",
    "        Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business {\n",
    "    public static int CountWords(string filename) {\n",
    "        var words = Dataaccess.Load(filename);\n",
    "        var significantWords = words.Where(w => w.Length > 2);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "class Dataaccess {\n",
    "    public static IEnumerable<string> Load(string filename) {\n",
    "        var text = System.IO.File.ReadAllText(filename);\n",
    "        return text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "Presentation.CountWords(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Code ist das Terrain. Das Schichtenmodell ist eine Karte für dieses Terrain. Sie abstrahiert von den Details der Logik und sogar von den einzelnen Methoden. Das ist durchaus nützlich. Und das ganze Programm mit einem Betriebssystemprozess als Host abstrahiert sogar noch von den Klassen als Feinheiten der Implementation.\n",
    "\n",
    "/// softwarezelle -* schichtenmodell -* code(101)\n",
    "\n",
    "##### Abhängigkeiten definieren das Abstraktionsgefälle\n",
    "\n",
    "Aus diesem Bild wird ersichtlich, wie Abstraktion und Abhängigkeit in Zusammenhang stehen: Abstraktion definiert einen Baum. Dessen Wurzel ist das Abstraktum, seine Blätter sind die Details, von denen damit abgesehen wird.\n",
    "\n",
    "/// abstraktionsbaum mit abhängigkeiten; beispiel vllt mit \"Gebäude\" und dann \"Wohnhaus\", \"Hochhaus\", \"Kirche\" (102)\n",
    "\n",
    "Das Abstrakte *besteht* aus dem Konkreten. Das Abstrakte ist somit vom Detail *abhängig*, das in ihm unter einem Gesichtspunkt zusammengefasst ist. Die Abhängigkeitsbeziehung weist vom Abstrakten zum Konkreten. In Richtung von Abhängigkeiten fällt mithin das Abstraktionsniveau.\n",
    "\n",
    "##### Abstraktionen im Flow-Design\n",
    "\n",
    "Flow-Design ist vor allem mit Abstraktionen nach zwei Gesichtspunkten beschäftigt:\n",
    "\n",
    "* Aggregation: Zusammenfassen von *Ähnlichem*; das, was gemeinsam ist, definiert die Abstraktion.\n",
    "* Komposition: Zusammenfassen von *Verschiedenem*; das Neue, das durch die gegenseitige Ergänzung des Verschiedenen entsteht, macht die Abstraktion aus.\n",
    "\n",
    "/// abstraktionsbäume für aggregation (irgendwas gemeinsames wird rausgezogen) und komposition (irgendwas neues entsteht) (103)\n",
    "\n",
    "Das Mittel zur Aggregation sind Module. Das Mittel zur Komposition sind Integration und Operation.\n",
    "\n",
    "Aggregation erzeugt Überblick durch Ausblenden der Verschiedenartigkeit von Konkretem. Komposition erzeugt Neues durch Verschmelzen der Verschiedenartigkeit von Konkretem.\n",
    "\n",
    "##### Fehlende Abstraktionen bei funktionaler Abhängigkeit\n",
    "\n",
    "Vor diesem Hintergrund wird deutlich, dass Code, der nach dem Schichtenmodell strukturiert ist, Abhängigkeiten falsch im Sinne von Abstraktion einsetzt.\n",
    "\n",
    "`Presentation.CountWords` als Wurzel des Abhängigkeitsbaums kann noch als Repräsentant des Ganzen auf höchster Abstraktionsebene angesehen werden; immerhin geht es um das Zählen von Worten in einer Datei.\n",
    "\n",
    "Aber wie steht es mit `Business.CountWords`? Liegt die Methode auf einem niedrigeren Abstraktionsniveau? Tut sie dasselbe, wie die von ihr abhängige, nur eben konkreter? Ja, vielleicht könnte man das noch zugestehen. Es ja immerhin wieder um das Zählen von Worten in einer Datei; dieses Mal wird deren Zahl als Ergebnis geliefert, statt auf dem Bildschirm ausgegeben.\n",
    "\n",
    "Und schließlich `Dataaccess.Load`: Ist damit die Problemlösung auf einem niedrigeren Abstraktionsniveau beschrieben? Nein. Hier geht es nicht mehr ums Zählen. Das ist deutlich sichtbar. Spätestens bei der Abhängigkeit der Geschäftslogik von der Datenzugriffslogik wird das Prinzip verletzt, dass Abhängigkeiten vom Abstrakten auf das Konkrete verweisen sollen.\n",
    "\n",
    "Abstraktionsniveaus sind dadurch gekennzeichnet, dass auf einem bestimmten Niveau jeweils das Ganze zu sehen ist, nur eben in einem gewissen Detaillierungsgrad. Das ist offensichtlich bei `Dataaccess.Load` nicht der Fall und schon bei `Business.CountWords` wackelt das Bild.\n",
    "\n",
    "Die Abhängigkeiten zwischen Methoden in einem Schichtenmodell beschreiben also keinen Abstraktionsbaum. Doch wie steht es mit dem Klassenbaum? Liegt eine `Presentation`-Klasse auf einem höheren Abstraktionsniveau als eine `Business`- oder `Dataaccess`-Klasse? Tut `Presentation` das in Aggregation, was `Business` oder `Dataccess` tun? Hier antwortet Flow-Design ebenfalls mit Nein.\n",
    "\n",
    "Eine Geschäftslogik ist nicht dasselbe wie Datenzugriffslogik, nur eben auf einem anderen Abstraktionsniveau.\n",
    "\n",
    "##### Dark Logic\n",
    "\n",
    "Der Grund für diese \"Missweisung\" der Abhängigkeiten ist ihre funktionale Natur. Bäume funktionaler Abhängigkeiten enthalten *dark logic*, d.h. Logik, die Verhaltensrelevant ist, aber nicht im Modell repräsentiert. Das wird deutlich bei einer Darstellung des Lösungsansatzes für die Wortzählung als Datenflussdiagramm:\n",
    "\n",
    "/// datenfluss für wortzählung (103)\n",
    "\n",
    "Der Input von `Business.CountWords` passt noch zum Input von `Presentation.CoundWords`, aber der Output passt nicht. Was passiert mit der hinausfließenden Zahl der Worte? Genauso bei `Business.CoundWords` und `Dataaccess.Load`: Wie wird aus einer collection von Strings eine Zahl?\n",
    "\n",
    "Beides ist nur zu erklären mit dark logic: In der abhängigen, integrierenden Funktionseinheit muss noch Logik stecken. Diese Logik widerspricht dem SLA:\n",
    "\n",
    "```csharp\n",
    "public static int CountWords(string filename) {\n",
    "    var words = Dataaccess.Load(filename);\n",
    "    var significantWords = words.Where(w => w.Length > 2);\n",
    "    return significantWords.Count();\n",
    "}\n",
    "```\n",
    "\n",
    "`Dataaccess.Load` liegt auf einem höheren Abstraktionsniveau als die folgenden Zeilen, weil die Methode selbst Logik zu einer neuen Funktionalität komponiert.\n",
    "\n",
    "Laut IOSP kann das jedoch nicht sein.\n",
    "\n",
    "Dark logic ist es, die Code schwer zu verstehen und schwer zu testen macht. Abhängigkeitsdiagrammen von Funktionen, die *funktional* abhängig sind, fehlt wesentliche Information, um zu verstehen, wie Verhalten hergestellt wird. Nicht, dass Logik explizit gezeigt werden müsste; damit würde der Abstraktionszweck gebrochen. Aber Logik muss explizit repräsentiert werden.\n",
    "\n",
    "Das ist, wozu die Einhaltung des IOSP führt. Das IOSP macht dark logic sichtbar.\n",
    "\n",
    "##### Stratified Design\n",
    "\n",
    "Software strukturiert nach IOSP besteht nicht aus Schichten, sondern *Strata*. Jedes Stratum definiert dabei ein Abstraktionsniveau.\n",
    "\n",
    "> \"\\[...\\] expert engineers stratify complex designs. Each level is constructed as a stylized combination of interchangeable parts that are regarded as primitive at that level. The parts constructed at each level are used as primitives at the next level. Each level of a stratified design may be thought of as a specialized language with a variety of primitives and means of combination appropriate to that level of detail.\", Abelson & Sussman in \"Lisp: A Language for Stratified Design\"\n",
    "\n",
    "Das Schichtenmodell (oder auch eine Clean Architecture) sind keine Repräsentaten von *stratified design*. Lösungen existieren dort nicht auf unterschiedlichen Abstraktionsniveaus, weil Schichten/Schalten funktional von einander abhängig sind.\n",
    "\n",
    "Anders jedoch im Flow-Design. Hier ein Datenfluss-Modell für das Wortzählungsproblem:\n",
    "\n",
    "/// datenfluss für das wortzählungsproblem (104)\n",
    "\n",
    "In diesem Modell existiert keine dark logic mehr. Die Lösung wird auf in zwei Strata komplett beschrieben:\n",
    "\n",
    "/// zwei strata für das wortzählungsproblem: nur die wurzel / nur der flow (105)\n",
    "\n",
    "Die gesamte Logik ist in Operationen verpackt.\n",
    "\n",
    "Das höchste Abstraktionsniveau wurde durch das IOSP explizit eingeführt: die Klasse `CountWords` mit der Methode `Run`, die beide für Integration stehen. `CountWords` integriert die Aspekt-Klassen `Presentation`, `Business` und `Dataaccess`. `Run` integriert deren Methoden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class CountWords {\n",
    "    public static void Run(string filename) {\n",
    "        var words = Dataaccess.Load(filename);\n",
    "        var numberOfWords = Business_Stratified.CountWords(words);\n",
    "        Presentation_Stratified.DisplayResult(filename, numberOfWords);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class Presentation_Stratified {\n",
    "    public static void DisplayResult(string filename, int numberOfWords) {\n",
    "        Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business_Stratified {\n",
    "    public static int CountWords(IEnumerable<string> words) {\n",
    "        var significantWords = words.Where(w => w.Length > 2);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "CountWords.Run(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was vorher funktional abhängig war, steht jetzt in einer Sequenz im Datenfluss in `Run`. So ist es richtig, wenn es keine Unterschiede im Abstraktionsniveau gibt.\n",
    "\n",
    "Im Beispiel macht die Geschäftslogik klar, wieviel plausibler das ist. Sie ist jetzt nicht mehr abhängig vom Datenzugriff. Warum sollte sie das auch sein? Welchen Grund gibt es, dass Domänenlogik sich Daten aus einer Ressource beschaffen sollte? Warum sollte Domänenlogik Kenntnis von einer Ressource haben?\n",
    "\n",
    "Das Schichtenmodell erklärt das nicht. Die Clean Architecture erklärt das auch nicht, obwohl auch dort zur Laufzeit (!) noch innere Schalen äußere aufrufen.\n",
    "\n",
    "Um den Kern einer Software wirklich von der Umwelt zu isolieren, darf es keine funktionalen Abhängigkeiten zwischen ihm und der Umwelt gehen. Funktionale Abhängigkeiten sind schlicht ein Widerspruch zum SLA. Mit ihnen würde die Geschäftslogik auf ein höheres Abstraktionsniveau gehoben als der Datenzugriff. Dort hat sie jedoch nichts zu suchen. Geschäftslogik ist nicht abstrakter als Datenzugriffslogik. Vielleicht ist sie zentraler, wichtiger, aber nicht abstrakter.\n",
    "\n",
    "##### Strata verstanden als Sprachen\n",
    "\n",
    "Die Lösung wird mit drei Sprache beschrieben:\n",
    "\n",
    "* Die höchste Sprache besteht nur aus einem Wort: `Run`.\n",
    "* Die niedrigere Sprache besteht aus drei Worten: `Load`, `CountWords` und `DisplayResult`.\n",
    "* Die niedrigste Sprache besteht aus den Logik-Anweisungen in den Operationen.\n",
    "\n",
    "Der Jo-Jo Entwurf von Flow-Design kann also als Sprachentwurf verstanden werden. Mit welchen sukzessive \"primitiveren\" - oder besser: allgemeineren - Sprachen lässt sich eine Lösung formulieren.\n",
    "\n",
    "Die höchste Sprache bzw. die spezifischste besteht dabei immer nur aus einem Wort. Im Grunde ist es ein [\"Sesam, öffne dich\"](https://de.wikipedia.org/wiki/Ali_Baba) oder [\"simsalabim\"](https://de.wikipedia.org/wiki/Zauberspruch): das ganze Problem möge sich wie von Zauberhand durch Aufruf dieses einen Wortes in Luft auflösen.\n",
    "\n",
    "Demgegenüber besteht die primitivste, allgemeinste Sprache immer aus allen Worten der zugrundgelegten Plattform aus Programmiersprache, Bibliotheken, Frameworks, APIs.\n",
    "\n",
    "Und zwischen diesen beiden können beliebig viele weitere Sprachen eingezogen werden. Bei trivialen Problem mögen die höchste und primitivste ausreichen. Alle interessanten Probleme jedoch werden am besten durch Spezialsprachen gelöst, die aufeinander aufbauen.\n",
    "\n",
    "Dazu ist es nicht nötig, *Domain Specific Languages (DSL)*, gar grafische, zu entwickeln. Simple Funktionen (und Module) genügen.\n",
    "\n",
    "Im Flow-Design gleichen sich diese Sprachen alle in ihrer Syntax, die durch Datenflüsse (und nicht-funktionale Abhängigkeiten) vorgegeben ist. Das Vokabular jedoch ist zu (er)finden.\n",
    "\n",
    "In Bezug auf ein etwas erweitertes Wortzählungsproblem ließen sich z.B. weitere Abstraktionsebenen mit eigenem Vokabular einziehen. Das könnte so aussehen:\n",
    "\n",
    "/// neue datenflusshierarchie für wortzählung mit mehr integrationsebenen (106)\n",
    "\n",
    "Im Code ist Logik nun in kleinere Einheiten verpackt. Die Funktionen sind feingranularer, das Vokabular also differenzierter (siehe Klassen der Geschäfts- und Datenzugriffslogik):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class CountWords_v2 {\n",
    "    public static void Run(string filename) {\n",
    "        var words = Dataaccess_Stratified.Load(filename);\n",
    "        var numberOfWords = Business_Stratified_v2.CountWords(words);\n",
    "        Presentation_Stratified.DisplayResult(filename, numberOfWords);\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business_Stratified_v2 {\n",
    "    public static int CountWords(IEnumerable<string> words) {\n",
    "        var significantWords = FilterShort(words);\n",
    "        significantWords = FilterNumbers(significantWords);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "    \n",
    "    private static IEnumerable<string> FilterShort(IEnumerable<string> words)\n",
    "        => words.Where(w => w.Length > 2);\n",
    "    \n",
    "    private static IEnumerable<string> FilterNumbers(IEnumerable<string> words) {\n",
    "        return words.Where(IsNoNumber);\n",
    "        \n",
    "        bool IsNoNumber(string candidateWord)\n",
    "            => int.TryParse(candidateWord, out var _) is false;\n",
    "    }\n",
    "}\n",
    "\n",
    "class Dataaccess_Stratified {\n",
    "    public static IEnumerable<string> Load(string filename) {\n",
    "        var text = LoadText(filename);\n",
    "        return SplitIntoWords(text);\n",
    "    }\n",
    "    \n",
    "    private static string LoadText(string filename)\n",
    "        => System.IO.File.ReadAllText(filename);\n",
    "    \n",
    "    private static IEnumerable<string> SplitIntoWords(string text)\n",
    "        => text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "}\n",
    "\n",
    "\n",
    "CountWords_v2.Run(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Lösung besteht jetzt aus drei Strata:\n",
    "\n",
    "1. `Run`\n",
    "2. `Load`, `CountWords`, `DisplayResult`\n",
    "3. `LoadText`, `SplitIntoWords`, `FilterShort`, `FilterNumbers`, `Count`, `DisplayResult`\n",
    "\n",
    "Das Vokabular wechselt von Stratum zu Stratum. Die Funktionseinheiten werden allgemeiner und allgemeiner, d.h. ihr Einsatzbereich wird größer und größer. Je tiefer ein Stratum liegt, desto größer die potenzielle Wiederverwendbarkeit der Funktionseinheiten in darüberliegenden Strata.\n",
    "\n",
    "Tendenziell werden Funktionseinheiten eines Stratums nur im direkt darüber liegenden benutzt. Gelegentlich greifen jedoch auch weiter oben liegende Strata darauf zu. Manches Vokabular ist dann so grundlegend, dass es sich durch mehrere Abstraktionsebenen durchzieht. Streng genommen könnte das als Verstoß gegen das SLA angesehen werden - doch im Einzelfall mag das besser verständlich sein als weitere Kapselungen in den einzelnen Strata.\n",
    "\n",
    "Deshalb ist auch Logik hier und da in der Integration im Flow-Design geduldet. Logik ist das Vokabular des Terrains und sollte deshalb nicht in einem Stratum der Abstraktion auftauchen - außer eben in Einzelfällen. Beispiel dafür hier ist `Count` in `Business_Stratified_v2.CountWords`, deren Aufruf zum dritten Stratum gerechnet wird.\n",
    "\n",
    "Unterhalb der Strata der Abstraktion liegt dann die Logik selbst. Ohne Operationen, Integrationen und Module ist sie quasi nackt. Jedes Detail ist sichtbar - aber die Lösung in dieser Weise entschleiert ist schwer verständlich und ihre Aspekte sind nicht getrennt testbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "var filename = \"samples/poem.txt\";\n",
    "\n",
    "var text = System.IO.File.ReadAllText(filename);\n",
    "IEnumerable<string> words = text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "words = words.Where(w => w.Length > 2);\n",
    "words = words.Where(w => int.TryParse(w, out var _) is false);\n",
    "var numberOfWords = words.Count();\n",
    "\n",
    "Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zusammenfassung\n",
    "\n",
    "Code aufgebaut aus Strata wachsender Abstraktion um einen Kern aus Logik herum versprechen bessere Verständlichkeit und Veränderbarkeit. Das meinen nicht nur Abselson und Sussman, sondern auch Alan Kay, [der dabei ebenfalls von einer Hierarchie von Sprachen spricht](https://www.tele-task.de/lecture/video/2772/#t=3283).\n",
    "\n",
    "/// schalen von strata mit logik im kern (107)\n",
    "\n",
    "Nichts anderes geschieht ja auch ganz grundsätzlich, wenn man Lösungen mit Logik in einer modernen Programmiersprache formuliert. Selbst die reine Logik der obigen Wortzählungslogik lässt sich als abstraktes Stratum verstehen oberhalb des Stratums der .NET *Intermediate Language (IL)*, das wiederum auf dem Stratum des Prozessor-Maschinencodes liegt, der den tatsächlich ausgeführten Microcode abstrahiert.\n",
    "\n",
    "/// schalen weiterführen unterhalb der logik mit microcode im kern (108)\n",
    "\n",
    "Warum also diese erfolgreiche Methode nicht oberhalb der Logik ebenfalls anwenden?\n",
    "\n",
    "Mit den Datenflüssen des Flow-Design geschieht das quasi natürlich durch die Anwendung von IOSP und PoMO. Dennoch ist die Vorstellung, in Strata von Sprache zu denken, ein gutes Hilfsmittel, um hierarchische Datenflüsse zu entwerfen.\n",
    "\n",
    "Und zur Analyse von funktionalen Hierarchien erweist sich das Prinzip nützlich, dass Abhängigkeiten nur in Richtung des Abstraktionsgefälles zeigen sollen, also von hoher Abstraktion zu niedriger. MVC, Schichtenmodell, Clean Architecture oder auch alle Entwurfsmuster können daraufhin überprüft werden, ob ihre Abhängigkeiten dem entsprechen. Tun sie das nicht, ist aus Sicht von Flow-Design zumindest Vorsicht angezeigt. Allemal die Verständlichkeit mag dann geringer als möglich sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-dimensionale Datenflüsse\n",
    "\n",
    "Das erste Kennzeichen von Flow-Design Datenflüssen ist die Abwesenheit von Schleifen. Daten fließen nur downstream: \"Vorwärts immer, rückwärts nimmer!\"😉 ist das Motto.\n",
    "\n",
    "Der Verzicht auf Schleifen ist eine \"freiwillige Selbstbeschränkung\". Er trägt dazu bei, dass Datenflüsse deklarativ sind, und erhöht die Verständlichkeit. Schleifen fordern mehr kognitiven Aufwand bei der Analyse von Code, weil sie dazu zwingen, etwas im Gedächtnis zu behalten, z.B. den Zustand einer Schleifenvariablen. Außerdem vergrößern sie das Risiko eines Bug z.B. durch 1-off Fehler:\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = 0;\n",
    "for(var i=0; i<=numbers.Length; i++) //😱\n",
    "    sum += numbers[i];\n",
    "```\n",
    "\n",
    "Moderne, abstraktere Sprachkonstrukte verringern zwar solches Risiko...\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = 0;\n",
    "foreach(var n in numbers) //😇\n",
    "    sum += numbers[i];\n",
    "```\n",
    "\n",
    "...und\\/oder erhöhen die Verständlichkeit:\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = numbers.Sum(); //🥳\n",
    "```\n",
    "\n",
    "Letztlich bleiben Schleifen aber problematisch: Es sind Kontrollstrukturen, die zur Schachtelung einladen und unübersichtlich werden, wenn sie wachsen. Nicht in allen Fällen helfen moderne Abstraktionen. Deshalb gilt das Prinzip des Verzichts auf Schleifen in Datenflüssen.\n",
    "\n",
    "Doch wie sieht es mit Fallunterscheidungen aus? Lassen sie sich auch vermeiden? Nein, Fallunterscheidungen definieren alternative Verhalten. Das ist notwendig und nicht zu vermeiden, auch wenn die Verhaltensproduktion mit Datenflüssen modelliert wird.\n",
    "\n",
    "#### Kategorisierung\n",
    "\n",
    "Eine häufige Anforderung im Rahmen der Verhaltensproduktion ist die Kategorisierung von Daten mit anschließend unterschiedlicher Behandlung je nach Kategorie. Beispiel: Eine Eingabe soll in eine Dezimalzahl konvertiert werden, wenn sie eine binäre Zahl ist, oder umgekehrt. Eine binäre Zahl liegt vor, wenn die Eingabe auf \"b\" endet.\n",
    "\n",
    "Eine Lösung könnte mit Flow-Design so aussehen:\n",
    "\n",
    "/// zahlenkonvertierung (109)\n",
    "\n",
    "Neu ist hier, dass eine Funktionseinheit wie `Determine number system` mehrere Ausgänge haben kann. Die stehen für die Alternativen, dass der Input als binäre oder dezimale Zahl vorliegt. Jenachdem, zu welcher Kategorie der Input gehört, fließt die Verarbeitung entlang des einen oder des anderen Datenflussarms weiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter {\n",
    "    public static string Convert(string number) {\n",
    "        var result = \"\";\n",
    "        DetermineNumberSystem(number,\n",
    "            decimalNumber => result = ToBinary(decimalNumber),\n",
    "            binaryNumber => result = ToDecimal(binaryNumber)\n",
    "        );\n",
    "        return result;\n",
    "    }\n",
    "    \n",
    "    private static void DetermineNumberSystem(string number, Action<string> onIsDecimal, Action<string> onIsBinary) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            onIsBinary(number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            onIsDecimal(number);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehrere parallele Datenflüsse fügen den bisherigen 2-dimensionalen Modellen eine dritte Dimension hinzu:\n",
    "\n",
    "/// 3 dimensionen in einem hierarchischen datenfluss kennzeichnen (komposition, produktion.linear und produktion.parallel) (109a)\n",
    "\n",
    "Wie schon vorher bei den 1-dimensionalen Datenflüssen gilt auch hier: alle Funktionseinheiten arbeiten grundsätzlich unabhängig voneinander. Nacheinander geschaltete Funktionseinheiten können gleichzeitig aktiv sein, parallel geschaltete ebenfalls. Dass das oft nicht der Fall ist, weil nicht nötig wie im obigen Beispiel, tut dem keinen Abbruch. 3-dimensionale Datenflüsse erlauben die modellierung synchroner wie asynchroner, gar paralleler Verarbeitung.\n",
    "\n",
    "##### Übersetzungsalternativen\n",
    "\n",
    "Auffallend an den alternativen Ausgängen der Funktionseinheit `DetermineNumberSystem` ist, dass Output auf beiden als stream herausfließt. Das ist immer der Fall, wenn Output-Nachrichten entstehen können oder auch nicht. Wenn der Input eine dezimale Zahl darstellt, dann fließt Output auf dem zugehörigen Port heraus - und beim anderen nicht. Und umgekehrt. Nur mit streams ist es möglich, keinen Output zu erzeugen.\n",
    "\n",
    "Das führt dann dazu, dass in der Übersetzung continuations zum Einsatz kommen. Nur mit ihnen lässt sich der Fall ohne Output für eine Alternative sauber implementieren.\n",
    "\n",
    "Alternativ wäre in einer Sprache wie C# mit Tupel-Unterstützung zwar auch folgende Übersetzung möglich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter_v2 {\n",
    "    public static string Convert(string number) {\n",
    "        var categorization = DetermineNumberSystem(number);\n",
    "        if (categorization.isBinary)\n",
    "            return ToDecimal(categorization.normalizedNumber);\n",
    "        else\n",
    "            return ToBinary(categorization.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (bool isBinary, string normalizedNumber) DetermineNumberSystem(string number) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            return (true, number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            return (false, number);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter_v2.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter_v2.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doch damit würde die Integration `Convert` durch eine Kontrollstruktur verschmutzt. Das ist zwar nur minimal... dennoch sollte man sich dessen bewusst sein.\n",
    "\n",
    "Im allgemeinen Fall würde diese Variante die Kategorie über einen `enum`-Datentyp zurückliefern.\n",
    "\n",
    "Oder sie könnte sogar noch weitergehen und die downstream Verarbeitung selbst dynamisch bestimmen. Hierin könnte man zwar einen Widerspruch zum PoMO sehen... doch wenn Kategorisierung und Mapping auf eine Verarbeitung getrennt sind, mag das der Verständlichkeit und Testbarkeit nicht abträglich, sondern sogar zuträglich sein.\n",
    "\n",
    "/// kategorisierung mit converter bestimmung (110)\n",
    "\n",
    "Jetzt gibt es keine Continuations mehr im Code. Jetzt gibt es keine unsauberen Kontrollstrukturen mehr in Integrationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter_v3 {\n",
    "    public static string Convert(string number) {\n",
    "        var conversion = ChooseConverter(number);\n",
    "        return conversion.convert(conversion.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (Func<string,string> convert, string normalizedNumber) ChooseConverter(string number) {\n",
    "        var categorization = DetermineNumberSystem(number);\n",
    "        var convert = PickConverter(categorization.isBinary);\n",
    "        return (convert, categorization.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (bool isBinary, string normalizedNumber) DetermineNumberSystem(string number) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            return (true, number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            return (false, number);\n",
    "    }\n",
    "    \n",
    "    private static Func<string,string> PickConverter(bool isBinary) => isBinary switch {\n",
    "        true => ToDecimal,\n",
    "        false => ToBinary\n",
    "    };\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter_v3.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter_v3.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem Anfänger in Sachen Flow-Design fällt es gewöhnlich nicht leicht, sich vorzustellen, dass Kontrollstrukturen und insbesondere Fallunterscheidungen wirklich nur in den Blättern des Zerlegungsbaumes stehen. Das ist verständlich, weil es so ungewohnt ist. In den Bäumen tiefer funktionaler Abhängigkeiten ist das undenkbar und scheint auch gar nicht nötig.\n",
    "\n",
    "Doch gerade hierin liegt das Geheimnis der Verständlichkeit und Testbarkeit von Code, der mit Flow-Design modelliert und IOSP/PoMO folgend übersetzt wird! Deshalb sollten alle Anstrengungen unternommen werden, Schleifen und Fallunterscheidungen wirklich in die Operation-Funktionen hinunter zu drücken. Es ist in jedem Fall machbar und ist der Default im Flow-Design. Abweichungen davon sollten sehr bewusst eingegangen werden; sie lassen dark logic entstehen und verwässern das stratified design.\n",
    "\n",
    "#### Fehler\n",
    "\n",
    "Ein weiterer typischer Fall für parallele Datenflüsse stellen Fehler dar. Da gibt es einerseits den Datenfluss für den \"happy day\", d.h. wenn alles wie erwartet läuft. Und andererseits gibt es den Datenfluss für den \"rainy day\", d.h. den Fehlerfall.\n",
    "\n",
    "Ein typisches Szenario ist die Validation: Wenn ankommende Daten bestimmten Kriterien genügen, scheint die Sonne, ansonsten regnet es. Gutfall und Fehlerfall zu unterscheiden ist ein nicht zu vernachlässigender Teil jedes Modells. Im Flow-Design geschieht das wieder mit mehreren Ausgängen und parallelen Datenflüssen.\n",
    "\n",
    "Als Beispiel die Addition mehrerer durch Leerzeichen getrennter Zahlen. Sind alle Zahlen valide, kann die Summe gebildet und ausgegeben werden. Falls nicht, gibt es eine Fehlermeldung.\n",
    "\n",
    "/// modell für die zahlenaddition mit fehlerfall (111)\n",
    "\n",
    "Gutfall oder Fehlerfall sind also im Grunde nur zwei Kategorien. Deren Bestimmung erfolgt oft jedoch nicht in einer speziellen Funktionseinheit zur Kategorisierung wie bei der Zahlenwandlung oben, sondern ist ein Beiprodukt. Hier nimmt z.B. `Parse` den Gutfall an, ist jedoch darauf vorbereitet, dass es zum Fehlerfall kommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum of 1 2 3 = 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Error: Cannot sum numbers! 'foo' is not a number."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "public class StringMath {\n",
    "    public static void Sum(string source, Action<int> onOk, Action<string> onError) {\n",
    "        Parse(source,\n",
    "             numbers => {\n",
    "                 var sum = numbers.Sum();\n",
    "                 onOk(sum);\n",
    "             },\n",
    "             erroneousNumber => {\n",
    "                 var error = $\"Cannot sum numbers! '{erroneousNumber}' is not a number.\";\n",
    "                 onError(error);\n",
    "             }\n",
    "         );\n",
    "    }\n",
    "    \n",
    "    private static void Parse(string source, Action<int[]> onSuccess, Action<string> onFailure) {\n",
    "        var candidateNumbers = source.Split(' ');\n",
    "        var numbers = new List<int>();\n",
    "        foreach(var cn in candidateNumbers)\n",
    "            if (int.TryParse(cn, out var n))\n",
    "                numbers.Add(n);\n",
    "            else {\n",
    "                onFailure(cn);\n",
    "                return;\n",
    "            }\n",
    "        onSuccess(numbers.ToArray());\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "var input = \"1 2 3\";\n",
    "StringMath.Sum(input,\n",
    "    sum => display($\"sum of {input} = {sum}\"),\n",
    "    error => display($\"Error: {error}\")\n",
    ");\n",
    "\n",
    "input = \"1 foo 3\";\n",
    "StringMath.Sum(input,\n",
    "    sum => display($\"sum of {input} = {sum}\"),\n",
    "    error => display($\"Error: {error}\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das der Gutfall der wünschenswerte und meist interessantere und hoffentlich auch der häufigere ist, könnte man versucht sein, die Asymmetrie zwischen Gutfall und Fehlerfall im Code auszudrücken. Warum nicht den Output des Gutfalls über das Funktionsresultat zurückliefern und den Fehlerfall in einer continuation abhandeln?\n",
    "\n",
    "```csharp\n",
    "private static int[] Parse(string source, Action<string> onFailure) {\n",
    "    var candidateNumbers = source.Split(' ');\n",
    "    var numbers = new List<int>();\n",
    "    foreach(var cn in candidateNumbers)\n",
    "        if (int.TryParse(cn, out var n))\n",
    "            numbers.Add(n);\n",
    "        else {\n",
    "            onFailure(cn);\n",
    "            return null; //😱\n",
    "        }\n",
    "    return numbers.ToArray();\n",
    "}\n",
    "```\n",
    "\n",
    "Das Problem ist der Rückgabewert der Funktion im Fehlerfall. Warum sollte der wie hier `null` sein? Darauf muss die Gutfall-Bearbeitung vorbereitet sein. Das vergrößert die Komplexität des Codes.\n",
    "\n",
    "Einer symmetrische Behandlung ist der Vorzug zu geben. Wenn die nicht durch continuations stattfinden soll, dann wäre es besser, die Alternative Klassifizierungsübersetzung zum Einsatz zu bringen:\n",
    "\n",
    "```csharp\n",
    "private static (bool success, int[] numbers, string error) Parse(string source) {\n",
    "    var candidateNumbers = source.Split(' ');\n",
    "    var numbers = new List<int>();\n",
    "    foreach(var cn in candidateNumbers)\n",
    "        if (int.TryParse(cn, out var n))\n",
    "            numbers.Add(n);\n",
    "        else \n",
    "            return (false, new int[0], cn);\n",
    "    return (true, numbers.ToArray(), \"\");\n",
    "}\n",
    "```\n",
    "\n",
    "Das ist ein anerkanntes Muster neben der einfacheren Variante einer `Try`-Funktion, z.B. `bool TryParse(string source, out int[] numbers)`.\n",
    "\n",
    "Ohne continuations rutscht aber in jedem Fall Kontrollstruktur-Logik in die Integration, in der eine solche Funktion aufgerufen wird. Es ist also sensibel abzuwägen.\n",
    "\n",
    "#### Ausnahmen\n",
    "\n",
    "Es gibt erwartete Fehler und unerwartet. Letztere werden im Notfall durch Exceptions angezeigt. Die können wie rainy-day Fehler modelliert werden und insofern erwartet aussehen. Oder man benutzt eine spezielle Datenflussnotation, um anzuzeigen, dass Ausnahme nicht näher bestimmt aus einer Reihe von Funktionseinheiten herausspringen können.\n",
    "\n",
    "Als Beispiel ein Datenfluss der eine Reihe von Dateien verarbeitet: Sie werden gelesen, analysiert und das Analyseergebnis am Ende ausgegeben. In jedem der Schritte könnte eine Ausnahme geworfen werden. Das wird nicht erwartet, aber die Möglichkeit besteht. Deshalb gibt es keine speziellen Fehlerausgänge bei allen Funktionseinheiten, sondern sie werden in einen \"Kontext\" gesteckt, der allgemein darauf reagiert. (Die Funktionale Programmierung könnte dazu wohl auch *Monade* sagen.)\n",
    "\n",
    "/// datenfluss mit lesen, analysieren, summieren, anzeigen (112)\n",
    "\n",
    "Für den möglichen, aber nicht wahrscheinlichen Fall einer Ausnahme jede Funktionseinheit mit einem speziellen Output-Port dafür zu versehen, würde die Komplexität des Modells und des Codes stark erhöhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 files with 28384 lines in total\n",
      "Exception: Could not find a part of the path '/Users/ralfw/Projects/jupyter-notebooks.github/Notebooks/flow-design-tutorial/foo'.\n"
     ]
    }
   ],
   "source": [
    "class FileStats {\n",
    "    public static void CountLines(string path) {\n",
    "        try {\n",
    "            (int numberOfFiles, int totalNumberOfLines) accumulator = (0,0);\n",
    "            EnumerateFiles(path,\n",
    "                filename => {\n",
    "                    var lines = System.IO.File.ReadAllLines(filename);\n",
    "                    accumulator.numberOfFiles += 1;\n",
    "                    accumulator.totalNumberOfLines += lines.Length;\n",
    "                });\n",
    "            DisplayResult(accumulator);\n",
    "        }\n",
    "        catch(Exception ex) {\n",
    "            DisplayException(ex);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void EnumerateFiles(string path, Action<string> onFile) {\n",
    "        foreach(var filename in System.IO.Directory.GetFiles(path, \"*.*\", System.IO.SearchOption.AllDirectories))\n",
    "            onFile(filename);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void DisplayResult((int numberOfFiles, int totalNumberOfLines) result)\n",
    "        => Console.WriteLine($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines in total\");\n",
    "    \n",
    "    private static void DisplayException(Exception ex)\n",
    "        => Console.WriteLine($\"Exception: {ex.Message}\");\n",
    "}\n",
    "\n",
    "\n",
    "FileStats.CountLines(\"../entwurf\");\n",
    "FileStats.CountLines(\"../foo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Übersetzung des Kontextes mit `try`-`catch` ist naheliegend. Dass diese Kontrollstruktur jedoch in der Integration liegt, ist ein Widerspruch zum IOSP. Da Verständlichkeit und Testbarkeit dadurch jedoch nicht beeinträchtigt werden, ist das ausnahmsweise jedoch kein Problem.\n",
    "\n",
    "Wer jedoch auf Nummer sicher gehen will, insbesondere wenn noch weitere Logik in beiden Fällen hinzukommen soll, der lagert die Kontrollstruktur aus in eine eigene Methode wie die folgende:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exceptionhandling {\n",
    "    public static void Try(Action tryThis, Action<Exception> onException) {\n",
    "        try {\n",
    "            display($\"trying...\");\n",
    "            tryThis();\n",
    "            display($\"succeeded!\");\n",
    "        }\n",
    "        catch(Exception ex) {\n",
    "            display($\"failed!\");\n",
    "            onException(ex);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzliche Logik ist hier angedeutet durch die Protokollnachrichten. Sie würden die eigentliche Logik verrauschen und sind ein einem \"Kontext\" als separater Aspekt gut ausgelagert.\n",
    "\n",
    "Die Lösung sieht dann nur wenig anders aus, enthält aber keine Logik mehr in der Integration `CountLines`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trying..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 files with 28936 lines in total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "succeeded!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "trying..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "failed!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: Could not find a part of the path '/Users/ralfw/Projects/jupyter-notebooks.github/Notebooks/flow-design-tutorial/foo'.\n"
     ]
    }
   ],
   "source": [
    "class FileStats_v2 {\n",
    "    public static void CountLines(string path) {\n",
    "        Exceptionhandling.Try(\n",
    "            () => Analyze(path),\n",
    "            DisplayException\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    private static void Analyze(string path) {\n",
    "        (int numberOfFiles, int totalNumberOfLines) accumulator = (0,0);\n",
    "        EnumerateFiles(path,\n",
    "            filename => {\n",
    "                var lines = System.IO.File.ReadAllLines(filename);\n",
    "                accumulator.numberOfFiles += 1;\n",
    "                accumulator.totalNumberOfLines += lines.Length;\n",
    "            });\n",
    "        DisplayResult(accumulator);\n",
    "    }\n",
    "    \n",
    "    private static void EnumerateFiles(string path, Action<string> onFile) {\n",
    "        foreach(var filename in System.IO.Directory.GetFiles(path, \"*.*\", System.IO.SearchOption.AllDirectories))\n",
    "            onFile(filename);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void DisplayResult((int numberOfFiles, int totalNumberOfLines) result)\n",
    "        => Console.WriteLine($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines in total\");\n",
    "    \n",
    "    private static void DisplayException(Exception ex)\n",
    "        => Console.WriteLine($\"Exception: {ex.Message}\");\n",
    "}\n",
    "\n",
    "\n",
    "FileStats_v2.CountLines(\"../entwurf\");\n",
    "FileStats_v2.CountLines(\"../foo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flüsse teilen und zusammenführen\n",
    "\n",
    "Mehrere Datenflüsse können nicht nur alternativ durchflossen werden, sondern auch gleichzeitig. Das ist z.B. der Fall, wenn Input Teile enthält, die unabhägig von einander verarbeitet werden können. Von der Datenflussnotation her könnte solche Verarbeitung zwar mit einem 1-dimensionalen Datenfluss modelliert werden, aber klarer ist es, wenn Parallelität auch visuell ausgedrückt wird.\n",
    "\n",
    "##### Split/Join\n",
    "\n",
    "Als Beispiel mag die Analyse von Dateien in Bezug auf zwei Aspekte dienen: einerseits soll ihre Zeilenzahl bestimmt werden, andererseits ihre Wortanzahl. Beide Informationen werden anschließend zu einem Ergebnis zusammengeschnürt.\n",
    "\n",
    "/// datei laden - split für zeilenzählung / wortzählung, join für ergebniszusammenführung (mit stats) datenstruktur (113)\n",
    "\n",
    "Nach dem Laden der Datei wird der Datenfluss geteilt (split), beide Verarbeitungszweige laufen unabhängig, am Ende werden deren Teilergebnisse zu einem Gesamtergebnis zusammengeführt (join).\n",
    "\n",
    "Sofern eine Zusammenführung unaufwändig ist, muss keine eigens benannte Funktionseinheit dafür modelliert werden. Es reicht das join-Symbol wie hier gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>NumberOfLines</th><th>NumberOfWords</th></tr></thead><tbody><tr><td>15</td><td>79</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FileAnalysis {\n",
    "    public class Result {\n",
    "        internal Result(int numberOfLines, int numberOfWords) {\n",
    "            NumberOfLines = numberOfLines;\n",
    "            NumberOfWords = numberOfWords;\n",
    "        }\n",
    "        \n",
    "        public int NumberOfLines {get;}\n",
    "        public int NumberOfWords {get;}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    public static Result Analyze(string filename) {\n",
    "        var text = Load(filename);\n",
    "        return new Result(\n",
    "            CountLines(text),\n",
    "            CountWords(text)\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string Load(string filename)\n",
    "        => System.IO.File.ReadAllText(filename);\n",
    "    \n",
    "    \n",
    "    private static int CountLines(string text) {\n",
    "        var lines = text.Split('\\n');\n",
    "        return lines.Length;\n",
    "    }\n",
    "    \n",
    "    private static int CountWords(string text) {\n",
    "        var words = text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "        return words.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(FileAnalysis.Analyze(\"samples/poem.txt\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was im Modell noch explizit ist, geschieht im Code dann fast unmerklich:\n",
    "\n",
    "* Der split findet keine spezielle Übersetzung; dieselben Daten werden einfach als aktuelle Parameter zweier Funktionsaufrufe benutzt.\n",
    "* Die Parallelität der Datenflüsse ist nicht deutlich zu sehen, weil der lineare Quelltext das nicht erlaubt. Nur aus der Benutzung derselben Daten als Input für aufeinander folgende Funktionsaufrufe ist Parallelität herauszulesen.\n",
    "* Der join besteht schlicht in der Nutzung beider Teilergebnisse als Parameter eines weiteren Funktionsaufrufs.\n",
    "\n",
    "In anderen Fällen mögen split und join hingegen sowohl im Modell wie im Code deutlicher zu sehen sein.\n",
    "\n",
    "/// beispiel für split und join funktionseinheiten (fluss dazwischen nur andeuten) (114)\n",
    "\n",
    "Zweierlei ist dabei dann zu bedenken:\n",
    "\n",
    "* Split: Fließt Output aus den Ports optional/alternativ oder stets? Optionalität fordert die Modellierung als stream und legt eine Implementation als continuation nahe.\n",
    "* Join: Soll Verarbeitung bei jedem Eintreffen von Input stattfinden, egal auf welchem Port er hineinfließt, oder nur, wenn an allen Ports Input anliegt? Letzteres lässt sich leicht in mehrere Funktionsparameter übersetzen wie oben beim `Result`-Konstruktor zu sehen. Ersteres legt eine Übersetzung in mehrere separate Funktionen einer Klasse nahe.\n",
    "\n",
    "##### Scatter/Gather\n",
    "\n",
    "Ein Beispiel für explizite splits und joins sind echte Parallelverarbeitungsszenarien, d.h. Übersetzungen, in denen mehrere Threads zum Einsatz kommen.\n",
    "\n",
    "Beispiel: Dateien sollen parallel analysiert werden. Anschließend werden alle Analyseergebnisse zu einem zusammengeführt. Die Analyse kann so simpel sein wie die Zählung der Zeilen je Datei.\n",
    "\n",
    "/// paralleler datenfluss für dateizeilenzählung mit join am ende (115)\n",
    "\n",
    "Zunächst findet hier eine unbekannt große Aufsplittung des Datenflusses in parallele/konkurrente statt (scatter). Das kann mit einem stream geschehen, bei dem für jedes Element ein Thread gestartet wird.\n",
    "\n",
    "Wie lange die einzelnen Analysen dauern und wieviele es sind, ist bei der Akkumulation des Ergebnisses jedoch nicht bekannt (gather). Wann soll also deren Output ausfließen? Wie weiß die Akkumulation, dass das letzte Analyseergebnis eingetroffen ist? Das kann implizit mittels einer Framework-Technologie geschehen (z.B. ein `Task.WaitAll` im .NET Framework) oder explizit durch Vergleich der Zahl der eingetroffenen Ergebnisse mit der zu erwartenden Zahl, die von scatter gemeldet wird. Das Modell zeigt den zweiten Ansatz für gather, um technologieneutraler und expliziter zu sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  analyzing ../prozess.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anforderungen.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anforderung-logik-lücke.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../index.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../entwurf/entwurf_1.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../codierung/arbeitsorganisation.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../analyse/slicing.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/radikale_oo.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/ioda.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/dimensionen.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10 files with 5601 lines total"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System.Threading;\n",
    "\n",
    "class ConcurrentFileAnalysis {\n",
    "    public static (int numberOfFiles, int totalNumberOfLines) Analyze(string path) {\n",
    "        var acc = new Accumulator();\n",
    "        \n",
    "        var filenames = CompileFiles(path);\n",
    "        Scatter(filenames,\n",
    "            filename => {\n",
    "                var numberOfLines = AnalyzeFile(filename);\n",
    "                acc.Add(numberOfLines);\n",
    "            },\n",
    "            acc.SetNumberOfValuesToExpect\n",
    "        );\n",
    "            \n",
    "        return acc.Gather();\n",
    "    }\n",
    "    \n",
    "    private static string[] CompileFiles(string path) {\n",
    "        var filenames = System.IO.Directory.GetFiles(path, \"*.ipynb\", System.IO.SearchOption.AllDirectories);\n",
    "        return filenames.Where(filename => filename.IndexOf(\"/.\") < 0).ToArray();\n",
    "    }\n",
    "    \n",
    "    private static void Scatter(string[] filenames, Action<string> onFilename, Action<int> onAllScattered) {\n",
    "        foreach(var filename in filenames) {\n",
    "            var th = new Thread(() => onFilename(filename));\n",
    "            th.Start();\n",
    "            //onFilename(filename);\n",
    "        }\n",
    "        onAllScattered(filenames.Length);\n",
    "    }\n",
    "    \n",
    "    private static int AnalyzeFile(string filename) {\n",
    "        display($\"  analyzing {filename}\");\n",
    "        var lines = System.IO.File.ReadAllLines(filename);\n",
    "        return lines.Length;\n",
    "    }\n",
    "}\n",
    "\n",
    "private class Accumulator {\n",
    "    private object _lock = new Object();\n",
    "    private AutoResetEvent _are = new AutoResetEvent(false);\n",
    "\n",
    "    private int _numberOfValuesToExpect = 0;\n",
    "    private int _numberOfValuesReceived = 0;\n",
    "\n",
    "    private int _total;\n",
    "\n",
    "    \n",
    "    public void SetNumberOfValuesToExpect(int numberOfValuesToExpect) {\n",
    "        lock(_lock) {\n",
    "            _numberOfValuesToExpect = numberOfValuesToExpect;\n",
    "            \n",
    "            if (_numberOfValuesReceived >= _numberOfValuesToExpect)\n",
    "                _are.Set();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void Add(int value) {\n",
    "        lock(_lock) {\n",
    "            _numberOfValuesReceived++;\n",
    "             _total += value;\n",
    "            \n",
    "            if (_numberOfValuesToExpect > 0 && _numberOfValuesReceived >= _numberOfValuesToExpect)\n",
    "                 _are.Set();\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public (int numberOfValues, int totalValue) Gather() {\n",
    "        _are.WaitOne();\n",
    "        return (_numberOfValuesToExpect, _total);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "var result = ConcurrentFileAnalysis.Analyze(\"..\");\n",
    "display($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines total\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "datenströme explizit beenden (hier ein thema, weil bei 3D datenflüssen eher continuations zum einsatz kommen)\n",
    "oder auch parallelverarbeitung: fork join/wait, scatter/gather (dateien parallel verarbeiten).\n",
    "ende implizit (IEnum) oder EOS element oder signal (dass ende erreicht oder wann ende erreicht (anzahl zu erwartender inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L√∂sungsmodelle entwerfen\n",
    "\n",
    "![](../images/serenity/serenity8.jpg)\n",
    "\n",
    "Flow-Design verfolgt einen verhaltensorientierten Ansatz. L√∂sungen werden von der SOLL-Funktionalit√§t her angegangen. F√ºr Flow-Design lautet die Frage zuerst: Was soll Software tun?\n",
    "\n",
    "Nicht Datenstrukturen stehen also im Vordergrund, sondern Verhaltensstrukturen. Verhalten konsumiert und produziert Daten. Um zu wissen, wie Daten strukturiert sein sollen, ist also zuerst die Verhaltensproduktion zu kl√§ren.\n",
    "\n",
    "Was wie womit getan werden soll, entsteht dabei zun√§chst in den K√∂pfen der Entwickler und auf Papier. Die Codierung ist zur√ºckgestellt, bis f√ºr ein klar umrissenes Problem die L√∂sung als Modell vorliegt.\n",
    "\n",
    "Ein Modell versteht Flow-Design dabei ganz allgemein so:\n",
    "\n",
    "> Modell = (Funktion, Beziehung, Funktion)\\*\n",
    "\n",
    "Ein Modell ist eine Menge von Tupeln, in denen je zwei Funktion in Beziehung zueinander gesetzt werden.\n",
    "\n",
    "Wie auch immer Modelle dargestellt werden, aus ihnen m√ºssen programmiersprachliche Funktionen abgeleitet werden k√∂nnen. In Modellen findet sich keine Logik; sie sind deklarativ. Aber ihre Bausteine stehen f√ºr Funktionen, die sp√§ter in der Codierung mit Logik gef√ºllt werden.\n",
    "\n",
    "Beziehungen zwischen Funktionen k√∂nnen unter anderem sein:\n",
    "\n",
    "* Abh√§ngigkeit: Eine Funktion ruft eine andere auf.\n",
    "* Sequenz: Eine Funktion steht in einem Fluss vor oder nach einer anderen.\n",
    "* Parallelit√§t: Eine Funktion kann/muss parallel zu einer anderen ausgef√ºhrt werden.\n",
    "* Aggregation: Zwei Funktionen sind in einem Modul zusammengefasst.\n",
    "* Gemeinsame Daten: Zwei Funktionen nutzen dieselben Daten.\n",
    "* Konkretisierung: Zwei Funktionen stehen in einer Vererbungsbeziehung.\n",
    "\n",
    "Die Deklarativit√§t von Modellen im Flow-Design macht aus, dass ihre Bausteine f√ºr angenommene Probleml√∂sungen stehen. Entweder wird dann das Problem an anderer Stelle im Modell durch eine Verfeinerung gel√∂st. Oder eine im Modell offen gebliebene Annahme wird sp√§testens in der Codierung mittels Logik erf√ºllt.\n",
    "\n",
    "![](images/df1.png)\n",
    "\n",
    "Bei all dieser Allgemeinheit in der Definition von Modellen hat Flow-Design allerdings einen klaren Favoriten als Modellierungsansatz. Flow-Design steht f√ºr die √úberzeugung, dass Softwarel√∂sungen zun√§chst und ganz fundamental Produktionsprozesse sind, die auf Daten arbeiten und also als Datenfl√ºsse modelliert werden k√∂nnen. Der Entwurf im Flow-Design beginnt daher gemeinhin mit einer Datenflussmodellierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Datenfl√ºssen modellieren\n",
    "\n",
    "Die Datenflussmodellierung beginnt gew√∂hnlich mit einer in der Analyse ermittelten Interaktion repr√§sentiert durch ein Nachrichtenpaar und ggf. Seiteneffekte. Ausgangspunkt ist eine Funktionseinheit, die Verhalten zeigen soll in Form einer klar definierten Datentransformation. Sie stellt die Wurzel des L√∂sungsansatzes dar. Sie repr√§sentiert die angenommen erf√ºllten Anforderungen.\n",
    "\n",
    "![](images/df2.png)\n",
    "\n",
    "Wie aufw√§ndig die L√∂sung eines so gestellten Verhaltensproblems sein mag, ist seiner formalen Darstellung nicht anzusehen. Das ist aber auch nicht n√∂tig, wie sich zeigen wird. Wichtiger ist die einfachheit der Darstellung und ihre Klarheit im Sinne einer Codierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-dimensionale Datenfl√ºsse\n",
    "\n",
    "Eine Funktionseinheit, die Input in Output √ºberf√ºhrt, ist das kleinstm√∂gliche Datenfluss-Modell. Sie entspricht einem Punkt im dreidimensionalen Raum, ist also 0-dimensional.\n",
    "\n",
    "![](images/df3.png)\n",
    "\n",
    "#### Notation\n",
    "\n",
    "So leichtgewichtig die Notation f√ºr solch eine Repr√§sentanz einer Probleml√∂sung sein mag, so sind doch ein paar Hinweise angebracht:\n",
    "\n",
    "* Eine Funktionseinheit dargestellt als \"Blase\" oder Kreis oder Ellipse, also als \"runde Form\" steht f√ºr etwas, das getan werden soll; sie l√∂st ein Problem durch ihre Transformation von Input zu Output. Deshalb ist ihre Benennung mit einem Verb oder einer Verbphrase sinnvoll. Ein Imperativ muss es nicht sein, aber darf es nat√ºrlich. Zudem sollte die Benennung relevant f√ºr das Umfeld sein, also orientiert an der Dom√§nensprache statt technisch. Au√üerdem - und vielleicht sogar am wichtigsten - sollte die Bennung keinen Hinweis auf die L√∂sung(simplementation) enthalten. Die wird im Modell nur gew√ºnscht, nicht gewusst. **Es geht im Modell ums Was und Warum, nicht ums Wie.**\n",
    "* Datenfl√ºsse werden durch Pfeile zur und von der Funktionseinheit angezeigt. Pfeile werden im Flow-Design ausschlie√ülich f√ºr diesen Zweck benutzt! Pfeile stellen also keine Abh√§ngigkeiten dar, sondern unidirektionale Datenkan√§le, deren Quellen und Senken einander nicht kennen.\n",
    "* Was flie√üt, wird immer (!) an Pfeilen in Klammern kurz beschrieben. Auch hier geht es vor allem ums Was, nicht ums Wie. Daten werden mit Substantiven benannt. Meist geschieht das in Kleinschreibung und ohne Datentyp, weil der offensichtlich ist. Aber es kann auch ein Datentyp explizit hinzugef√ºgt werden. Oder Daten werden in Gro√üschreibung benannt und stehen damit selbst f√ºr einen Datentyp.\n",
    "\n",
    "![](images/df4.png)\n",
    "\n",
    "##### Zustandsbehaftete Funktionseinheiten\n",
    "\n",
    "Funktionseinheiten arbeiten vor allem auf dem Input, der in sie einflie√üt. Eintreffender Input triggert ihr Verhalten. Aber Funktionseinheiten sind nicht per se *pur*. Flow-Design hat kein Ideal von \"pure functional units\" wie die Funktionale Programmierung \"pure functions\" favorisiert. Flow-Design empfiehlt Zustandslosigkeit bzw. Seiteneffektfreiheit, wo sie sinnvoll und machbar sind. Doch wenn sich das (zun√§chst) als unintuitiv erweisen sollte, sind Zustand und Seiteneffekte v√∂llig akzeptable - sollten jedoch angezeigt werden.\n",
    "\n",
    "![](images/df5.png)\n",
    "\n",
    "Wie Zustand genau realisiert wird, ist wieder nicht Sache des Modells. Es soll vor allem klar gemacht werden, dass es eine Einflussgr√∂√üe f√ºr die Transformation gibt, die √ºber Nachrichten hinweg relevant ist.\n",
    "\n",
    "Wenn Zustand an gewisser Stelle vermieden werden soll, kann er auch in den Fluss extrahiert werden:\n",
    "\n",
    "![](images/df6.png)\n",
    "\n",
    "Dasselbe gilt f√ºr Seiteneffekte. Die werden √ºber einen API hergestellt, der auch in spezifischeren Funktionseinheiten up-/downstream enger gekapselt werden k√∂nnte:\n",
    "\n",
    "![](images/df7.png)\n",
    "\n",
    "##### Datenstr√∂me\n",
    "\n",
    "Die meisten Funktionseinheiten transformieren eine Input-Nachricht in eine Output-Nachricht. Dabei ist es unerheblich, ob Input oder Output aus einem Datum bestehen oder ein Feld sind, eine Liste oder eine andere Sammlung von vielen Daten.\n",
    "\n",
    "![](images/df8.png)\n",
    "\n",
    "Wenn Sammlungen (*collections*) flie√üen, kann deren Typ explizit angeben werden - z.B. `(dateiname[])`, `(dateinamen:List<string>)`. Im Allgemeinen ist das jedoch schon zu viel Implementationsdetail f√ºr ein Modell. Deshalb ziegt Flow-Design ein schlichtere Angabe f√ºr \"mehrere Daten\" vor, die \"in einem Schwung\" ein-/ausflie√üen: `(dateiname*)`. Der Datenangabe ist einfach nur unmittelbar und in der Klammer ein Sternchen nachzustellen.\n",
    "\n",
    "![](images/df9.png)\n",
    "\n",
    "Eine oft zu vernachl√§ssigende, am Ende jedoch sehr interessante Eigenschaft von Datenfl√ºssen im Gegensatz zu Kontrollfl√ºssen ist jedoch, dass alle Funktionseinheiten im Grunde *gleichzeitig* aktiv sind. Nur weil Daten produziert sind und ausflie√üen, hei√üt das nicht, dass eine Funktionseinheit die Kontrolle abgibt. Sie kann auch weiterarbeiten, w√§hrend der Output zu einer anderen Funktionseinheit flie√üt und gleichzeitig dort verarbeitet wird. Produzenten und Konsumenten sind grunds√§tzlich nebenl√§ufig und asynchron - und nur, wenn das nicht wichtig ist, werden sie sequenziell und synchron implementiert.\n",
    "\n",
    "Die grunds√§tzliche Nebenl√§ufigkeit hat nun zur Folge, dass eine Funktionseinheit nicht nur einmal f√ºr einen Input einen Output produzieren kann, sondern mehrfach. Dann entsteht keine *collection* von Nachrichten, sondern ein *stream*. Jedes Element in solch einem  Strom ist eine eigene Nachricht. Angezeigt wird das im Modell durch ein Sternchen *hinter* der Klammer, z.B. `(dateiname)*`.\n",
    "\n",
    "Str√∂me sind nur relevant zu markieren als Output. Die Anlieferung von Input erfolgt im Grunde immer als Strom. Notiert wird das nur nicht speziell; es ist normal. Auf jede Nachricht im Input-Strom reagiert eine Funktionseinheit dann.\n",
    "\n",
    "![](images/df10.png)\n",
    "\n",
    "#### √úbersetzung\n",
    "\n",
    "\"Bubbles don't crash\" - das ist wahr und deshalb ist es Flow-Design wichtig, dass die \"Bubbles\" seiner Modelle m√∂glichst einfach in Code √ºbersetzt werden k√∂nnen, der crashen kann, um Modell-Ideen zu √ºberpr√ºfen.\n",
    "\n",
    "Die naheliegende √úbersetzung einer Funktionseinheit ist die in eine Funktion:\n",
    "\n",
    "![](images/df11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int CalcAverage(IEnumerable<int> werte) {\n",
    "    return werte.Sum() / werte.Count();\n",
    "}\n",
    "\n",
    "display($\"Durchschnitt von [1,5,9,3]: {CalcAverage(new[]{1,5,9,3})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert gut, solange f√ºr jeden Input-Wert ein Output-Wert bzw. eine Output-Collection erzeugt wird. Und auch mit Tupeln funktioniert es, wenn die Programmiersprache Tupel direkt unterst√ºtzt oder man gewillt ist, f√ºr ein Tupel einen Datentypen zu definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T head, IEnumerable<T> tail) Split<T>(IEnumerable<T> list)\n",
    "    => (list.First(), list.Skip(1));\n",
    "\n",
    "var result = Split(new[]{2,7,9,3});\n",
    "display($\"head: {result.head}\");\n",
    "foreach(var e in result.tail) display($\"  tail element: {e}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktionen sind nat√ºrliche \"Objekte\" im Sinne von Alan Kay, weil sie f√ºr eine empfangene Nachricht - *dass* man sie aufruft und mit welchen Parametern man sie aufruft - ein Resulat herstellen, ohne zu wissen, woher sie aufgerufen wurden und wie das Resultat benutzt wird. Das PoMO wird eingehalten.\n",
    "\n",
    "##### Datenstr√∂me\n",
    "\n",
    "Allerdings k√∂nnen Funktionen f√ºr jedes eintreffende Nachricht, d.h. f√ºr jeden Aufruf, nur einmal ein Resultat herstellen (auch wenn das wom√∂glich aus mehreren Elementen besteht). Was aber, wenn Input in einen Strom von Resultaten umzuwandeln ist?\n",
    "\n",
    "Hier bricht die √úbersetzung der \"Blase\" in eine Funktion. Bei genauerem Hinsehen ist es stattdessen so, dass die Punkte, wo Pfeile auf eine Funktionseinheit treffen und wo sie sie verlassen, getrennt √ºbersetzt werden:\n",
    "\n",
    "* Ein eintreffender Pfeil wird in eine Funktion mit Parametern √ºbersetzt.\n",
    "* Ein ausgehender Pfeil wird in ein Funktionsresultat oder eine *continuation* √ºbersetzt.\n",
    "\n",
    "Ein Funktionsresultat ist dann m√∂glich, wenn nur einmal ein Output generiert wird. Andernfalls muss Output √ºber einen Funktionszeiger an die Umwelt weitergeschoben werden. Dieser Funktionszeiger muss eine *Prozedur* beschreiben (Funktion ohne R√ºckgabewert), deren Name nicht auf weitere downstream Verarbeitung des Output hindeutet, da sonst das PoMO verletzt w√ºrde.\n",
    "\n",
    "![](images/df12.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "quick"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "brown"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fox"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IEnumerable<string> SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "var words = SplitIntoWords(\"the quick brown fox\");\n",
    "foreach(var w in words) display(w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dumpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "on"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wall"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void EnumerateWords(string text, Action<string> onWord)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries).ToList()\n",
    "           .ForEach(onWord);\n",
    "\n",
    "EnumerateWords(\"humpty dumpty sat on a wall\",\n",
    "    word => display(word));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Codierung eines Output-Datenkanals mit einer continuation ist die universellere. Aber sie ist weniger intuitiv und umst√§ndlicher. Deshalb zieht Flow-Design die √úbersetzung mit Funktionsresultaten vor, wo sie offensichtlich ist oder auch machbar durch Sprachkonstrukte wie Iteratoren (z.B. `IEnumerable<>` in C#).\n",
    "\n",
    "Streams sind Mengen von einzelnen Werten. Wo sie naheliegend und n√ºtzlich im Modell sind, sollten sie angemessen in der √úbersetzung repr√§sentiert werden. Das ist mit continuations, also Funktionszeigern in vielen Programmiersprachen m√∂glich, wenn auch ein wenig gew√∂hnungsbed√ºrftig. Aber die Gew√∂hnung lohnt sich: die √úbersetzung von Modellen wird einfacher, die Testbarkeit des Codes steigt.\n",
    "\n",
    "##### Zustand\n",
    "\n",
    "Zustand bzw. Ressourcenzugriff sind Abh√§ngigkeiten einer Funktionseinheit. Sie werden als Abh√§ngigkeiten √ºbersetzt. Zustand ist dabei eine globale Variable im aggregierenden Modul einer Funktion:\n",
    "\n",
    "![](images/df13.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add 1: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 2: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 3: 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Accumulator {\n",
    "    private int _value;\n",
    "    \n",
    "    public int Add(int a) {\n",
    "        _value += a;\n",
    "        return _value;\n",
    "    }\n",
    "}\n",
    "\n",
    "var accu = new Accumulator();\n",
    "display($\"add 1: {accu.Add(1)}\");\n",
    "display($\"add 2: {accu.Add(2)}\");\n",
    "display($\"add 3: {accu.Add(3)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-dimensionale Datenfl√ºsse\n",
    "\n",
    "Einzelne Funktionsheiten werden in Modellen zu Datenfl√ºssen mehrere Funktionseinheiten zusammengesetzt. Flow-Design nennt das auch \"zusammenstecken\" oder \"verdrahten\" in Anlehnung an elektronische Schaltungen, die √ºbrigens ganz nat√ºrlich dem PoMO folgen. Aus 0-dimensionalen Modellen werden so 1-dimensionale: viele punktuelle Funktionseinheiten zusammen ergeben einen linearen Fluss.\n",
    "\n",
    "![](images/df14.png)\n",
    "\n",
    "Wenn der Output einer Funktionseinheit in der Form dem Input einer anderen entspricht, k√∂nnen beide in eine producer-consumer Beziehung gebracht werden. Sie spannen dann einen Transformationsfluss auf.\n",
    "\n",
    "Die √úbersetzung eines 1-dimensionalen Flusses ist trivial: die Funktionen der einzelnen Funktionseinheiten..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Funktionseinheiten\n",
    "int[] Map(string roman)\n",
    "    => roman.ToCharArray()\n",
    "            .Select(romanDigit => romanDigit switch {\n",
    "                        'I' => 1, 'V' => 5, 'X' => 10,\n",
    "                        'L' => 50, 'C' => 100, 'D' => 500,\n",
    "                        'M' => 1000\n",
    "                    })\n",
    "            .ToArray();\n",
    "\n",
    "int[] Negate(int[] values) {\n",
    "    var negatedValues = (int[])values.Clone();\n",
    "    for(var i=0; i<negatedValues.Length-1; i++)\n",
    "    if (negatedValues[i]<negatedValues[i+1])\n",
    "        negatedValues[i] *= -1;\n",
    "    return negatedValues;\n",
    "}\n",
    "\n",
    "int Sum(IEnumerable<int> values) {\n",
    "    var sum = 0;\n",
    "    foreach(var v in values) sum += v;\n",
    "    return sum;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ...werden schlicht nacheinander aufgerufen. Der Compiler gibt Feedback, ob die Bausteine eines Datenflusses zueinander passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XIV=14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Datenfluss\n",
    "var values = Map(\"XIV\");\n",
    "values = Negate(values);\n",
    "var decimalNumber = Sum(values);\n",
    "\n",
    "display($\"XIV={decimalNumber}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser √úbersetzung verliert das Modell des Datenflusses zwar seine Eigenschaft der grunds√§tzlichen Asynchronizit√§t seiner Transformationsschritte, doch das ist in den meisten F√§llen unerheblich. Datenfl√ºsse sind auch Datenfl√ºsse, wenn sie synchron operieren. Das Modell hat trotzdem einen hohen Wert durch seine Abstraktion.\n",
    "\n",
    "Die Funktionseinheiten, die im 1-dimensionalen Datenfluss verdrahtet werden, sind (zun√§chst) Operationen. Der Datenfluss stellt ihre Integration dar: alle einzelnen Transformationen bilden in spezifischer Weise zusammengesteckt eine gr√∂√üere Transformation.\n",
    "\n",
    "#### Datenstr√∂me\n",
    "\n",
    "Solche √úbersetzung von 1-dimensionalen Fl√ºssen als L√∂sungen von gr√∂√üeren Problemen in Form einer Abfolge von L√∂sungen kleinerer Probleme funktionieren auch f√ºr Str√∂me von Einzeldaten statt Collections.\n",
    "\n",
    "Datenstr√∂me sind n√ºtzlich, wenn...\n",
    "\n",
    "* ...die Zahl der zu erzeugenden Output-Datenelemente unbekannt und wahrscheinlich gro√ü ist. In dem Fall soll vielleicht vermieden werden, alle Datenelemente in einer Collection im Hauptspeicher zu sammeln.\n",
    "* ...die Generierung aller Output-Datenelemente erhebliche Zeit in Anspruch nimmt. In dem Fall sollen schon generierte Output-Daten schon downstream in Verarbeitung gehen, w√§hrend weitere beschafft werden.\n",
    "* ...ein Datenfluss besser zu verstehen und/oder zu √ºbersetzen ist als Strom von Einzeldaten.\n",
    "\n",
    "Als Beispiel daf√ºr mag die Traversierung eines Verzeichnisbaumes dienen, in dem Dateien eines bestimmten Typs gesucht werden, um sie zu analysieren. Zu ermitteln ist die Gesamtanzahl der Worte in relevanten Dateien.\n",
    "\n",
    "![](images/df15.png)\n",
    "\n",
    "Die Zahl der zu pr√ºfenden Dateien ist in so einem Szenario wom√∂glich schwer abzusch√§tzen und/oder die L√∂sung ist leichter \"zu denken\", wenn die Analyse sich auf einzelne Dateien konzentriert.\n",
    "\n",
    "Zuerst die √úbersetzung der Funktionseinheiten, der Bausteine des Flusses. Jede ist nur eine kleine Operation mit wenigen Zeilen Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "void EnumerateFiles(string path, Action<string> onFilename) {\n",
    "    // Die Logik hier ist aufw√§ndiger als n√∂tig aus didaktischen Gr√ºnden, um einen Output-Strom zu erzeugen.\n",
    "    var filenames = System.IO.Directory.GetFiles(path);\n",
    "    foreach(var f in filenames) {\n",
    "        onFilename(f);\n",
    "    }\n",
    "    \n",
    "    var subdirectories = System.IO.Directory.GetDirectories(path);\n",
    "    foreach(var d in subdirectories)\n",
    "        EnumerateFiles(d,\n",
    "              onFilename);\n",
    "}\n",
    "\n",
    "void FilterByEndOfFilename(string filename, string pattern, Action<string> onFilename) {\n",
    "    if (filename.EndsWith(pattern))\n",
    "        onFilename(filename);\n",
    "}\n",
    "\n",
    "string Load(string filename) \n",
    "    => System.IO.File.ReadAllText(filename);\n",
    "\n",
    "string[] SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "void Print(string filename, int numberOfWords) {\n",
    "    display($\"{filename} with {numberOfWords} words\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und dann die √úbersetzung des Flusses. Die mag ein wenig gew√∂hnungsbed√ºrftig sein in der Schachtelung der Lambda-Funktionen als continuations. Doch das verliert sich, wenn man es ein paar Mal geschrieben und gelesen hat. Der Gewinn der Gew√∂hnung liegt dann darin, eine geradlinige √úbersetzung f√ºr Datenfl√ºsse mit Str√∂men zu haben, die in jedem Schritt gut testbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-l√ºcke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 3485 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 3388 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-l√ºcke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EnumerateFiles(\"..\",\n",
    "    filename => FilterByEndOfFilename(filename, \".ipynb\",\n",
    "          filename => {\n",
    "              var text = Load(filename);\n",
    "              var words = SplitIntoWords(text);\n",
    "              Print(filename, words.Length);\n",
    "          })\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EnumerateFiles` erzeugt f√ºr eine Input-Nachricht einen Strom von Output-Nachrichten. `FilterByEndOfFilename` hingegen hat die Aufgabe, Input zu verschlucken, falls er nicht dem Filterkriterium entspricht. Das klingt sehr unterschiedlich, ist letztlich jedoch dasselbe: Der Strom dient in beiden F√§llen zur Ausgabe einer unbekannten Zahl von Elementen, das k√∂nnen 1 oder 1000 sein - oder auch gar keines.\n",
    "\n",
    "Eine Funktion, die ein Resultat mittels `return` liefert, ist gezwungen, eines zu produzieren, selbst wenn das `null` sein sollte. Eine Funktion, die ihr Resultat stattdessen √ºber eine continuation \"hinausschiebt\", kann auch entscheiden, gar kein Resultat zu liefern! Deshalb ist die √úbersetzung von Datenfluss-Funktionseinheiten in Funktionen mit continuation die universellere, wenn auch etwas aufw√§ndigere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dimensionale Datenfl√ºsse\n",
    "\n",
    "Funktionen sind in 0-dimensionalen und 1-dimensionalen Datenfl√ºssen die Container f√ºr Logik. Sie komponieren aus \"Logikbausteinen\" ein Verhalten, f√ºr das sie stehen.\n",
    "\n",
    "Obwohl 1-dimensionale Datenfl√ºsse leicht zu verstehen sind auch in der √úbersetzung in Funktionsaufrufsequenzen, skalieren sie nicht. Mehr als 5 oder vielleicht 10 Funktionseinheiten \"in einer Reihe\" oder Funktionsaufrufe nacheinander, sind aus mehreren Gr√ºnden nicht praktikabel:\n",
    "\n",
    "* Im Modell wie im Code sind so lange Sequenzen trotz ihrer formalen Einfachheit nicht mehr gut zu √ºberblicken.\n",
    "* Die Gefahr, dass Datenfl√ºsse das SLA verletzen, steigt mit jeder weiteren Funktionseinheit.\n",
    "* Die Wahrscheinlichkeit, dass es in Datenfl√ºssen Gruppen von Funktionseinheiten mit h√∂herer Koh√§sion untereinander gibt als zu anderen, steigt mit jeder weiteren Funktionseinheit.\n",
    "\n",
    "Schon zum oben stehenden Datenfluss zur Analyse von Dateien kann gefragt werden, ob er f√ºr das Verst√§ndnis eine optimale L√§nge hat.\n",
    "\n",
    "#### Integrationen als Bedeutungseinheiten\n",
    "\n",
    "Einerseits hat ein Leser bei dem 1-dimensionalen Datenfluss \"alles auf einmal im Blick\". Alle Operationen stehen in einer Reihe. Andererseits muss ein Leser sich die Bedeutung des Ganzen aus den Bedeutungen der Teile erst zusammenreimen. Das ist bei 5 Funktionseinheiten schwieriger als bei 4, 3 oder 1.\n",
    "\n",
    "Was tut der Datenfluss? Kann das mit 1 Funktionseinheit ausgedr√ºckt werden? Selbstverst√§ndlich!\n",
    "\n",
    "![](images/df16.png)\n",
    "\n",
    "Die eine Funktionseinheit integriert nun explizit die bisherigen Operationen.\n",
    "\n",
    "Oder gibt es im Datenfluss noch Teile, die wiederum unter einem Begriff zusammengefasst werden k√∂nnen, um ihnen eine eigene Bedeutung zu geben? Beispiele daf√ºr w√§ren:\n",
    "\n",
    "* Alles au√üer der Ausgabe k√∂nnte als Kernlogik zusammengefasst werden. Die Ausgabe eines Ergebnisses ist etwas ganz anderes, als das Ergebnis herzustellen. Dadurch w√ºrde die Ergebnisherstellung separat von der Benutzerschnittstelle testbar.\n",
    "* Die Beschaffung der relevanten Dateinamen k√∂nnte zusammengefasst werden. Die Traversierung des Dateisystems ist etwas ganz anderes, als mit einer Datei umzugehen.\n",
    "* Laden und Zerlegen einer Datei k√∂nnte zusammengefasst werden. Eine Datei als Text zu beschaffen, statt als Byteblock, ist schon eine Abstraktion, die der .NET Framework zur Verf√ºgung stellt. Warum nicht den Dateizugriff weiter abstrahieren und eine Datei als Collection von Worten repr√§sentieren?\n",
    "\n",
    "Wie man sich entscheidet bei den Zusammenfassungen, ist weniger wichtig, als dass Zusammenfassungen zur Verbesserung der Verst√§ndlichkeit und der Testbarkeit m√∂glich und einfach sind. Die eine beste Zusammenfassung wird es wohl nicht geben. Da Integrationen von Teilfl√ºssen jedoch billig herzustellen und auch wieder aufzul√∂sen sind, kann die Integrationshierarchie jederzeit umgestellt werden.\n",
    "\n",
    "Verst√§ndnis ver√§ndert sich mit der Zeit: Es wird aufgebaut durch Besch√§ftigung mit Code - aber es wird auch wieder abgebaut, wenn die Besch√§ftigung abnimmt. Eine Struktur, die dem heutigen Verst√§ndnis angemessen ist, passt wom√∂glich nicht mehr optimal zum morgigen Verst√§ndnis.\n",
    "\n",
    "In dieser Hinsicht unterliegen Modelle und Code trotz ihrer Immaterialit√§t einem Verschlei√ü. Ohne, dass Code \"sich bewegte\" oder ver√§ndert w√ºrde, verliert er an \"Verst√§ndlichkeitsqualit√§t\". Das hat zwei Konsequenzen:\n",
    "\n",
    "* Die Diskussion um die allerbeste Struktur sollte begrenzt werden. Die allerbeste Struktur, selbst wenn sie f√ºr heute gefunden werden k√∂nnte, ist morgen nicht mehr die allerbeste. Nach dem Herstellungszeitpunkt verliert jede auf Verst√§ndlichkeit getrimmte Struktur sofort und automatisch an Wert. Warum also bis aufs Letzte optimieren?\n",
    "* Strukturen f√ºr Verst√§ndlichkeit sollten gewartet werden. D.h. sie sollten proaktiv in angemessenen Wartungsinverallen aufgesucht und dem aktuellen Verst√§ndnisstand angepasst werden. Sonst besteht die Gefahr, dass sie zur Unzeit als stark erodiert erfahren werden und viel M√ºhe beim Verst√§ndnis machen.\n",
    "\n",
    "Die obigen Fragen zu m√∂glichen Integrationen sind daher nur Beispiele daf√ºr, dass und wie m√∂glichen Verst√§ndlichkeitsverbesserungen nachgesp√ºrt werden kann. Nach angemessenem Diskurs muss eine Entscheidung getroffen werden. Die k√∂nnte z.B. so aussehen:\n",
    "\n",
    "![](images/df17.png)\n",
    "\n",
    "Ein Datenflussmodell dehnt sich damit sichtbar in 2 Dimensionen aus:\n",
    "\n",
    "* In der ersten Dimension wird Verhalten im Datenfluss erzeugt: am Anfang einflie√üerder Input wird schrittweise in am Ende ausflie√üenden Output transformiert.\n",
    "* In der zweiten Dimension findet Abstraktion durch Komposition statt. Kompositionen - Operation wie Integration - fassen verschiedene Teilverhalten zu einem gr√∂√üeren, neuen Gesamtverhalten zusammen. Komposition ist die Abstraktion, die Bequemlichkeit in der Nutzung herstellt.\n",
    "\n",
    "Kompositionen √§ndern am Verhalten nat√ºrlich nichts. Das Verhalten wird immer nur durch Logik (und Verteilung) beeinflusst. Aber Kompositionen √§ndern an der Verst√§ndlichkeit etwas. Deshalb ist auch der Einwand, dass in einer Integrationshierarchie Operationen und Integrationen wom√∂glich nur einmal verwendet werden, unerheblich. Wenn eine Komposition der Verst√§ndlichkeit oder Testbarkeit dient, dann muss sie nicht gleichzeitig der kurzfristigen Produktivit√§t dienen. Das ist n√§mlich der Zweck von Wiederverwendung.\n",
    "\n",
    "#### √úbersetzung\n",
    "\n",
    "Sind Integrationen f√ºr einen Fluss gefunden, lassen sie sich leicht √ºbersetzen: wie Operationen werden sie zu Funktionen. Das ist einerseits sehr n√ºtzlich und intuitiv. Andererseits hat es aber auch einen Nachteil.\n",
    "\n",
    "Integrationen in Funktionen zu √ºbersetzen, liegt nahe, weil die Darstellung im Modell sich nicht von Operationen unterscheidet. Auch weil w√§hrend des Modellierungsprozesses nicht klar ist, ob Bl√§tter in einer Integrationshierarchie Operationen bleiben oder weiter verfeinert werden, d.h. \"in Integrationen umklappen\", w√§re eine unterschiedliche Darstellung bzw. Codierung hinderlich.\n",
    "\n",
    "Andererseits verf√ºhrt die √úbersetzung von Integrationen in Funktionen dazu, Logik in sie \"hineinzuschmuggeln\". Das w√ºrde dem IOSP widersprechen und mindestens die Testbarkeit senken.\n",
    "\n",
    "Letztlich √ºberwiegt jedoch f√ºr Flow-Design die Einfachheit. Integrationen werden also zu Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-l√ºcke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 4778 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 4776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-l√ºcke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void PrintWordsInFiles(string path, string pattern) {\n",
    "    CountWordsInFiles(path, pattern,\n",
    "        Print);\n",
    "}\n",
    "\n",
    "void CountWordsInFiles(string path, string pattern, Action<string,int> onFile) {\n",
    "    EnumerateRelevantFiles(path, pattern,\n",
    "        filename => {\n",
    "            var words = LoadWordsFromFile(filename);\n",
    "            onFile(filename, words.Length);\n",
    "        });\n",
    "}\n",
    "\n",
    "void EnumerateRelevantFiles(string path, string pattern, Action<string> onFilename) {\n",
    "    EnumerateFiles(\"..\",\n",
    "        filename => FilterByEndOfFilename(filename, pattern,\n",
    "                      onFilename));\n",
    "}\n",
    "\n",
    "string[] LoadWordsFromFile(string filename) {\n",
    "    var text = Load(filename);\n",
    "    return SplitIntoWords(text);\n",
    "}\n",
    "\n",
    "\n",
    "PrintWordsInFiles(\"..\", \".ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jo-Jo Modellierung\n",
    "\n",
    "Im Flow-Design beginnt die Modellierung der L√∂sung eines Problem au√üen und beim Gesamtverhalten. Von dort setzt sich durch Zerlegung von gr√∂√üeren in kleinere Probleme nach innen fort. Sie ist verhaltensorientiert und schrittweise verfeinernd, d.h. rekursiv absteigend: Am Anfang steht eine Funktionseinheit als vorl√§ufige Operation. Deren Transformation wird dann jedoch zerlegt in Schritte, die durch n√§chste vorl√§ufige Operationen in einem Fluss vollst√§ndig geleistet wird, so dass die vorherige Funktionseinheit zu einer Integration wird. Und immer so weiter f√ºr jedes Blatt im 2-dimensionalen Datenflussbaum - bis man am Ende nicht mehr wei√ü, wie eine vorl√§ufige Operation weiter zerlegt werden soll. Dann wird aus der vorl√§ufigen Operation eine endg√ºltige.\n",
    "\n",
    "Zumindest verl√§uft die Modellierung des Verhaltens idealerweise so. In der Praxis jedoch zeigt sich, dass nicht immer outside-in, top-down eine L√∂sung erkannt wird. Manchmal steht schon am Anfang ein sp√§tere Operation fest und die wird schrittweise an die Wurzel-Funktionseinheit bottom-up angebunden. Oder nach einem ersten Durchstich von der Wurzel bis zu den Operationen scheint es verst√§ndlichkeitsf√∂rdernd, weitere Integrationsebenen einzuziehen. Oder Kind-Knoten im Kompositionsbaum, die unter verschiedenen Eltern-Knoten h√§ngen, werden horizontal verschoben.\n",
    "\n",
    "![](images/df18.png)\n",
    "\n",
    "Flow-Design ist insofern weder strickt top-down, noch bottom-up, sondern geht in beide Richtungen vor oder schwingt auch mal seitw√§rts. Das passende Bild f√ºr ihre Bewegungsrichtung ist mithin ein Jo-Jo: der geht immer wieder runter und hoch oder bricht auch mal aus und kommt am Ende zur Ruhe. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logik in der Integration\n",
    "\n",
    "Das IOSP ist glasklar: Eine Funktionseinheit ist entweder Operation und steht f√ºr Verhaltenserzeugung durch Logik. Oder sie ist eine Integration und stellt nur einen Fluss zwischen anderen Funktionseinheiten her, wof√ºr keine Logik n√∂tig ist.\n",
    "\n",
    "Damit formuliert das Prinzip ein Soll, ein Ideal. Und dieses Ideal kann technisch auch immer implementiert werden.\n",
    "\n",
    "Allerdings ist es eben ein Ideal. Das bedeutet, in seiner Reinheit kann es anderen Zielen auch mal im Wege stehen.\n",
    "\n",
    "Flow-Design sieht dieses und andere Prinzipien daher pragmatisch. Ja, es soll stets das Ideal im Sinne von Korrektheit und Evolvierbarkeit angestrebt werden. Dabei soll aber auch Augenma√ü bewahrt werden. IOSP, PoMO usw. f√ºr langfristig hohe Produktivit√§t sind auszubalancieren mit Ma√ünahmen f√ºr funktionale und nicht-funktionale Qualit√§ten.\n",
    "\n",
    "F√ºr Flow-Design sind deshalb gelegentliche \"Spuren von Logik\" in eigentlich integrierenden Funktionseinheiten akzeptabel. Nicht w√ºnschenswert, aber ok - wenn man denn wei√ü, was man da tut.\n",
    "\n",
    "Meistens handelt es sich bei diesen Logik-Einsprengseln um Kontrollstrukturen oder triviale selbsterkl√§rende API-Aufrufe.\n",
    "\n",
    "Als Beispiel mag nochmal die obige Dateianalyse dienen. Mit der Erlaubnis zu etwas Logik in der Integration k√∂nnte die √úbersetzung anders aussehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-l√ºcke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 124 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 5776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 5776 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-l√ºcke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 124 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Schmutzige Integration\n",
    "void PrintWordsInFiles_v2(string path, string pattern) {\n",
    "    foreach(var r in CountWordsInFiles_v2(path, pattern)) // Kontrollstrukturüò±\n",
    "        Print(r.filename, r.numberOfWords);\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "IEnumerable<(string filename, int numberOfWords)> CountWordsInFiles_v2(string path, string pattern) {\n",
    "    foreach(var f in EnumerateRelevantFiles_v2(path, pattern)) { // Kontrollstrukturüò±\n",
    "        var words = LoadWordsFromFile_v2(f);\n",
    "        yield return (f, words.Length);\n",
    "    };\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "IEnumerable<string> EnumerateRelevantFiles_v2(string path, string pattern) {\n",
    "    foreach(var f in EnumerateFiles_v2(path)) // Kontrollstrukturüò±\n",
    "        if (IsRelevantFile(f, pattern)) // Kontrollstrukturüò±\n",
    "            yield return f;\n",
    "}\n",
    "\n",
    "// Schmutzige Integration\n",
    "string[] LoadWordsFromFile_v2(string filename) {\n",
    "    var text = System.IO.File.ReadAllText(filename); // API-Aufrufüò±\n",
    "    return SplitIntoWords(text);\n",
    "}\n",
    "\n",
    "\n",
    "// Ge√§nderte Operation f√ºr den Aufruf in einer schmutzigen Integration\n",
    "IEnumerable<string> EnumerateFiles_v2(string path) {\n",
    "    // Die Logik hier ist aufw√§ndiger als n√∂tig aus didaktischen Gr√ºnden, um einen Output-Strom zu erzeugen.\n",
    "    var filenames = System.IO.Directory.GetFiles(path);\n",
    "    foreach(var f in filenames) {\n",
    "        yield return f; // Statt √ºber eine Continuation wird ein Strom jetzt mittel Iterator erzeugtü§î\n",
    "    }\n",
    "    \n",
    "    var subdirectories = System.IO.Directory.GetDirectories(path);\n",
    "    foreach(var d in subdirectories)\n",
    "        foreach(var f in EnumerateFiles_v2(d))\n",
    "            yield return f; //ü§î\n",
    "}\n",
    "\n",
    "// Ge√§nderte Operation f√ºr den Aufruf in einer schmutzigen Integration\n",
    "bool IsRelevantFile(string filename, string pattern)\n",
    "    => filename.EndsWith(pattern);\n",
    "\n",
    "\n",
    "PrintWordsInFiles_v2(\"..\", \".ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In jeder einzelnen Methode h√§lt sich die Unsauberkeit in Bezug auf das IOSP in Grenzen. Die Methoden bleiben auch klein. Solange beides gegeben ist, steht aus Sicht von Flow-Design ein wenig \"Schmutz\" nichts entgegen. Wichtiger als die absolute Befolgung des Prinzips sind die Qualit√§ten, die es bef√∂rdert, hier: **Verst√§ndlichkeit und Testbarkeit. Solange diese Qualit√§ten auch trotz (oder wegen?) gewisser Unsauberkeit vorhanden sind, ist etwas Logik in einer Integrationsfunktion ok.**\n",
    "\n",
    "[Solche \"Schmutzreste\"](https://ccd-school.de/2017/02/kontrollstrukturen-in-der-integration/) sind vor allem simple Schleifen, auch mal eine Fallunterscheidung oder ein trivialer API-Aufruf. **Wichtig ist, dass diese Logik so einfach ist, dass sie selbst nicht getestet werden muss.** Das ist z.B. hier der Fall:\n",
    "\n",
    "```csharp\n",
    "if (IsRelevantFile(f, pattern))\n",
    "    yield return f;\n",
    "```\n",
    "\n",
    "Die `if`-Anweisung selbst kann nicht falsch geschrieben werden; der Compiler w√ºrde das beanstanden. Die eigentliche Logik steckt in der Funktion `IsRelevantFile`, zu der nun eine funktionale Abh√§ngigkeit besteht. Diese Logik ist durch die Auslagerung jedoch leicht testbar.\n",
    "\n",
    "Wenn ein `if` in solcher Weise zur Lesbarkeit einer Integration beitr√§gt... Warum dann darauf verzichten? Flow-Design will mit seinen Prinzipien leiten, aber nicht darauf reiten.\n",
    "\n",
    "√Ñhnlich sieht es f√ºr `foreach` aus, mit dem der Code auf Continuations verzichten kann, weil C# mit `yield return` es erlaubt, sehr einfach Iteratoren nach und nach mit Elementen zu f√ºllen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Offen f√ºr Erweiterung, geschlossen f√ºr Ver√§nderung\n",
    "\n",
    "Die Vorteile der Einhaltung von IOSP und PoMO liegen zun√§chst sichtbar in gr√∂√üerer Verst√§ndlichkeit und besserer Testbarkeit von Code. Logik wird ganz nat√ºrlich in kleine Einheiten \"gezwungen\". Flow-Design verzichtet ganz bewusst auf die M√∂glichkeit funktionaler Abh√§ngigkeiten, um Produktivit√§tsqualit√§ten verl√§sslicher herzustellen. [Functional dependencies considered harmful!](https://ralfw.de/2019/07/functional-dependencies-considered-harmful/) Freiwillige Selbstbeschr√§nkung beim Schreiben von Code f√∂rdert das sp√§tere und h√§ufigere Lesen und Ver√§ndern von Code.\n",
    "\n",
    "Der positive Effekt des IOSP entstammt zun√§chst einer Zuspitzung des SRP: Integration und Operation sind formale Verantwortlichkeiten. W√§hrend √ºblicherweise das SRP inhaltlich bzw. auf das Verhalten angewandt wird, konzentriert sich das IOSP auf die Struktur von Code. Deshalb kann die Einhaltung des IOSP auch leicht √ºberpr√ºft werden, selbst wenn ein Leser mit einer Programmiersprache oder dem angestrebten Verhalten oder der Dom√§ne nur wenig vertraut ist.\n",
    "\n",
    "Weiterhin bef√∂rdert das IOSP die Einhaltung des SLA. Wenn Funktionen keine funktionalene Abh√§ngigkeiten enthalten, dann liegt das, was sie zusammenfassen (Komposition) im Abstraktionsgrad n√§her beieinander.\n",
    "\n",
    "Und schlie√ülich kann man das PoMO als eine Steigerung des *Interface Segregation Principle (ISP)* auffassen. Denn wenn downstream Konsumenten upstream Produzenten √ºber einen Funktionszeiger (continuation) bekannt gemacht werden, dann entspricht das einer Abh√§ngigkeit von einem Interface mit nur einer Methode. Es findet eine Funktionsinjektion in eine Funktion im Bedarfsfall statt.\n",
    "\n",
    "Damit aber nicht genug! IOSP und PoMO sind auch ganz im Sinne des *(Polymorphic) Open/Closed Principle (OCP)*! [Robert C. Martin definiert das](https://drive.google.com/file/d/0BwhCYaYDn8EgN2M5MTkwM2EtNWFkZC00ZTI3LWFjZTUtNTFhZGZiYmUzODc1/view) wie folgt:\n",
    "\n",
    "> Modules that conform to the open-closed principle have two primary attributes.\n",
    "> 1. They are ‚ÄúOpen For Extension‚Äù. This means that the behavior of the module can be extended. That we can make the module behave in new and different ways as the requirements of the application change, or to meet the needs of new applications.\n",
    "> 2. They are ‚ÄúClosed for Modification‚Äù. The source code of such a module is inviolate. No one is allowed to make source code changes to it.\n",
    "\n",
    "Flow-Design √ºbersetzt \"module\" dabei allerdings in \"Funktionseinheit\" bzw. \"Funktion\" als eigentlich Verhalten erzeugende Strukturbestandteile. Und Flow-Design konkretisiert, was denn nicht ver√§ndert werden sollte: Logik. Logik ist schwer zu verstehen und schwer zu testen. Daher sollte man die Finger davon lassen, sobald sie einmal tut, was sie soll. Ver√§nderungen f√ºr neues Verhalten sollten nicht durch Ver√§nderung (modification) von Logik hergestellt werden - sondern durch neue, separate Logik (extension).\n",
    "\n",
    "Dem leistet Flow-Design Vorschub durch den Verzicht auf funktionale Abh√§ngigkeiten. Operationen sieht Flow-Design als geschlossen an; ihre Logik sollte soweit m√∂glich nicht angetastet werden. Integrationen hingegen sind f√ºr Flow-Design offen. In Integrationen k√∂nnen Erweiterungen des Verhaltens leicht \"zwischengeschaltet\" werden.\n",
    "\n",
    "Zun√§chst ein Szenario ohne IOSP: die Umwandlung r√∂mischer Zahlen in dezimale noch ohne Ber√ºcksichtigung der Subtraktionsregel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman(string romanNumber) {\n",
    "    var decimalNumber = 0;\n",
    "    for(var i=0; i<romanNumber.Length; i++) {\n",
    "        switch(romanNumber[i]) {\n",
    "            case 'I': decimalNumber += 1; break;\n",
    "            case 'V': decimalNumber += 5; break;\n",
    "            case 'X': decimalNumber += 10; break;\n",
    "            // ...\n",
    "        }\n",
    "    }\n",
    "    return decimalNumber;\n",
    "}\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman(\"XVI\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was tun, um auch die Anforderungen der Subtraktionsregel zu erf√ºllen? Die Logik von `FromRoman` muss *ver√§ndert* werden! Das ist riskant/schwierig.\n",
    "\n",
    "Anders liegt der Fall, wenn eine L√∂sung - auch wenn sie klein ist - sauber modelliert und mit IOSP im Kopf √ºbersetzt wird. Sie s√§he dann z.B. so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XIV=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman_OCP(string romanNumber) {\n",
    "    var digitValues = Map(romanNumber);\n",
    "    return digitValues.Sum();\n",
    "}\n",
    "\n",
    "int[] Map(string romanNumber)\n",
    "    => romanNumber.ToCharArray().Select(Map).ToArray();\n",
    "int Map(char romanDigit) => romanDigit switch {\n",
    "    'I' => 1,\n",
    "    'V' => 5,\n",
    "    'X' => 10\n",
    "    // ...\n",
    "};\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman_OCP(\"XVI\")}\");\n",
    "display($\"XIV={FromRoman_OCP(\"XIV\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch leistet die L√∂sung nicht, was sie soll. Doch ohne Ver√§nderung einer Operation - `Map`, `Sum` - kann das ge√§ndert werden mit einer Erweiterung der Integration. Deren Extension besteht im \"Dazwischenschieben\" eines weiteren Funktionsaufrufs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XVI=16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "XIV=14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "int FromRoman_OCP_extended(string romanNumber) {\n",
    "    var digitValues = Map(romanNumber);\n",
    "    digitValues = Negate(digitValues); // Erweiterungü§©\n",
    "    return digitValues.Sum();\n",
    "}\n",
    "\n",
    "// Neue Logik, statt ver√§nderterü•≥\n",
    "int[] Negate(IEnumerable<int> digitValues) {\n",
    "    var negated = digitValues.ToArray();\n",
    "    for(var i=0; i<negated.Length-1; i++)\n",
    "        if (negated[i]<negated[i+1])\n",
    "            negated[i] *= -1;\n",
    "    return negated;\n",
    "}\n",
    "\n",
    "\n",
    "display($\"XVI={FromRoman_OCP_extended(\"XVI\")}\");\n",
    "display($\"XIV={FromRoman_OCP_extended(\"XIV\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durch die Trennung von Integration und Operation reduziert Flow-Design den Aufwand, um dem OCP zu dienen. Erweiterbarkeit ist ein grundlegendes Merkmal von Integrationen. Dass man daf√ºr Code im Fluss der Verhaltensherstellung anfassen muss, ist unerheblich. Das Risiko f√ºr Schaden (Regression) dadurch ist vergleichsweise klein. Wahrhaft risikoreiche Ver√§nderungen an Logik sind auf sehr √ºberschaubare Operationen begrenzt.\n",
    "\n",
    "Die erste Frage beim Modellieren eines L√∂sungsansatzes f√ºr neues Verhalten lautet im Flow-Design: Kann das neue Verhalten hergestellt werden, in den lediglich Funktionseinheiten in einem Datenfluss zwischen andere gesetzt werden? √ñfter als man denkt, kann darauf mit Ja geantwortet werden. (Und wenn nicht, kann das als Anlass genommen werden, den bisherigen L√∂sungsansatz nocheinmal zu √ºberdenken, um ihn mittels IOSP n√§her ans OCP zu bringen.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stratified Design\n",
    "\n",
    "Dem Verst√§ndnis eines Systems ist zutr√§glich, wenn man es aus unterschiedlicher Entfernung betrachten kann. Ist man n√§her dran, kann man Details untersuchen. Ist man weiter weg, gewinnt man √úberblick √ºber den Zusammenhang von Teilen.\n",
    "\n",
    "Geografische Karten erlauben uns, in solcher Weise mit einem Terrain umzugehen. Wir ziehen sie z.B. zur Planung einer Reise in unterschiedlichem Ma√üstab heran. Eine Karte mit gro√üem Ma√üstab, z.B. eine Europa-Karte, gibt uns √úberblick f√ºr eine grobe Routenplanung. Eine topografische Karte hingegen zeigt uns eine eng begrenzte Umgebung mit viel mehr Einzelheiten. Werkzeuge wie Google Maps machen heute den Wechsel des Ma√üstabs besonders einfach.\n",
    "\n",
    "F√ºr das Studium von Code ist es ebenfalls n√ºtzlich, den Ma√üstab seiner Darstellung wechseln zu k√∂nnen. Das Ganze sollte grob und im √úberblick betrachtet werden k√∂nnen; genauso sollte es m√∂glich sein, schrittweise hinein zu zoomen, um mehr und mehr Details zu sehen.\n",
    "\n",
    "Gro√üe Ma√üst√§be stehen f√ºr ein hohes Abstraktionsniveau, kleine Ma√üst√§be f√ºr ein niedriges. Um hinein und heraus zoomen zu k√∂nnen, muss Code also unterschiedliche Abstraktionsniveaus aufweisen.\n",
    "\n",
    "Tut er das z.B., wenn er nach dem weit verbreiteten Schichtenmodell strukturiert ist?\n",
    "\n",
    "Als Beispiel ein kleines Programm, dass die Worte in einer Datei z√§hlt. Es besteht aus drei typischen Schichten:\n",
    "\n",
    "* Presentationsschicht/Benutzerschnittstelle: Beschafft den Namen der zu verarbeitenden Datei aus der Umgebung und gibt das Ergebnis aus, das es von der Gesch√§ftslogik bekommt.\n",
    "* Gesch√§ftslogikschicht: Ermittelt das Ergebnis, nachdem es von der Datenzugriffschicht den Dateiinhalt bekommen hat.\n",
    "* Datenzugriffsschicht: L√§dt den Inhalt einer Datei.\n",
    "\n",
    "/// schichtenmodell f√ºr das beispiel (erstmal nur klassennamen) (100)\n",
    "\n",
    "Funktionale Abh√§ngigkeiten zeigen hier grunds√§tzlich √ºber die Schichten hinweg von oben nach unten. Ob das kaschiert wird mit DIP/IoC, ist unwesentlich. Und auch Schalen statt Schichten, wie in der Clean Architecture, machen keinen Unterschied. So oder so sind die Aspekte funktional voneinander abh√§ngig zur Laufzeit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class Presentation {\n",
    "    public static void CountWords(string filename) {\n",
    "        var numberOfWords = Business.CountWords(filename);\n",
    "        Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business {\n",
    "    public static int CountWords(string filename) {\n",
    "        var words = Dataaccess.Load(filename);\n",
    "        var significantWords = words.Where(w => w.Length > 2);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "class Dataaccess {\n",
    "    public static IEnumerable<string> Load(string filename) {\n",
    "        var text = System.IO.File.ReadAllText(filename);\n",
    "        return text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "Presentation.CountWords(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Code ist das Terrain. Das Schichtenmodell ist eine Karte f√ºr dieses Terrain. Sie abstrahiert von den Details der Logik und sogar von den einzelnen Methoden. Das ist durchaus n√ºtzlich. Und das ganze Programm mit einem Betriebssystemprozess als Host abstrahiert sogar noch von den Klassen als Feinheiten der Implementation.\n",
    "\n",
    "/// softwarezelle -* schichtenmodell -* code(101)\n",
    "\n",
    "##### Abh√§ngigkeiten definieren das Abstraktionsgef√§lle\n",
    "\n",
    "Aus diesem Bild wird ersichtlich, wie Abstraktion und Abh√§ngigkeit in Zusammenhang stehen: Abstraktion definiert einen Baum. Dessen Wurzel ist das Abstraktum, seine Bl√§tter sind die Details, von denen damit abgesehen wird.\n",
    "\n",
    "/// abstraktionsbaum mit abh√§ngigkeiten; beispiel vllt mit \"Geb√§ude\" und dann \"Wohnhaus\", \"Hochhaus\", \"Kirche\" (102)\n",
    "\n",
    "Das Abstrakte *besteht* aus dem Konkreten. Das Abstrakte ist somit vom Detail *abh√§ngig*, das in ihm unter einem Gesichtspunkt zusammengefasst ist. Die Abh√§ngigkeitsbeziehung weist vom Abstrakten zum Konkreten. In Richtung von Abh√§ngigkeiten f√§llt mithin das Abstraktionsniveau.\n",
    "\n",
    "##### Abstraktionen im Flow-Design\n",
    "\n",
    "Flow-Design ist vor allem mit Abstraktionen nach zwei Gesichtspunkten besch√§ftigt:\n",
    "\n",
    "* Aggregation: Zusammenfassen von *√Ñhnlichem*; das, was gemeinsam ist, definiert die Abstraktion.\n",
    "* Komposition: Zusammenfassen von *Verschiedenem*; das Neue, das durch die gegenseitige Erg√§nzung des Verschiedenen entsteht, macht die Abstraktion aus.\n",
    "\n",
    "/// abstraktionsb√§ume f√ºr aggregation (irgendwas gemeinsames wird rausgezogen) und komposition (irgendwas neues entsteht) (103)\n",
    "\n",
    "Das Mittel zur Aggregation sind Module. Das Mittel zur Komposition sind Integration und Operation.\n",
    "\n",
    "Aggregation erzeugt √úberblick durch Ausblenden der Verschiedenartigkeit von Konkretem. Komposition erzeugt Neues durch Verschmelzen der Verschiedenartigkeit von Konkretem.\n",
    "\n",
    "##### Fehlende Abstraktionen bei funktionaler Abh√§ngigkeit\n",
    "\n",
    "Vor diesem Hintergrund wird deutlich, dass Code, der nach dem Schichtenmodell strukturiert ist, Abh√§ngigkeiten falsch im Sinne von Abstraktion einsetzt.\n",
    "\n",
    "`Presentation.CountWords` als Wurzel des Abh√§ngigkeitsbaums kann noch als Repr√§sentant des Ganzen auf h√∂chster Abstraktionsebene angesehen werden; immerhin geht es um das Z√§hlen von Worten in einer Datei.\n",
    "\n",
    "Aber wie steht es mit `Business.CountWords`? Liegt die Methode auf einem niedrigeren Abstraktionsniveau? Tut sie dasselbe, wie die von ihr abh√§ngige, nur eben konkreter? Ja, vielleicht k√∂nnte man das noch zugestehen. Es ja immerhin wieder um das Z√§hlen von Worten in einer Datei; dieses Mal wird deren Zahl als Ergebnis geliefert, statt auf dem Bildschirm ausgegeben.\n",
    "\n",
    "Und schlie√ülich `Dataaccess.Load`: Ist damit die Probleml√∂sung auf einem niedrigeren Abstraktionsniveau beschrieben? Nein. Hier geht es nicht mehr ums Z√§hlen. Das ist deutlich sichtbar. Sp√§testens bei der Abh√§ngigkeit der Gesch√§ftslogik von der Datenzugriffslogik wird das Prinzip verletzt, dass Abh√§ngigkeiten vom Abstrakten auf das Konkrete verweisen sollen.\n",
    "\n",
    "Abstraktionsniveaus sind dadurch gekennzeichnet, dass auf einem bestimmten Niveau jeweils das Ganze zu sehen ist, nur eben in einem gewissen Detaillierungsgrad. Das ist offensichtlich bei `Dataaccess.Load` nicht der Fall und schon bei `Business.CountWords` wackelt das Bild.\n",
    "\n",
    "Die Abh√§ngigkeiten zwischen Methoden in einem Schichtenmodell beschreiben also keinen Abstraktionsbaum. Doch wie steht es mit dem Klassenbaum? Liegt eine `Presentation`-Klasse auf einem h√∂heren Abstraktionsniveau als eine `Business`- oder `Dataaccess`-Klasse? Tut `Presentation` das in Aggregation, was `Business` oder `Dataccess` tun? Hier antwortet Flow-Design ebenfalls mit Nein.\n",
    "\n",
    "Eine Gesch√§ftslogik ist nicht dasselbe wie Datenzugriffslogik, nur eben auf einem anderen Abstraktionsniveau.\n",
    "\n",
    "##### Dark Logic\n",
    "\n",
    "Der Grund f√ºr diese \"Missweisung\" der Abh√§ngigkeiten ist ihre funktionale Natur. B√§ume funktionaler Abh√§ngigkeiten enthalten *dark logic*, d.h. Logik, die Verhaltensrelevant ist, aber nicht im Modell repr√§sentiert. Das wird deutlich bei einer Darstellung des L√∂sungsansatzes f√ºr die Wortz√§hlung als Datenflussdiagramm:\n",
    "\n",
    "/// datenfluss f√ºr wortz√§hlung (103)\n",
    "\n",
    "Der Input von `Business.CountWords` passt noch zum Input von `Presentation.CoundWords`, aber der Output passt nicht. Was passiert mit der hinausflie√üenden Zahl der Worte? Genauso bei `Business.CoundWords` und `Dataaccess.Load`: Wie wird aus einer collection von Strings eine Zahl?\n",
    "\n",
    "Beides ist nur zu erkl√§ren mit dark logic: In der abh√§ngigen, integrierenden Funktionseinheit muss noch Logik stecken. Diese Logik widerspricht dem SLA:\n",
    "\n",
    "```csharp\n",
    "public static int CountWords(string filename) {\n",
    "    var words = Dataaccess.Load(filename);\n",
    "    var significantWords = words.Where(w => w.Length > 2);\n",
    "    return significantWords.Count();\n",
    "}\n",
    "```\n",
    "\n",
    "`Dataaccess.Load` liegt auf einem h√∂heren Abstraktionsniveau als die folgenden Zeilen, weil die Methode selbst Logik zu einer neuen Funktionalit√§t komponiert.\n",
    "\n",
    "Laut IOSP kann das jedoch nicht sein.\n",
    "\n",
    "Dark logic ist es, die Code schwer zu verstehen und schwer zu testen macht. Abh√§ngigkeitsdiagrammen von Funktionen, die *funktional* abh√§ngig sind, fehlt wesentliche Information, um zu verstehen, wie Verhalten hergestellt wird. Nicht, dass Logik explizit gezeigt werden m√ºsste; damit w√ºrde der Abstraktionszweck gebrochen. Aber Logik muss explizit repr√§sentiert werden.\n",
    "\n",
    "Das ist, wozu die Einhaltung des IOSP f√ºhrt. Das IOSP macht dark logic sichtbar.\n",
    "\n",
    "##### Stratified Design\n",
    "\n",
    "Software strukturiert nach IOSP besteht nicht aus Schichten, sondern *Strata*. Jedes Stratum definiert dabei ein Abstraktionsniveau.\n",
    "\n",
    "> \"\\[...\\] expert engineers stratify complex designs. Each level is constructed as a stylized combination of interchangeable parts that are regarded as primitive at that level. The parts constructed at each level are used as primitives at the next level. Each level of a stratified design may be thought of as a specialized language with a variety of primitives and means of combination appropriate to that level of detail.\", Abelson & Sussman in \"Lisp: A Language for Stratified Design\"\n",
    "\n",
    "Das Schichtenmodell (oder auch eine Clean Architecture) sind keine Repr√§sentaten von *stratified design*. L√∂sungen existieren dort nicht auf unterschiedlichen Abstraktionsniveaus, weil Schichten/Schalten funktional von einander abh√§ngig sind.\n",
    "\n",
    "Anders jedoch im Flow-Design. Hier ein Datenfluss-Modell f√ºr das Wortz√§hlungsproblem:\n",
    "\n",
    "/// datenfluss f√ºr das wortz√§hlungsproblem (104)\n",
    "\n",
    "In diesem Modell existiert keine dark logic mehr. Die L√∂sung wird auf in zwei Strata komplett beschrieben:\n",
    "\n",
    "/// zwei strata f√ºr das wortz√§hlungsproblem: nur die wurzel / nur der flow (105)\n",
    "\n",
    "Die gesamte Logik ist in Operationen verpackt.\n",
    "\n",
    "Das h√∂chste Abstraktionsniveau wurde durch das IOSP explizit eingef√ºhrt: die Klasse `CountWords` mit der Methode `Run`, die beide f√ºr Integration stehen. `CountWords` integriert die Aspekt-Klassen `Presentation`, `Business` und `Dataaccess`. `Run` integriert deren Methoden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class CountWords {\n",
    "    public static void Run(string filename) {\n",
    "        var words = Dataaccess.Load(filename);\n",
    "        var numberOfWords = Business_Stratified.CountWords(words);\n",
    "        Presentation_Stratified.DisplayResult(filename, numberOfWords);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "class Presentation_Stratified {\n",
    "    public static void DisplayResult(string filename, int numberOfWords) {\n",
    "        Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business_Stratified {\n",
    "    public static int CountWords(IEnumerable<string> words) {\n",
    "        var significantWords = words.Where(w => w.Length > 2);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "CountWords.Run(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was vorher funktional abh√§ngig war, steht jetzt in einer Sequenz im Datenfluss in `Run`. So ist es richtig, wenn es keine Unterschiede im Abstraktionsniveau gibt.\n",
    "\n",
    "Im Beispiel macht die Gesch√§ftslogik klar, wieviel plausibler das ist. Sie ist jetzt nicht mehr abh√§ngig vom Datenzugriff. Warum sollte sie das auch sein? Welchen Grund gibt es, dass Dom√§nenlogik sich Daten aus einer Ressource beschaffen sollte? Warum sollte Dom√§nenlogik Kenntnis von einer Ressource haben?\n",
    "\n",
    "Das Schichtenmodell erkl√§rt das nicht. Die Clean Architecture erkl√§rt das auch nicht, obwohl auch dort zur Laufzeit (!) noch innere Schalen √§u√üere aufrufen.\n",
    "\n",
    "Um den Kern einer Software wirklich von der Umwelt zu isolieren, darf es keine funktionalen Abh√§ngigkeiten zwischen ihm und der Umwelt gehen. Funktionale Abh√§ngigkeiten sind schlicht ein Widerspruch zum SLA. Mit ihnen w√ºrde die Gesch√§ftslogik auf ein h√∂heres Abstraktionsniveau gehoben als der Datenzugriff. Dort hat sie jedoch nichts zu suchen. Gesch√§ftslogik ist nicht abstrakter als Datenzugriffslogik. Vielleicht ist sie zentraler, wichtiger, aber nicht abstrakter.\n",
    "\n",
    "##### Strata verstanden als Sprachen\n",
    "\n",
    "Die L√∂sung wird mit drei Sprache beschrieben:\n",
    "\n",
    "* Die h√∂chste Sprache besteht nur aus einem Wort: `Run`.\n",
    "* Die niedrigere Sprache besteht aus drei Worten: `Load`, `CountWords` und `DisplayResult`.\n",
    "* Die niedrigste Sprache besteht aus den Logik-Anweisungen in den Operationen.\n",
    "\n",
    "Der Jo-Jo Entwurf von Flow-Design kann also als Sprachentwurf verstanden werden. Mit welchen sukzessive \"primitiveren\" - oder besser: allgemeineren - Sprachen l√§sst sich eine L√∂sung formulieren.\n",
    "\n",
    "Die h√∂chste Sprache bzw. die spezifischste besteht dabei immer nur aus einem Wort. Im Grunde ist es ein [\"Sesam, √∂ffne dich\"](https://de.wikipedia.org/wiki/Ali_Baba) oder [\"simsalabim\"](https://de.wikipedia.org/wiki/Zauberspruch): das ganze Problem m√∂ge sich wie von Zauberhand durch Aufruf dieses einen Wortes in Luft aufl√∂sen.\n",
    "\n",
    "Demgegen√ºber besteht die primitivste, allgemeinste Sprache immer aus allen Worten der zugrundgelegten Plattform aus Programmiersprache, Bibliotheken, Frameworks, APIs.\n",
    "\n",
    "Und zwischen diesen beiden k√∂nnen beliebig viele weitere Sprachen eingezogen werden. Bei trivialen Problem m√∂gen die h√∂chste und primitivste ausreichen. Alle interessanten Probleme jedoch werden am besten durch Spezialsprachen gel√∂st, die aufeinander aufbauen.\n",
    "\n",
    "Dazu ist es nicht n√∂tig, *Domain Specific Languages (DSL)*, gar grafische, zu entwickeln. Simple Funktionen (und Module) gen√ºgen.\n",
    "\n",
    "Im Flow-Design gleichen sich diese Sprachen alle in ihrer Syntax, die durch Datenfl√ºsse (und nicht-funktionale Abh√§ngigkeiten) vorgegeben ist. Das Vokabular jedoch ist zu (er)finden.\n",
    "\n",
    "In Bezug auf ein etwas erweitertes Wortz√§hlungsproblem lie√üen sich z.B. weitere Abstraktionsebenen mit eigenem Vokabular einziehen. Das k√∂nnte so aussehen:\n",
    "\n",
    "/// neue datenflusshierarchie f√ºr wortz√§hlung mit mehr integrationsebenen (106)\n",
    "\n",
    "Im Code ist Logik nun in kleinere Einheiten verpackt. Die Funktionen sind feingranularer, das Vokabular also differenzierter (siehe Klassen der Gesch√§fts- und Datenzugriffslogik):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "class CountWords_v2 {\n",
    "    public static void Run(string filename) {\n",
    "        var words = Dataaccess_Stratified.Load(filename);\n",
    "        var numberOfWords = Business_Stratified_v2.CountWords(words);\n",
    "        Presentation_Stratified.DisplayResult(filename, numberOfWords);\n",
    "    }\n",
    "}\n",
    "\n",
    "class Business_Stratified_v2 {\n",
    "    public static int CountWords(IEnumerable<string> words) {\n",
    "        var significantWords = FilterShort(words);\n",
    "        significantWords = FilterNumbers(significantWords);\n",
    "        return significantWords.Count();\n",
    "    }\n",
    "    \n",
    "    private static IEnumerable<string> FilterShort(IEnumerable<string> words)\n",
    "        => words.Where(w => w.Length > 2);\n",
    "    \n",
    "    private static IEnumerable<string> FilterNumbers(IEnumerable<string> words) {\n",
    "        return words.Where(IsNoNumber);\n",
    "        \n",
    "        bool IsNoNumber(string candidateWord)\n",
    "            => int.TryParse(candidateWord, out var _) is false;\n",
    "    }\n",
    "}\n",
    "\n",
    "class Dataaccess_Stratified {\n",
    "    public static IEnumerable<string> Load(string filename) {\n",
    "        var text = LoadText(filename);\n",
    "        return SplitIntoWords(text);\n",
    "    }\n",
    "    \n",
    "    private static string LoadText(string filename)\n",
    "        => System.IO.File.ReadAllText(filename);\n",
    "    \n",
    "    private static IEnumerable<string> SplitIntoWords(string text)\n",
    "        => text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "}\n",
    "\n",
    "\n",
    "CountWords_v2.Run(\"samples/poem.txt\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die L√∂sung besteht jetzt aus drei Strata:\n",
    "\n",
    "1. `Run`\n",
    "2. `Load`, `CountWords`, `DisplayResult`\n",
    "3. `LoadText`, `SplitIntoWords`, `FilterShort`, `FilterNumbers`, `Count`, `DisplayResult`\n",
    "\n",
    "Das Vokabular wechselt von Stratum zu Stratum. Die Funktionseinheiten werden allgemeiner und allgemeiner, d.h. ihr Einsatzbereich wird gr√∂√üer und gr√∂√üer. Je tiefer ein Stratum liegt, desto gr√∂√üer die potenzielle Wiederverwendbarkeit der Funktionseinheiten in dar√ºberliegenden Strata.\n",
    "\n",
    "Tendenziell werden Funktionseinheiten eines Stratums nur im direkt dar√ºber liegenden benutzt. Gelegentlich greifen jedoch auch weiter oben liegende Strata darauf zu. Manches Vokabular ist dann so grundlegend, dass es sich durch mehrere Abstraktionsebenen durchzieht. Streng genommen k√∂nnte das als Versto√ü gegen das SLA angesehen werden - doch im Einzelfall mag das besser verst√§ndlich sein als weitere Kapselungen in den einzelnen Strata.\n",
    "\n",
    "Deshalb ist auch Logik hier und da in der Integration im Flow-Design geduldet. Logik ist das Vokabular des Terrains und sollte deshalb nicht in einem Stratum der Abstraktion auftauchen - au√üer eben in Einzelf√§llen. Beispiel daf√ºr hier ist `Count` in `Business_Stratified_v2.CountWords`, deren Aufruf zum dritten Stratum gerechnet wird.\n",
    "\n",
    "Unterhalb der Strata der Abstraktion liegt dann die Logik selbst. Ohne Operationen, Integrationen und Module ist sie quasi nackt. Jedes Detail ist sichtbar - aber die L√∂sung in dieser Weise entschleiert ist schwer verst√§ndlich und ihre Aspekte sind nicht getrennt testbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant words in 'samples/poem.txt': 72\n"
     ]
    }
   ],
   "source": [
    "var filename = \"samples/poem.txt\";\n",
    "\n",
    "var text = System.IO.File.ReadAllText(filename);\n",
    "IEnumerable<string> words = text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "words = words.Where(w => w.Length > 2);\n",
    "words = words.Where(w => int.TryParse(w, out var _) is false);\n",
    "var numberOfWords = words.Count();\n",
    "\n",
    "Console.WriteLine($\"Number of significant words in '{filename}': {numberOfWords}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Zusammenfassung\n",
    "\n",
    "Code aufgebaut aus Strata wachsender Abstraktion um einen Kern aus Logik herum versprechen bessere Verst√§ndlichkeit und Ver√§nderbarkeit. Das meinen nicht nur Abselson und Sussman, sondern auch Alan Kay, [der dabei ebenfalls von einer Hierarchie von Sprachen spricht](https://www.tele-task.de/lecture/video/2772/#t=3283).\n",
    "\n",
    "/// schalen von strata mit logik im kern (107)\n",
    "\n",
    "Nichts anderes geschieht ja auch ganz grunds√§tzlich, wenn man L√∂sungen mit Logik in einer modernen Programmiersprache formuliert. Selbst die reine Logik der obigen Wortz√§hlungslogik l√§sst sich als abstraktes Stratum verstehen oberhalb des Stratums der .NET *Intermediate Language (IL)*, das wiederum auf dem Stratum des Prozessor-Maschinencodes liegt, der den tats√§chlich ausgef√ºhrten Microcode abstrahiert.\n",
    "\n",
    "/// schalen weiterf√ºhren unterhalb der logik mit microcode im kern (108)\n",
    "\n",
    "Warum also diese erfolgreiche Methode nicht oberhalb der Logik ebenfalls anwenden?\n",
    "\n",
    "Mit den Datenfl√ºssen des Flow-Design geschieht das quasi nat√ºrlich durch die Anwendung von IOSP und PoMO. Dennoch ist die Vorstellung, in Strata von Sprache zu denken, ein gutes Hilfsmittel, um hierarchische Datenfl√ºsse zu entwerfen.\n",
    "\n",
    "Und zur Analyse von funktionalen Hierarchien erweist sich das Prinzip n√ºtzlich, dass Abh√§ngigkeiten nur in Richtung des Abstraktionsgef√§lles zeigen sollen, also von hoher Abstraktion zu niedriger. MVC, Schichtenmodell, Clean Architecture oder auch alle Entwurfsmuster k√∂nnen daraufhin √ºberpr√ºft werden, ob ihre Abh√§ngigkeiten dem entsprechen. Tun sie das nicht, ist aus Sicht von Flow-Design zumindest Vorsicht angezeigt. Allemal die Verst√§ndlichkeit mag dann geringer als m√∂glich sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-dimensionale Datenfl√ºsse\n",
    "\n",
    "Das erste Kennzeichen von Flow-Design Datenfl√ºssen ist die Abwesenheit von Schleifen. Daten flie√üen nur downstream: \"Vorw√§rts immer, r√ºckw√§rts nimmer!\"üòâ ist das Motto.\n",
    "\n",
    "Der Verzicht auf Schleifen ist eine \"freiwillige Selbstbeschr√§nkung\". Er tr√§gt dazu bei, dass Datenfl√ºsse deklarativ sind, und erh√∂ht die Verst√§ndlichkeit. Schleifen fordern mehr kognitiven Aufwand bei der Analyse von Code, weil sie dazu zwingen, etwas im Ged√§chtnis zu behalten, z.B. den Zustand einer Schleifenvariablen. Au√üerdem vergr√∂√üern sie das Risiko eines Bug z.B. durch 1-off Fehler:\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = 0;\n",
    "for(var i=0; i<=numbers.Length; i++) //üò±\n",
    "    sum += numbers[i];\n",
    "```\n",
    "\n",
    "Moderne, abstraktere Sprachkonstrukte verringern zwar solches Risiko...\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = 0;\n",
    "foreach(var n in numbers) //üòá\n",
    "    sum += numbers[i];\n",
    "```\n",
    "\n",
    "...und\\/oder erh√∂hen die Verst√§ndlichkeit:\n",
    "\n",
    "```\n",
    "var numbers = new[]{1,2,3};\n",
    "var sum = numbers.Sum(); //ü•≥\n",
    "```\n",
    "\n",
    "Letztlich bleiben Schleifen aber problematisch: Es sind Kontrollstrukturen, die zur Schachtelung einladen und un√ºbersichtlich werden, wenn sie wachsen. Nicht in allen F√§llen helfen moderne Abstraktionen. Deshalb gilt das Prinzip des Verzichts auf Schleifen in Datenfl√ºssen.\n",
    "\n",
    "Doch wie sieht es mit Fallunterscheidungen aus? Lassen sie sich auch vermeiden? Nein, Fallunterscheidungen definieren alternative Verhalten. Das ist notwendig und nicht zu vermeiden, auch wenn die Verhaltensproduktion mit Datenfl√ºssen modelliert wird.\n",
    "\n",
    "#### Kategorisierung\n",
    "\n",
    "Eine h√§ufige Anforderung im Rahmen der Verhaltensproduktion ist die Kategorisierung von Daten mit anschlie√üend unterschiedlicher Behandlung je nach Kategorie. Beispiel: Eine Eingabe soll in eine Dezimalzahl konvertiert werden, wenn sie eine bin√§re Zahl ist, oder umgekehrt. Eine bin√§re Zahl liegt vor, wenn die Eingabe auf \"b\" endet.\n",
    "\n",
    "Eine L√∂sung k√∂nnte mit Flow-Design so aussehen:\n",
    "\n",
    "/// zahlenkonvertierung (109)\n",
    "\n",
    "Neu ist hier, dass eine Funktionseinheit wie `Determine number system` mehrere Ausg√§nge haben kann. Die stehen f√ºr die Alternativen, dass der Input als bin√§re oder dezimale Zahl vorliegt. Jenachdem, zu welcher Kategorie der Input geh√∂rt, flie√üt die Verarbeitung entlang des einen oder des anderen Datenflussarms weiter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter {\n",
    "    public static string Convert(string number) {\n",
    "        var result = \"\";\n",
    "        DetermineNumberSystem(number,\n",
    "            decimalNumber => result = ToBinary(decimalNumber),\n",
    "            binaryNumber => result = ToDecimal(binaryNumber)\n",
    "        );\n",
    "        return result;\n",
    "    }\n",
    "    \n",
    "    private static void DetermineNumberSystem(string number, Action<string> onIsDecimal, Action<string> onIsBinary) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            onIsBinary(number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            onIsDecimal(number);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mehrere parallele Datenfl√ºsse f√ºgen den bisherigen 2-dimensionalen Modellen eine dritte Dimension hinzu:\n",
    "\n",
    "/// 3 dimensionen in einem hierarchischen datenfluss kennzeichnen (komposition, produktion.linear und produktion.parallel) (109a)\n",
    "\n",
    "Wie schon vorher bei den 1-dimensionalen Datenfl√ºssen gilt auch hier: alle Funktionseinheiten arbeiten grunds√§tzlich unabh√§ngig voneinander. Nacheinander geschaltete Funktionseinheiten k√∂nnen gleichzeitig aktiv sein, parallel geschaltete ebenfalls. Dass das oft nicht der Fall ist, weil nicht n√∂tig wie im obigen Beispiel, tut dem keinen Abbruch. 3-dimensionale Datenfl√ºsse erlauben die modellierung synchroner wie asynchroner, gar paralleler Verarbeitung.\n",
    "\n",
    "##### √úbersetzungsalternativen\n",
    "\n",
    "Auffallend an den alternativen Ausg√§ngen der Funktionseinheit `DetermineNumberSystem` ist, dass Output auf beiden als stream herausflie√üt. Das ist immer der Fall, wenn Output-Nachrichten entstehen k√∂nnen oder auch nicht. Wenn der Input eine dezimale Zahl darstellt, dann flie√üt Output auf dem zugeh√∂rigen Port heraus - und beim anderen nicht. Und umgekehrt. Nur mit streams ist es m√∂glich, keinen Output zu erzeugen.\n",
    "\n",
    "Das f√ºhrt dann dazu, dass in der √úbersetzung continuations zum Einsatz kommen. Nur mit ihnen l√§sst sich der Fall ohne Output f√ºr eine Alternative sauber implementieren.\n",
    "\n",
    "Alternativ w√§re in einer Sprache wie C# mit Tupel-Unterst√ºtzung zwar auch folgende √úbersetzung m√∂glich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter_v2 {\n",
    "    public static string Convert(string number) {\n",
    "        var categorization = DetermineNumberSystem(number);\n",
    "        if (categorization.isBinary)\n",
    "            return ToDecimal(categorization.normalizedNumber);\n",
    "        else\n",
    "            return ToBinary(categorization.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (bool isBinary, string normalizedNumber) DetermineNumberSystem(string number) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            return (true, number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            return (false, number);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter_v2.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter_v2.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doch damit w√ºrde die Integration `Convert` durch eine Kontrollstruktur verschmutzt. Das ist zwar nur minimal... dennoch sollte man sich dessen bewusst sein.\n",
    "\n",
    "Im allgemeinen Fall w√ºrde diese Variante die Kategorie √ºber einen `enum`-Datentyp zur√ºckliefern.\n",
    "\n",
    "Oder sie k√∂nnte sogar noch weitergehen und die downstream Verarbeitung selbst dynamisch bestimmen. Hierin k√∂nnte man zwar einen Widerspruch zum PoMO sehen... doch wenn Kategorisierung und Mapping auf eine Verarbeitung getrennt sind, mag das der Verst√§ndlichkeit und Testbarkeit nicht abtr√§glich, sondern sogar zutr√§glich sein.\n",
    "\n",
    "/// kategorisierung mit converter bestimmung (110)\n",
    "\n",
    "Jetzt gibt es keine Continuations mehr im Code. Jetzt gibt es keine unsauberen Kontrollstrukturen mehr in Integrationen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10b=2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10=1010"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class NumberConverter_v3 {\n",
    "    public static string Convert(string number) {\n",
    "        var conversion = ChooseConverter(number);\n",
    "        return conversion.convert(conversion.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (Func<string,string> convert, string normalizedNumber) ChooseConverter(string number) {\n",
    "        var categorization = DetermineNumberSystem(number);\n",
    "        var convert = PickConverter(categorization.isBinary);\n",
    "        return (convert, categorization.normalizedNumber);\n",
    "    }\n",
    "    \n",
    "    private static (bool isBinary, string normalizedNumber) DetermineNumberSystem(string number) {\n",
    "        if (number.EndsWith(\"b\"))\n",
    "            return (true, number.Substring(0, number.Length-1));\n",
    "        else\n",
    "            return (false, number);\n",
    "    }\n",
    "    \n",
    "    private static Func<string,string> PickConverter(bool isBinary) => isBinary switch {\n",
    "        true => ToDecimal,\n",
    "        false => ToBinary\n",
    "    };\n",
    "    \n",
    "    \n",
    "    private static string ToBinary(string number)\n",
    "        => System.Convert.ToString(int.Parse(number), 2);\n",
    "    \n",
    "    private static string ToDecimal(string number)\n",
    "        => System.Convert.ToInt32(number,2).ToString();\n",
    "}\n",
    "\n",
    "\n",
    "display($\"10b={NumberConverter_v3.Convert(\"10b\")}\");\n",
    "display($\"10={NumberConverter_v3.Convert(\"10\")}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem Anf√§nger in Sachen Flow-Design f√§llt es gew√∂hnlich nicht leicht, sich vorzustellen, dass Kontrollstrukturen und insbesondere Fallunterscheidungen wirklich nur in den Bl√§ttern des Zerlegungsbaumes stehen. Das ist verst√§ndlich, weil es so ungewohnt ist. In den B√§umen tiefer funktionaler Abh√§ngigkeiten ist das undenkbar und scheint auch gar nicht n√∂tig.\n",
    "\n",
    "Doch gerade hierin liegt das Geheimnis der Verst√§ndlichkeit und Testbarkeit von Code, der mit Flow-Design modelliert und IOSP/PoMO folgend √ºbersetzt wird! Deshalb sollten alle Anstrengungen unternommen werden, Schleifen und Fallunterscheidungen wirklich in die Operation-Funktionen hinunter zu dr√ºcken. Es ist in jedem Fall machbar und ist der Default im Flow-Design. Abweichungen davon sollten sehr bewusst eingegangen werden; sie lassen dark logic entstehen und verw√§ssern das stratified design.\n",
    "\n",
    "#### Fehler\n",
    "\n",
    "Ein weiterer typischer Fall f√ºr parallele Datenfl√ºsse stellen Fehler dar. Da gibt es einerseits den Datenfluss f√ºr den \"happy day\", d.h. wenn alles wie erwartet l√§uft. Und andererseits gibt es den Datenfluss f√ºr den \"rainy day\", d.h. den Fehlerfall.\n",
    "\n",
    "Ein typisches Szenario ist die Validation: Wenn ankommende Daten bestimmten Kriterien gen√ºgen, scheint die Sonne, ansonsten regnet es. Gutfall und Fehlerfall zu unterscheiden ist ein nicht zu vernachl√§ssigender Teil jedes Modells. Im Flow-Design geschieht das wieder mit mehreren Ausg√§ngen und parallelen Datenfl√ºssen.\n",
    "\n",
    "Als Beispiel die Addition mehrerer durch Leerzeichen getrennter Zahlen. Sind alle Zahlen valide, kann die Summe gebildet und ausgegeben werden. Falls nicht, gibt es eine Fehlermeldung.\n",
    "\n",
    "/// modell f√ºr die zahlenaddition mit fehlerfall (111)\n",
    "\n",
    "Gutfall oder Fehlerfall sind also im Grunde nur zwei Kategorien. Deren Bestimmung erfolgt oft jedoch nicht in einer speziellen Funktionseinheit zur Kategorisierung wie bei der Zahlenwandlung oben, sondern ist ein Beiprodukt. Hier nimmt z.B. `Parse` den Gutfall an, ist jedoch darauf vorbereitet, dass es zum Fehlerfall kommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum of 1 2 3 = 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Error: Cannot sum numbers! 'foo' is not a number."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "public class StringMath {\n",
    "    public static void Sum(string source, Action<int> onOk, Action<string> onError) {\n",
    "        Parse(source,\n",
    "             numbers => {\n",
    "                 var sum = numbers.Sum();\n",
    "                 onOk(sum);\n",
    "             },\n",
    "             erroneousNumber => {\n",
    "                 var error = $\"Cannot sum numbers! '{erroneousNumber}' is not a number.\";\n",
    "                 onError(error);\n",
    "             }\n",
    "         );\n",
    "    }\n",
    "    \n",
    "    private static void Parse(string source, Action<int[]> onSuccess, Action<string> onFailure) {\n",
    "        var candidateNumbers = source.Split(' ');\n",
    "        var numbers = new List<int>();\n",
    "        foreach(var cn in candidateNumbers)\n",
    "            if (int.TryParse(cn, out var n))\n",
    "                numbers.Add(n);\n",
    "            else {\n",
    "                onFailure(cn);\n",
    "                return;\n",
    "            }\n",
    "        onSuccess(numbers.ToArray());\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "var input = \"1 2 3\";\n",
    "StringMath.Sum(input,\n",
    "    sum => display($\"sum of {input} = {sum}\"),\n",
    "    error => display($\"Error: {error}\")\n",
    ");\n",
    "\n",
    "input = \"1 foo 3\";\n",
    "StringMath.Sum(input,\n",
    "    sum => display($\"sum of {input} = {sum}\"),\n",
    "    error => display($\"Error: {error}\")\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das der Gutfall der w√ºnschenswerte und meist interessantere und hoffentlich auch der h√§ufigere ist, k√∂nnte man versucht sein, die Asymmetrie zwischen Gutfall und Fehlerfall im Code auszudr√ºcken. Warum nicht den Output des Gutfalls √ºber das Funktionsresultat zur√ºckliefern und den Fehlerfall in einer continuation abhandeln?\n",
    "\n",
    "```csharp\n",
    "private static int[] Parse(string source, Action<string> onFailure) {\n",
    "    var candidateNumbers = source.Split(' ');\n",
    "    var numbers = new List<int>();\n",
    "    foreach(var cn in candidateNumbers)\n",
    "        if (int.TryParse(cn, out var n))\n",
    "            numbers.Add(n);\n",
    "        else {\n",
    "            onFailure(cn);\n",
    "            return null; //üò±\n",
    "        }\n",
    "    return numbers.ToArray();\n",
    "}\n",
    "```\n",
    "\n",
    "Das Problem ist der R√ºckgabewert der Funktion im Fehlerfall. Warum sollte der wie hier `null` sein? Darauf muss die Gutfall-Bearbeitung vorbereitet sein. Das vergr√∂√üert die Komplexit√§t des Codes.\n",
    "\n",
    "Einer symmetrische Behandlung ist der Vorzug zu geben. Wenn die nicht durch continuations stattfinden soll, dann w√§re es besser, die Alternative Klassifizierungs√ºbersetzung zum Einsatz zu bringen:\n",
    "\n",
    "```csharp\n",
    "private static (bool success, int[] numbers, string error) Parse(string source) {\n",
    "    var candidateNumbers = source.Split(' ');\n",
    "    var numbers = new List<int>();\n",
    "    foreach(var cn in candidateNumbers)\n",
    "        if (int.TryParse(cn, out var n))\n",
    "            numbers.Add(n);\n",
    "        else \n",
    "            return (false, new int[0], cn);\n",
    "    return (true, numbers.ToArray(), \"\");\n",
    "}\n",
    "```\n",
    "\n",
    "Das ist ein anerkanntes Muster neben der einfacheren Variante einer `Try`-Funktion, z.B. `bool TryParse(string source, out int[] numbers)`.\n",
    "\n",
    "Ohne continuations rutscht aber in jedem Fall Kontrollstruktur-Logik in die Integration, in der eine solche Funktion aufgerufen wird. Es ist also sensibel abzuw√§gen.\n",
    "\n",
    "#### Ausnahmen\n",
    "\n",
    "Es gibt erwartete Fehler und unerwartet. Letztere werden im Notfall durch Exceptions angezeigt. Die k√∂nnen wie rainy-day Fehler modelliert werden und insofern erwartet aussehen. Oder man benutzt eine spezielle Datenflussnotation, um anzuzeigen, dass Ausnahme nicht n√§her bestimmt aus einer Reihe von Funktionseinheiten herausspringen k√∂nnen.\n",
    "\n",
    "Als Beispiel ein Datenfluss der eine Reihe von Dateien verarbeitet: Sie werden gelesen, analysiert und das Analyseergebnis am Ende ausgegeben. In jedem der Schritte k√∂nnte eine Ausnahme geworfen werden. Das wird nicht erwartet, aber die M√∂glichkeit besteht. Deshalb gibt es keine speziellen Fehlerausg√§nge bei allen Funktionseinheiten, sondern sie werden in einen \"Kontext\" gesteckt, der allgemein darauf reagiert. (Die Funktionale Programmierung k√∂nnte dazu wohl auch *Monade* sagen.)\n",
    "\n",
    "/// datenfluss mit lesen, analysieren, summieren, anzeigen (112)\n",
    "\n",
    "F√ºr den m√∂glichen, aber nicht wahrscheinlichen Fall einer Ausnahme jede Funktionseinheit mit einem speziellen Output-Port daf√ºr zu versehen, w√ºrde die Komplexit√§t des Modells und des Codes stark erh√∂hen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 files with 28384 lines in total\n",
      "Exception: Could not find a part of the path '/Users/ralfw/Projects/jupyter-notebooks.github/Notebooks/flow-design-tutorial/foo'.\n"
     ]
    }
   ],
   "source": [
    "class FileStats {\n",
    "    public static void CountLines(string path) {\n",
    "        try {\n",
    "            (int numberOfFiles, int totalNumberOfLines) accumulator = (0,0);\n",
    "            EnumerateFiles(path,\n",
    "                filename => {\n",
    "                    var lines = System.IO.File.ReadAllLines(filename);\n",
    "                    accumulator.numberOfFiles += 1;\n",
    "                    accumulator.totalNumberOfLines += lines.Length;\n",
    "                });\n",
    "            DisplayResult(accumulator);\n",
    "        }\n",
    "        catch(Exception ex) {\n",
    "            DisplayException(ex);\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void EnumerateFiles(string path, Action<string> onFile) {\n",
    "        foreach(var filename in System.IO.Directory.GetFiles(path, \"*.*\", System.IO.SearchOption.AllDirectories))\n",
    "            onFile(filename);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void DisplayResult((int numberOfFiles, int totalNumberOfLines) result)\n",
    "        => Console.WriteLine($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines in total\");\n",
    "    \n",
    "    private static void DisplayException(Exception ex)\n",
    "        => Console.WriteLine($\"Exception: {ex.Message}\");\n",
    "}\n",
    "\n",
    "\n",
    "FileStats.CountLines(\"../entwurf\");\n",
    "FileStats.CountLines(\"../foo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die √úbersetzung des Kontextes mit `try`-`catch` ist naheliegend. Dass diese Kontrollstruktur jedoch in der Integration liegt, ist ein Widerspruch zum IOSP. Da Verst√§ndlichkeit und Testbarkeit dadurch jedoch nicht beeintr√§chtigt werden, ist das ausnahmsweise jedoch kein Problem.\n",
    "\n",
    "Wer jedoch auf Nummer sicher gehen will, insbesondere wenn noch weitere Logik in beiden F√§llen hinzukommen soll, der lagert die Kontrollstruktur aus in eine eigene Methode wie die folgende:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exceptionhandling {\n",
    "    public static void Try(Action tryThis, Action<Exception> onException) {\n",
    "        try {\n",
    "            display($\"trying...\");\n",
    "            tryThis();\n",
    "            display($\"succeeded!\");\n",
    "        }\n",
    "        catch(Exception ex) {\n",
    "            display($\"failed!\");\n",
    "            onException(ex);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zus√§tzliche Logik ist hier angedeutet durch die Protokollnachrichten. Sie w√ºrden die eigentliche Logik verrauschen und sind ein einem \"Kontext\" als separater Aspekt gut ausgelagert.\n",
    "\n",
    "Die L√∂sung sieht dann nur wenig anders aus, enth√§lt aber keine Logik mehr in der Integration `CountLines`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trying..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 files with 28936 lines in total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "succeeded!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "trying..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "failed!"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception: Could not find a part of the path '/Users/ralfw/Projects/jupyter-notebooks.github/Notebooks/flow-design-tutorial/foo'.\n"
     ]
    }
   ],
   "source": [
    "class FileStats_v2 {\n",
    "    public static void CountLines(string path) {\n",
    "        Exceptionhandling.Try(\n",
    "            () => Analyze(path),\n",
    "            DisplayException\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    private static void Analyze(string path) {\n",
    "        (int numberOfFiles, int totalNumberOfLines) accumulator = (0,0);\n",
    "        EnumerateFiles(path,\n",
    "            filename => {\n",
    "                var lines = System.IO.File.ReadAllLines(filename);\n",
    "                accumulator.numberOfFiles += 1;\n",
    "                accumulator.totalNumberOfLines += lines.Length;\n",
    "            });\n",
    "        DisplayResult(accumulator);\n",
    "    }\n",
    "    \n",
    "    private static void EnumerateFiles(string path, Action<string> onFile) {\n",
    "        foreach(var filename in System.IO.Directory.GetFiles(path, \"*.*\", System.IO.SearchOption.AllDirectories))\n",
    "            onFile(filename);\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static void DisplayResult((int numberOfFiles, int totalNumberOfLines) result)\n",
    "        => Console.WriteLine($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines in total\");\n",
    "    \n",
    "    private static void DisplayException(Exception ex)\n",
    "        => Console.WriteLine($\"Exception: {ex.Message}\");\n",
    "}\n",
    "\n",
    "\n",
    "FileStats_v2.CountLines(\"../entwurf\");\n",
    "FileStats_v2.CountLines(\"../foo\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fl√ºsse teilen und zusammenf√ºhren\n",
    "\n",
    "Mehrere Datenfl√ºsse k√∂nnen nicht nur alternativ durchflossen werden, sondern auch gleichzeitig. Das ist z.B. der Fall, wenn Input Teile enth√§lt, die unabh√§gig von einander verarbeitet werden k√∂nnen. Von der Datenflussnotation her k√∂nnte solche Verarbeitung zwar mit einem 1-dimensionalen Datenfluss modelliert werden, aber klarer ist es, wenn Parallelit√§t auch visuell ausgedr√ºckt wird.\n",
    "\n",
    "##### Split/Join\n",
    "\n",
    "Als Beispiel mag die Analyse von Dateien in Bezug auf zwei Aspekte dienen: einerseits soll ihre Zeilenzahl bestimmt werden, andererseits ihre Wortanzahl. Beide Informationen werden anschlie√üend zu einem Ergebnis zusammengeschn√ºrt.\n",
    "\n",
    "/// datei laden - split f√ºr zeilenz√§hlung / wortz√§hlung, join f√ºr ergebniszusammenf√ºhrung (mit stats) datenstruktur (113)\n",
    "\n",
    "Nach dem Laden der Datei wird der Datenfluss geteilt (split), beide Verarbeitungszweige laufen unabh√§ngig, am Ende werden deren Teilergebnisse zu einem Gesamtergebnis zusammengef√ºhrt (join).\n",
    "\n",
    "Sofern eine Zusammenf√ºhrung unaufw√§ndig ist, muss keine eigens benannte Funktionseinheit daf√ºr modelliert werden. Es reicht das join-Symbol wie hier gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><thead><tr><th>NumberOfLines</th><th>NumberOfWords</th></tr></thead><tbody><tr><td>15</td><td>79</td></tr></tbody></table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class FileAnalysis {\n",
    "    public class Result {\n",
    "        internal Result(int numberOfLines, int numberOfWords) {\n",
    "            NumberOfLines = numberOfLines;\n",
    "            NumberOfWords = numberOfWords;\n",
    "        }\n",
    "        \n",
    "        public int NumberOfLines {get;}\n",
    "        public int NumberOfWords {get;}\n",
    "    }\n",
    "    \n",
    "    \n",
    "    public static Result Analyze(string filename) {\n",
    "        var text = Load(filename);\n",
    "        return new Result(\n",
    "            CountLines(text),\n",
    "            CountWords(text)\n",
    "        );\n",
    "    }\n",
    "    \n",
    "    \n",
    "    private static string Load(string filename)\n",
    "        => System.IO.File.ReadAllText(filename);\n",
    "    \n",
    "    \n",
    "    private static int CountLines(string text) {\n",
    "        var lines = text.Split('\\n');\n",
    "        return lines.Length;\n",
    "    }\n",
    "    \n",
    "    private static int CountWords(string text) {\n",
    "        var words = text.Split(new[]{' ', '\\t', '\\n', '\\r'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "        return words.Count();\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "display(FileAnalysis.Analyze(\"samples/poem.txt\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was im Modell noch explizit ist, geschieht im Code dann fast unmerklich:\n",
    "\n",
    "* Der split findet keine spezielle √úbersetzung; dieselben Daten werden einfach als aktuelle Parameter zweier Funktionsaufrufe benutzt.\n",
    "* Die Parallelit√§t der Datenfl√ºsse ist nicht deutlich zu sehen, weil der lineare Quelltext das nicht erlaubt. Nur aus der Benutzung derselben Daten als Input f√ºr aufeinander folgende Funktionsaufrufe ist Parallelit√§t herauszulesen.\n",
    "* Der join besteht schlicht in der Nutzung beider Teilergebnisse als Parameter eines weiteren Funktionsaufrufs.\n",
    "\n",
    "In anderen F√§llen m√∂gen split und join hingegen sowohl im Modell wie im Code deutlicher zu sehen sein.\n",
    "\n",
    "/// beispiel f√ºr split und join funktionseinheiten (fluss dazwischen nur andeuten) (114)\n",
    "\n",
    "Zweierlei ist dabei dann zu bedenken:\n",
    "\n",
    "* Split: Flie√üt Output aus den Ports optional/alternativ oder stets? Optionalit√§t fordert die Modellierung als stream und legt eine Implementation als continuation nahe.\n",
    "* Join: Soll Verarbeitung bei jedem Eintreffen von Input stattfinden, egal auf welchem Port er hineinflie√üt, oder nur, wenn an allen Ports Input anliegt? Letzteres l√§sst sich leicht in mehrere Funktionsparameter √ºbersetzen wie oben beim `Result`-Konstruktor zu sehen. Ersteres legt eine √úbersetzung in mehrere separate Funktionen einer Klasse nahe.\n",
    "\n",
    "##### Scatter/Gather\n",
    "\n",
    "Ein Beispiel f√ºr explizite splits und joins sind echte Parallelverarbeitungsszenarien, d.h. √úbersetzungen, in denen mehrere Threads zum Einsatz kommen.\n",
    "\n",
    "Beispiel: Dateien sollen parallel analysiert werden. Anschlie√üend werden alle Analyseergebnisse zu einem zusammengef√ºhrt. Die Analyse kann so simpel sein wie die Z√§hlung der Zeilen je Datei.\n",
    "\n",
    "/// paralleler datenfluss f√ºr dateizeilenz√§hlung mit join am ende (115)\n",
    "\n",
    "Zun√§chst findet hier eine unbekannt gro√üe Aufsplittung des Datenflusses in parallele/konkurrente statt (scatter). Das kann mit einem stream geschehen, bei dem f√ºr jedes Element ein Thread gestartet wird.\n",
    "\n",
    "Wie lange die einzelnen Analysen dauern und wieviele es sind, ist bei der Akkumulation des Ergebnisses jedoch nicht bekannt (gather). Wann soll also deren Output ausflie√üen? Wie wei√ü die Akkumulation, dass das letzte Analyseergebnis eingetroffen ist? Das kann implizit mittels einer Framework-Technologie geschehen (z.B. ein `Task.WaitAll` im .NET Framework) oder explizit durch Vergleich der Zahl der eingetroffenen Ergebnisse mit der zu erwartenden Zahl, die von scatter gemeldet wird. Das Modell zeigt den zweiten Ansatz f√ºr gather, um technologieneutraler und expliziter zu sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  analyzing ../prozess.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anforderungen.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anforderung-logik-l√ºcke.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../index.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../entwurf/entwurf_1.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../codierung/arbeitsorganisation.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../analyse/slicing.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/radikale_oo.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/ioda.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  analyzing ../anatomie/dimensionen.ipynb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10 files with 5601 lines total"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using System.Threading;\n",
    "\n",
    "class ConcurrentFileAnalysis {\n",
    "    public static (int numberOfFiles, int totalNumberOfLines) Analyze(string path) {\n",
    "        var acc = new Accumulator();\n",
    "        \n",
    "        var filenames = CompileFiles(path);\n",
    "        Scatter(filenames,\n",
    "            filename => {\n",
    "                var numberOfLines = AnalyzeFile(filename);\n",
    "                acc.Add(numberOfLines);\n",
    "            },\n",
    "            acc.SetNumberOfValuesToExpect\n",
    "        );\n",
    "            \n",
    "        return acc.Gather();\n",
    "    }\n",
    "    \n",
    "    private static string[] CompileFiles(string path) {\n",
    "        var filenames = System.IO.Directory.GetFiles(path, \"*.ipynb\", System.IO.SearchOption.AllDirectories);\n",
    "        return filenames.Where(filename => filename.IndexOf(\"/.\") < 0).ToArray();\n",
    "    }\n",
    "    \n",
    "    private static void Scatter(string[] filenames, Action<string> onFilename, Action<int> onAllScattered) {\n",
    "        foreach(var filename in filenames) {\n",
    "            var th = new Thread(() => onFilename(filename));\n",
    "            th.Start();\n",
    "            //onFilename(filename);\n",
    "        }\n",
    "        onAllScattered(filenames.Length);\n",
    "    }\n",
    "    \n",
    "    private static int AnalyzeFile(string filename) {\n",
    "        display($\"  analyzing {filename}\");\n",
    "        var lines = System.IO.File.ReadAllLines(filename);\n",
    "        return lines.Length;\n",
    "    }\n",
    "}\n",
    "\n",
    "private class Accumulator {\n",
    "    private object _lock = new Object();\n",
    "    private AutoResetEvent _are = new AutoResetEvent(false);\n",
    "\n",
    "    private int _numberOfValuesToExpect = 0;\n",
    "    private int _numberOfValuesReceived = 0;\n",
    "\n",
    "    private int _total;\n",
    "\n",
    "    \n",
    "    public void SetNumberOfValuesToExpect(int numberOfValuesToExpect) {\n",
    "        lock(_lock) {\n",
    "            _numberOfValuesToExpect = numberOfValuesToExpect;\n",
    "            \n",
    "            if (_numberOfValuesReceived >= _numberOfValuesToExpect)\n",
    "                _are.Set();\n",
    "        }\n",
    "    }\n",
    "\n",
    "    public void Add(int value) {\n",
    "        lock(_lock) {\n",
    "            _numberOfValuesReceived++;\n",
    "             _total += value;\n",
    "            \n",
    "            if (_numberOfValuesToExpect > 0 && _numberOfValuesReceived >= _numberOfValuesToExpect)\n",
    "                 _are.Set();\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public (int numberOfValues, int totalValue) Gather() {\n",
    "        _are.WaitOne();\n",
    "        return (_numberOfValuesToExpect, _total);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "var result = ConcurrentFileAnalysis.Analyze(\"..\");\n",
    "display($\"{result.numberOfFiles} files with {result.totalNumberOfLines} lines total\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "datenstr√∂me explizit beenden (hier ein thema, weil bei 3D datenfl√ºssen eher continuations zum einsatz kommen)\n",
    "oder auch parallelverarbeitung: fork join/wait, scatter/gather (dateien parallel verarbeiten).\n",
    "ende implizit (IEnum) oder EOS element oder signal (dass ende erreicht oder wann ende erreicht (anzahl zu erwartender inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

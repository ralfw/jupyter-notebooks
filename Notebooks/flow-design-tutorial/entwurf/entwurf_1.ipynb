{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lösungsmodelle entwerfen\n",
    "\n",
    "![](../images/serenity/serenity8.jpg)\n",
    "\n",
    "Flow-Design verfolgt einen verhaltensorientierten Ansatz. Lösungen werden von der SOLL-Funktionalität her angegangen. Für Flow-Design lautet die Frage zuerst: Was soll Software tun?\n",
    "\n",
    "Nicht Datenstrukturen stehen also im Vordergrund, sondern Verhaltensstrukturen. Verhalten konsumiert und produziert Daten. Um zu wissen, wie Daten strukturiert sein sollen, ist also zuerst die Verhaltensproduktion zu klären.\n",
    "\n",
    "Was wie womit getan werden soll, entsteht dabei zunächst in den Köpfen der Entwickler und auf Papier. Die Codierung ist zurückgestellt, bis für ein klar umrissenes Problem die Lösung als Modell vorliegt.\n",
    "\n",
    "Ein Modell versteht Flow-Design dabei ganz allgemein so:\n",
    "\n",
    "> Modell = (Funktion, Beziehung, Funktion)\\*\n",
    "\n",
    "Ein Modell ist eine Menge von Tupeln, in denen je zwei Funktion in Beziehung zueinander gesetzt werden.\n",
    "\n",
    "Wie auch immer Modelle dargestellt werden, aus ihnen müssen programmiersprachliche Funktionen abgeleitet werden können. In Modellen findet sich keine Logik; sie sind deklarativ. Aber ihre Bausteine stehen für Funktionen, die später in der Codierung mit Logik gefüllt werden.\n",
    "\n",
    "Beziehungen zwischen Funktionen können unter anderem sein:\n",
    "\n",
    "* Abhängigkeit: Eine Funktion ruft eine andere auf.\n",
    "* Sequenz: Eine Funktion steht in einem Fluss vor oder nach einer anderen.\n",
    "* Parallelität: Eine Funktion kann/muss parallel zu einer anderen ausgeführt werden.\n",
    "* Aggregation: Zwei Funktionen sind in einem Modul zusammengefasst.\n",
    "* Gemeinsame Daten: Zwei Funktionen nutzen dieselben Daten.\n",
    "* Konkretisierung: Zwei Funktionen stehen in einer Vererbungsbeziehung.\n",
    "\n",
    "Die Deklarativität von Modellen im Flow-Design macht aus, dass ihre Bausteine für angenommene Problemlösungen stehen. Entweder wird dann das Problem an anderer Stelle im Modell durch eine Verfeinerung gelöst. Oder eine im Modell offen gebliebene Annahme wird spätestens in der Codierung mittels Logik erfüllt.\n",
    "\n",
    "/// modellbaum: große probleme werden in kleinere zerlegt und die wieder in kleinere. kleinere lösen größere probleme im modell. aber die blätter müssen im code gelöst werden. (1)\n",
    "\n",
    "Bei all dieser Allgemeinheit in der Definition von Modellen hat Flow-Design allerdings einen klaren Favoriten als Modellierungsansatz. Flow-Design steht für die Überzeugung, dass Softwarelösungen zunächst und ganz fundamental Produktionsprozesse sind, die auf Daten arbeiten und also als Datenflüsse modelliert werden können. Der Entwurf im Flow-Design beginnt daher gemeinhin mit einer Datenflussmodellierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Datenflüssen modellieren\n",
    "\n",
    "Die Datenflussmodellierung beginnt gewöhnlich mit einer in der Analyse ermittelten Interaktion repräsentiert durch ein Nachrichtenpaar und ggf. Seiteneffekte. Ausgangspunkt ist eine Funktionseinheit, die Verhalten zeigen soll in Form einer klar definierten Datentransformation. Sie stellt die Wurzel des Lösungsansatzes dar. Sie repräsentiert die angenommen erfüllten Anforderungen.\n",
    "\n",
    "/// funktionseinheit mit input/output/state (2)\n",
    "\n",
    "Wie aufwändig die Lösung eines so gestellten Verhaltensproblems sein mag, ist seiner formalen Darstellung nicht anzusehen. Das ist aber auch nicht nötig, wie sich zeigen wird. Wichtiger ist die einfachheit der Darstellung und ihre Klarheit im Sinne einer Codierung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-dimensionale Datenflüsse\n",
    "\n",
    "Eine Funktionseinheit, die Input in Output überführt, ist das kleinstmögliche Datenfluss-Modell. Sie entspricht einem Punkt im dreidimensionalen Raum, ist also 0-dimensional.\n",
    "\n",
    "/// funktionseinheit mit annotierter blase und pfeilen (3)\n",
    "\n",
    "#### Notation\n",
    "\n",
    "So leichtgewichtig die Notation für solch eine Repräsentanz einer Problemlösung sein mag, so sind doch ein paar Hinweise angebracht:\n",
    "\n",
    "* Eine Funktionseinheit dargestellt als \"Blase\" oder Kreis oder Ellipse, also als \"runde Form\" steht für etwas, das getan werden soll; sie löst ein Problem durch ihre Transformation von Input zu Output. Deshalb ist ihre Benennung mit einem Verb oder einer Verbphrase sinnvoll. Ein Imperativ muss es nicht sein, aber darf es natürlich. Zudem sollte die Benennung relevant für das Umfeld sein, also orientiert an der Domänensprache statt technisch. Außerdem - und vielleicht sogar am wichtigsten - sollte die Bennung keinen Hinweis auf die Lösung(simplementation) enthalten. Die wird im Modell nur gewünscht, nicht gewusst. **Es geht im Modell ums Was und Warum, nicht ums Wie.**\n",
    "* Datenflüsse werden durch Pfeile zur und von der Funktionseinheit angezeigt. Pfeile werden im Flow-Design ausschließlich für diesen Zweck benutzt! Pfeile stellen also keine Abhängigkeiten dar, sondern unidirektionale Datenkanäle, deren Quellen und Senken einander nicht kennen.\n",
    "* Was fließt, wird immer (!) an Pfeilen in Klammern kurz beschrieben. Auch hier geht es vor allem ums Was, nicht ums Wie. Daten werden mit Substantiven benannt. Meist geschieht das in Kleinschreibung und ohne Datentyp, weil der offensichtlich ist. Aber es kann auch ein Datentyp explizit hinzugefügt werden. Oder Daten werden in Großschreibung benannt und stehen damit selbst für einen Datentyp.\n",
    "\n",
    "/// daten implizit typisiert, explizit und als datentyp (4)\n",
    "\n",
    "##### Zustandsbehaftete Funktionseinheiten\n",
    "\n",
    "Funktionseinheiten arbeiten vor allem auf dem Input, der in sie einfließt. Eintreffender Input triggert ihr Verhalten. Aber Funktionseinheiten sind nicht per se *pur*. Flow-Design hat kein Ideal von \"pure functional units\" wie die Funktionale Programmierung \"pure functions\" favorisiert. Flow-Design empfiehlt Zustandslosigkeit bzw. Seiteneffektfreiheit, wo sie sinnvoll und machbar sind. Doch wenn sich das (zunächst) als unintuitiv erweisen sollte, sind Zustand und Seiteneffekte völlig akzeptable - sollten jedoch angezeigt werden.\n",
    "\n",
    "/// funktionseinheit mit Zustand (tonne), funktionseinheit mit seiteneffekt (dreieck) (5)\n",
    "\n",
    "Wie Zustand genau realisiert wird, ist wieder nicht Sache des Modells. Es soll vor allem klar gemacht werden, dass es eine Einflussgröße für die Transformation gibt, die über Nachrichten hinweg relevant ist.\n",
    "\n",
    "Wenn Zustand an gewisser Stelle vermieden werden soll, kann er auch in den Fluss extrahiert werden:\n",
    "\n",
    "/// zustand fließt (6)\n",
    "\n",
    "Dasselbe gilt für Seiteneffekte. Die werden über einen API hergestellt, der auch in spezifischeren Funktionseinheiten up-/downstream enger gekapselt werden könnte:\n",
    "\n",
    "/// seiteneffekt zb nach einer funktionseinheit erzeugen, die ihn vorher selbst erzeugt hat (7)\n",
    "\n",
    "##### Datenströme\n",
    "\n",
    "Die meisten Funktionseinheiten transformieren eine Input-Nachricht in eine Output-Nachricht. Dabei ist es unerheblich, ob Input oder Output aus einem Datum bestehen oder ein Feld sind, eine Liste oder eine andere Sammlung von vielen Daten.\n",
    "\n",
    "/// einzelne daten fließen rein/raus vs menge fließt rein od raus (8)\n",
    "\n",
    "Wenn Sammlungen (*collections*) fließen, kann deren Typ explizit angeben werden - z.B. `(dateiname[])`, `(dateinamen:List<string>)`. Im Allgemeinen ist das jedoch schon zu viel Implementationsdetail für ein Modell. Deshalb ziegt Flow-Design ein schlichtere Angabe für \"mehrere Daten\" vor, die \"in einem Schwung\" ein-/ausfließen: `(dateiname*)`. Der Datenangabe ist einfach nur unmittelbar und in der Klammer ein Sternchen nachzustellen.\n",
    "\n",
    "/// daten fließen mit sternchen für collection (9)\n",
    "\n",
    "Eine oft zu vernachlässigende, am Ende jedoch sehr interessante Eigenschaft von Datenflüssen im Gegensatz zu Kontrollflüssen ist jedoch, dass alle Funktionseinheiten im Grunde *gleichzeitig* aktiv sind. Nur weil Daten produziert sind und ausfließen, heißt das nicht, dass eine Funktionseinheit die Kontrolle abgibt. Sie kann auch weiterarbeiten, während der Output zu einer anderen Funktionseinheit fließt und gleichzeitig dort verarbeitet wird. Produzenten und Konsumenten sind grundsätzlich nebenläufig und asynchron - und nur, wenn das nicht wichtig ist, werden sie sequenziell und synchron implementiert.\n",
    "\n",
    "Die grundsätzliche Nebenläufigkeit hat nun zur Folge, dass eine Funktionseinheit nicht nur einmal für einen Input einen Output produzieren kann, sondern mehrfach. Dann entsteht keine *collection* von Nachrichten, sondern ein *stream*. Jedes Element in solch einem  Strom ist eine eigene Nachricht. Angezeigt wird das im Modell durch ein Sternchen *hinter* der Klammer, z.B. `(dateiname)*`.\n",
    "\n",
    "Ströme sind nur relevant zu markieren als Output. Die Anlieferung von Input erfolgt im Grunde immer als Strom. Notiert wird das nur nicht speziell; es ist normal. Auf jede Nachricht im Input-Strom reagiert eine Funktionseinheit dann.\n",
    "\n",
    "/// daten fließen mit einem sternchen für streams (10)\n",
    "\n",
    "#### Übersetzung\n",
    "\n",
    "\"Bubbles don't crash\" - das ist wahr und deshalb ist es Flow-Design wichtig, dass die \"Bubbles\" seiner Modelle möglichst einfach in Code übersetzt werden können, der crashen kann, um Modell-Ideen zu überprüfen.\n",
    "\n",
    "Die naheliegende Übersetzung einer Funktionseinheit ist die in eine Funktion:\n",
    "\n",
    "/// simple funktionseinheit, die den durchschnitt einer liste von zahlen berechnet (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int CalcAverage(IEnumerable<int> werte) {\n",
    "    return werte.Sum() / werte.Count();\n",
    "}\n",
    "\n",
    "display($\"Durchschnitt von [1,5,9,3]: {CalcAverage(new[]{1,5,9,3})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert gut, solange für jeden Input-Wert ein Output-Wert bzw. eine Output-Collection erzeugt wird. Und auch mit Tupeln funktioniert es, wenn die Programmiersprache Tupel direkt unterstützt oder man gewillt ist, für ein Tupel einen Datentypen zu definieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(T head, IEnumerable<T> tail) Split<T>(IEnumerable<T> list)\n",
    "    => (list.First(), list.Skip(1));\n",
    "\n",
    "var result = Split(new[]{2,7,9,3});\n",
    "display($\"head: {result.head}\");\n",
    "foreach(var e in result.tail) display($\"  tail element: {e}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktionen sind natürliche \"Objekte\" im Sinne von Alan Kay, weil sie für eine empfangene Nachricht - *dass* man sie aufruft und mit welchen Parametern man sie aufruft - ein Resulat herstellen, ohne zu wissen, woher sie aufgerufen wurden und wie das Resultat benutzt wird. Das PoMO wird eingehalten.\n",
    "\n",
    "##### Datenströme\n",
    "\n",
    "Allerdings können Funktionen für jedes eintreffende Nachricht, d.h. für jeden Aufruf, nur einmal ein Resultat herstellen (auch wenn das womöglich aus mehreren Elementen besteht). Was aber, wenn Input in einen Strom von Resultaten umzuwandeln ist?\n",
    "\n",
    "Hier bricht die Übersetzung der \"Blase\" in eine Funktion. Bei genauerem Hinsehen ist es stattdessen so, dass die Punkte, wo Pfeile auf eine Funktionseinheit treffen und wo sie sie verlassen, getrennt übersetzt werden:\n",
    "\n",
    "* Ein eintreffender Pfeil wird in eine Funktion mit Parametern übersetzt.\n",
    "* Ein ausgehender Pfeil wird in ein Funktionsresultat oder eine *continuation* übersetzt.\n",
    "\n",
    "Ein Funktionsresultat ist dann möglich, wenn nur einmal ein Output generiert wird. Andernfalls muss Output über einen Funktionszeiger an die Umwelt weitergeschoben werden. Dieser Funktionszeiger muss eine *Prozedur* beschreiben (Funktion ohne Rückgabewert), deren Name nicht auf weitere downstream Verarbeitung des Output hindeutet, da sonst das PoMO verletzt würde.\n",
    "\n",
    "/// übersetzen des input und output pfeils; einmal result, einmal continuation (12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "quick"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "brown"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fox"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IEnumerable<string> SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "var words = SplitIntoWords(\"the quick brown fox\");\n",
    "foreach(var w in words) display(w);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "humpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dumpty"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sat"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "on"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "wall"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void EnumerateWords(string text, Action<string> onWord)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries).ToList()\n",
    "           .ForEach(onWord);\n",
    "\n",
    "EnumerateWords(\"humpty dumpty sat on a wall\",\n",
    "    word => display(word));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Codierung eines Output-Datenkanals mit einer continuation ist die universellere. Aber sie ist weniger intuitiv und umständlicher. Deshalb zieht Flow-Design die Übersetzung mit Funktionsresultaten vor, wo sie offensichtlich ist oder auch machbar durch Sprachkonstrukte wie Iteratoren (z.B. `IEnumerable<>` in C#).\n",
    "\n",
    "Streams sind Mengen von einzelnen Werten. Wo sie naheliegend und nützlich im Modell sind, sollten sie angemessen in der Übersetzung repräsentiert werden. Das ist mit continuations, also Funktionszeigern in vielen Programmiersprachen möglich, wenn auch ein wenig gewöhnungsbedürftig. Aber die Gewöhnung lohnt sich: die Übersetzung von Modellen wird einfacher, die Testbarkeit des Codes steigt.\n",
    "\n",
    "##### Zustand\n",
    "\n",
    "Zustand bzw. Ressourcenzugriff sind Abhängigkeiten einer Funktionseinheit. Sie werden als Abhängigkeiten übersetzt. Zustand ist dabei eine globale Variable im aggregierenden Modul einer Funktion:\n",
    "\n",
    "/// akkumulator (13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add 1: 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 2: 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "add 3: 6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Accumulator {\n",
    "    private int _value;\n",
    "    \n",
    "    public int Add(int a) {\n",
    "        _value += a;\n",
    "        return _value;\n",
    "    }\n",
    "}\n",
    "\n",
    "var accu = new Accumulator();\n",
    "display($\"add 1: {accu.Add(1)}\");\n",
    "display($\"add 2: {accu.Add(2)}\");\n",
    "display($\"add 3: {accu.Add(3)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-dimensionale Datenflüsse\n",
    "\n",
    "Einzelne Funktionsheiten werden in Modellen zu Datenflüssen mehrere Funktionseinheiten zusammengesetzt. Flow-Design nennt das auch \"zusammenstecken\" oder \"verdrahten\" in Anlehnung an elektronische Schaltungen, die übrigens ganz natürlich dem PoMO folgen. Aus 0-dimensionalen Modellen werden so 1-dimensionale: viele punktuelle Funktionseinheiten zusammen ergeben einen linearen Fluss.\n",
    "\n",
    "/// eine sequenz von funktionseinheiten: from roman (14)\n",
    "\n",
    "Wenn der Output einer Funktionseinheit in der Form dem Input einer anderen entspricht, können beide in eine producer-consumer Beziehung gebracht werden. Sie spannen dann einen Transformationsfluss auf.\n",
    "\n",
    "Die Übersetzung eines 1-dimensionalen Flusses ist trivial: die Funktionen der einzelnen Funktionseinheiten..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Funktionseinheiten\n",
    "int[] Map(string roman)\n",
    "    => roman.ToCharArray()\n",
    "            .Select(romanDigit => romanDigit switch {\n",
    "                        'I' => 1, 'V' => 5, 'X' => 10,\n",
    "                        'L' => 50, 'C' => 100, 'D' => 500,\n",
    "                        'M' => 1000\n",
    "                    })\n",
    "            .ToArray();\n",
    "\n",
    "int[] Negate(int[] values) {\n",
    "    var negatedValues = (int[])values.Clone();\n",
    "    for(var i=0; i<negatedValues.Length-1; i++)\n",
    "    if (negatedValues[i]<negatedValues[i+1])\n",
    "        negatedValues[i] *= -1;\n",
    "    return negatedValues;\n",
    "}\n",
    "\n",
    "int Sum(IEnumerable<int> values) {\n",
    "    var sum = 0;\n",
    "    foreach(var v in values) sum += v;\n",
    "    return sum;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ...werden schlicht nacheinander aufgerufen. Der Compiler gibt Feedback, ob die Bausteine eines Datenflusses zueinander passen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XIV=14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Datenfluss\n",
    "var values = Map(\"XIV\");\n",
    "values = Negate(values);\n",
    "var decimalNumber = Sum(values);\n",
    "\n",
    "display($\"XIV={decimalNumber}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In dieser Übersetzung verliert das Modell des Datenflusses zwar seine Eigenschaft der grundsätzlichen Asynchronizität seiner Transformationsschritte, doch das ist in den meisten Fällen unerheblich. Datenflüsse sind auch Datenflüsse, wenn sie synchron operieren. Das Modell hat trotzdem einen hohen Wert durch seine Abstraktion.\n",
    "\n",
    "Die Funktionseinheiten, die im 1-dimensionalen Datenfluss verdrahtet werden, sind (zunächst) Operationen. Der Datenfluss stellt ihre Integration dar: alle einzelnen Transformationen bilden in spezifischer Weise zusammengesteckt eine größere Transformation.\n",
    "\n",
    "#### Datenströme\n",
    "\n",
    "Solche Übersetzung von 1-dimensionalen Flüssen als Lösungen von größeren Problemen in Form einer Abfolge von Lösungen kleinerer Probleme funktionieren auch für Ströme von Einzeldaten statt Collections.\n",
    "\n",
    "Datenströme sind nützlich, wenn...\n",
    "\n",
    "* ...die Zahl der zu erzeugenden Output-Datenelemente unbekannt und wahrscheinlich groß ist. In dem Fall soll vielleicht vermieden werden, alle Datenelemente in einer Collection im Hauptspeicher zu sammeln.\n",
    "* ...die Generierung aller Output-Datenelemente erhebliche Zeit in Anspruch nimmt. In dem Fall sollen schon generierte Output-Daten schon downstream in Verarbeitung gehen, während weitere beschafft werden.\n",
    "* ...ein Datenfluss besser zu verstehen und/oder zu übersetzen ist als Strom von Einzeldaten.\n",
    "\n",
    "Als Beispiel dafür mag die Traversierung eines Verzeichnisbaumes dienen, in dem Dateien eines bestimmten Typs gesucht werden, um sie zu analysieren. Zu ermitteln ist die Gesamtanzahl der Worte in relevanten Dateien.\n",
    "\n",
    "/// datenfluss für traversierung, filterung, analyse, ausgabe (15)\n",
    "\n",
    "Die Zahl der zu prüfenden Dateien ist in so einem Szenario womöglich schwer abzuschätzen und/oder die Lösung ist leichter \"zu denken\", wenn die Analyse sich auf einzelne Dateien konzentriert.\n",
    "\n",
    "Zuerst die Übersetzung der Funktionseinheiten, der Bausteine des Flusses. Jede ist nur eine kleine Operation mit wenigen Zeilen Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "void EnumerateFiles(string path, Action<string> onFilename) {\n",
    "    // Die Logik hier ist aufwändiger als nötig aus didaktischen Gründen, um einen Output-Strom zu erzeugen.\n",
    "    var filenames = System.IO.Directory.GetFiles(path);\n",
    "    foreach(var f in filenames) {\n",
    "        onFilename(f);\n",
    "    }\n",
    "    \n",
    "    var subdirectories = System.IO.Directory.GetDirectories(path);\n",
    "    foreach(var d in subdirectories)\n",
    "        EnumerateFiles(d,\n",
    "              onFilename);\n",
    "}\n",
    "\n",
    "void FilterByEndOfFilename(string filename, string pattern, Action<string> onFilename) {\n",
    "    if (filename.EndsWith(pattern))\n",
    "        onFilename(filename);\n",
    "}\n",
    "\n",
    "string Load(string filename) \n",
    "    => System.IO.File.ReadAllText(filename);\n",
    "\n",
    "string[] SplitIntoWords(string text)\n",
    "    => text.Split(new[]{' ', '\\n', '\\t'}, StringSplitOptions.RemoveEmptyEntries);\n",
    "\n",
    "void Print(string filename, int numberOfWords) {\n",
    "    display($\"{filename} with {numberOfWords} words\");\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Und dann die Übersetzung des Flusses. Die mag ein wenig gewöhnungsbedürftig sein in der Schachtelung der Lambda-Funktionen als continuations. Doch das verliert sich, wenn man es ein paar Mal geschrieben und gelesen hat. Der Gewinn der Gewöhnung liegt dann darin, eine geradlinige Übersetzung für Datenflüsse mit Strömen zu haben, die in jedem Schritt gut testbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-lücke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 3485 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 3388 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-lücke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EnumerateFiles(\"..\",\n",
    "    filename => FilterByEndOfFilename(filename, \".ipynb\",\n",
    "          filename => {\n",
    "              var text = Load(filename);\n",
    "              var words = SplitIntoWords(text);\n",
    "              Print(filename, words.Length);\n",
    "          })\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`EnumerateFiles` erzeugt für eine Input-Nachricht einen Strom von Output-Nachrichten. `FilterByEndOfFilename` hingegen hat die Aufgabe, Input zu verschlucken, falls er nicht dem Filterkriterium entspricht. Das klingt sehr unterschiedlich, ist letztlich jedoch dasselbe: Der Strom dient in beiden Fällen zur Ausgabe einer unbekannten Zahl von Elementen, das können 1 oder 1000 sein - oder auch gar keines.\n",
    "\n",
    "Eine Funktion, die ein Resultat mittels `return` liefert, ist gezwungen, eines zu produzieren, selbst wenn das `null` sein sollte. Eine Funktion, die ihr Resultat stattdessen über eine continuation \"hinausschiebt\", kann auch entscheiden, gar kein Resultat zu liefern! Deshalb ist die Übersetzung von Datenfluss-Funktionseinheiten in Funktionen mit continuation die universellere, wenn auch etwas aufwändigere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-dimensionale Datenflüsse\n",
    "\n",
    "Funktionen sind in 0-dimensionalen und 1-dimensionalen Datenflüssen die Container für Logik. Sie komponieren aus \"Logikbausteinen\" ein Verhalten, für das sie stehen.\n",
    "\n",
    "Obwohl 1-dimensionale Datenflüsse leicht zu verstehen sind auch in der Übersetzung in Funktionsaufrufsequenzen, skalieren sie nicht. Mehr als 5 oder vielleicht 10 Funktionseinheiten \"in einer Reihe\" oder Funktionsaufrufe nacheinander, sind aus mehreren Gründen nicht praktikabel:\n",
    "\n",
    "* Im Modell wie im Code sind so lange Sequenzen trotz ihrer formalen Einfachheit nicht mehr gut zu überblicken.\n",
    "* Die Gefahr, dass Datenflüsse das SLA verletzen, steigt mit jeder weiteren Funktionseinheit.\n",
    "* Die Wahrscheinlichkeit, dass es in Datenflüssen Gruppen von Funktionseinheiten mit höherer Kohäsion untereinander gibt als zu anderen, steigt mit jeder weiteren Funktionseinheit.\n",
    "\n",
    "Schon zum oben stehenden Datenfluss zur Analyse von Dateien kann gefragt werden, ob er für das Verständnis eine optimale Länge hat.\n",
    "\n",
    "Einerseits hat ein Leser bei dem 1-dimensionalen Datenfluss \"alles auf einmal im Blick\". Alle Operationen stehen in einer Reihe. Andererseits muss ein Leser sich die Bedeutung des Ganzen aus den Bedeutungen der Teile erst zusammenreimen. Das ist bei 5 Funktionseinheiten schwieriger als bei 4, 3 oder 1.\n",
    "\n",
    "Was tut der Datenfluss? Kann das mit 1 Funktionseinheit ausgedrückt werden? Selbstverständlich!\n",
    "\n",
    "/// dateianalyse mit 1 funktionseinheit ausdrücken und den fluss integrieren (16)\n",
    "\n",
    "Die eine Funktionseinheit integriert nun explizit die bisherigen Operationen.\n",
    "\n",
    "Oder gibt es im Datenfluss noch Teile, die wiederum unter einem Begriff zusammengefasst werden können, um ihnen eine eigene Bedeutung zu geben? Beispiele dafür wären:\n",
    "\n",
    "* Alles außer der Ausgabe könnte als Kernlogik zusammengefasst werden. Die Ausgabe eines Ergebnisses ist etwas ganz anderes, als das Ergebnis herzustellen. Dadurch würde die Ergebnisherstellung separat von der Benutzerschnittstelle testbar.\n",
    "* Die Beschaffung der relevanten Dateinamen könnte zusammengefasst werden. Die Traversierung des Dateisystems ist etwas ganz anderes, als mit einer Datei umzugehen.\n",
    "* Laden und Zerlegen einer Datei könnte zusammengefasst werden. Eine Datei als Text zu beschaffen, statt als Byteblock, ist schon eine Abstraktion, die der .NET Framework zur Verfügung stellt. Warum nicht den Dateizugriff weiter abstrahieren und eine Datei als Collection von Worten repräsentieren?\n",
    "\n",
    "Wie man sich entscheidet bei den Zusammenfassungen, ist weniger wichtig, als dass Zusammenfassungen zur Verbesserung der Verständlichkeit und der Testbarkeit möglich und einfach sind. Die eine beste Zusammenfassung wird es wohl nicht geben. Da Integrationen von Teilflüssen jedoch billig herzustellen und auch wieder aufzulösen sind, kann die Integrationshierarchie jederzeit umgestellt werden.\n",
    "\n",
    "Verständnis verändert sich mit der Zeit: Es wird aufgebaut durch Beschäftigung mit Code - aber es wird auch wieder abgebaut, wenn die Beschäftigung abnimmt. Eine Struktur, die dem heutigen Verständnis angemessen ist, passt womöglich nicht mehr optimal zum morgigen Verständnis.\n",
    "\n",
    "In dieser Hinsicht unterliegen Modelle und Code trotz ihrer Immaterialität einem Verschleiß. Ohne, dass Code \"sich bewegte\" oder verändert würde, verliert er an \"Verständlichkeitsqualität\". Das hat zwei Konsequenzen:\n",
    "\n",
    "* Die Diskussion um die allerbeste Struktur sollte begrenzt werden. Die allerbeste Struktur, selbst wenn sie für heute gefunden werden könnte, ist morgen nicht mehr die allerbeste. Nach dem Herstellungszeitpunkt verliert jede auf Verständlichkeit getrimmte Struktur sofort und automatisch an Wert. Warum also bis aufs Letzte optimieren?\n",
    "* Strukturen für Verständlichkeit sollten gewartet werden. D.h. sie sollten proaktiv in angemessenen Wartungsinverallen aufgesucht und dem aktuellen Verständnisstand angepasst werden. Sonst besteht die Gefahr, dass sie zur Unzeit als stark erodiert erfahren werden und viel Mühe beim Verständnis machen.\n",
    "\n",
    "Die obigen Fragen zu möglichen Integrationen sind daher nur Beispiele dafür, dass und wie möglichen Verständlichkeitsverbesserungen nachgespürt werden kann. Nach angemessenem Diskurs muss eine Entscheidung getroffen werden. Die könnte z.B. so aussehen:\n",
    "\n",
    "/// hierarchischer datenfluss für wortzählung (2 dimensionen einzeichnen: verhaltensproduktion, komposition) (17)\n",
    "\n",
    "Ein Datenflussmodell dehnt sich damit sichtbar in 2 Dimensionen aus:\n",
    "\n",
    "* In der ersten Dimension wird Verhalten im Datenfluss erzeugt: am Anfang einfließerder Input wird schrittweise in am Ende ausfließenden Output transformiert.\n",
    "* In der zweiten Dimension findet Abstraktion durch Komposition statt. Kompositionen - Operation wie Integration - fassen verschiedene Teilverhalten zu einem größeren, neuen Gesamtverhalten zusammen. Komposition ist die Abstraktion, die Bequemlichkeit in der Nutzung herstellt.\n",
    "\n",
    "Kompositionen ändern am Verhalten natürlich nichts. Das Verhalten wird immer nur durch Logik (und Verteilung) beeinflusst. Aber Kompositionen ändern an der Verständlichkeit etwas - hoffentlich zum Besseren. Deshalb ist auch der Einwand, dass in einer Integrationshierarchie Operationen und Integrationen womöglich nur einmal verwendet werden, unerheblich. Wenn eine Komposition der Verständlichkeit oder Testbarkeit dient, dann muss sie nicht gleichzeitig der kurzfristigen Produktivität dienen. Das wäre nämlich der Zweck von Wiederverwendung.\n",
    "\n",
    "Sind Integrationen für einen Fluss gefunden, lassen sie sich leicht übersetzen: wie Operationen werden sie zu Funktionen. Das ist einerseits sehr nützlich und intuitiv. Andererseits hat es aber auch einen Nachteil.\n",
    "\n",
    "Integrationen in Funktionen zu übersetzen, liegt nahe, weil die Darstellung im Modell sich nicht von Operationen unterscheidet. Auch weil während des Modellierungsprozesses nicht klar ist, ob Blätter in einer Integrationshierarchie Operationen bleiben oder weiter verfeinert werden, d.h. \"in Integrationen umklappen\", wäre eine unterschiedliche Darstellung bzw. Codierung hinderlich.\n",
    "\n",
    "Andererseits verführt die Übersetzung von Integrationen in Funktionen dazu, Logik in sie \"hineinzuschmuggeln\". Das würde dem IOSP widersprechen und mindestens die Testbarkeit senken. Mehr dazu unten.\n",
    "\n",
    "Letztlich überwiegt jedoch für Flow-Design die Einfachheit. Integrationen werden zu Funktionen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "../anforderungen.ipynb with 4475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../prozess.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anforderung-logik-lücke.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../index.ipynb with 125 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/entwurf_1.ipynb with 4714 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../entwurf/.ipynb_checkpoints/entwurf_1-checkpoint.ipynb with 4699 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/arbeitsorganisation.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../codierung/.ipynb_checkpoints/arbeitsorganisation-checkpoint.ipynb with 37 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/slicing.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../analyse/.ipynb_checkpoints/slicing-checkpoint.ipynb with 49 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/radikale_oo.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/ioda.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/dimensionen.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/radikale_oo-checkpoint.ipynb with 3736 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/dimensionen-checkpoint.ipynb with 2475 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../anatomie/.ipynb_checkpoints/ioda-checkpoint.ipynb with 3216 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_1-checkpoint.ipynb with 3734 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderung-logik-lücke-checkpoint.ipynb with 3276 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_3-checkpoint.ipynb with 3372 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/prozess-checkpoint.ipynb with 1827 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/index-checkpoint.ipynb with 115 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anatomie_2-checkpoint.ipynb with 2549 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "../.ipynb_checkpoints/anforderungen-checkpoint.ipynb with 4473 words"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "void CountWordsInFiles(string path, string pattern) {\n",
    "    CountWordsInFiles(path, pattern,\n",
    "        Print);\n",
    "}\n",
    "\n",
    "void CountWordsInFiles(string path, string pattern, Action<string,int> onFile) {\n",
    "    EnumerateRelevantFiles(path, pattern,\n",
    "        filename => {\n",
    "            var words = LoadWordsFromFile(filename);\n",
    "            onFile(filename, words.Length);\n",
    "        });\n",
    "}\n",
    "\n",
    "void EnumerateRelevantFiles(string path, string pattern, Action<string> onFilename) {\n",
    "    EnumerateFiles(\"..\",\n",
    "        filename => FilterByEndOfFilename(filename, \".ipynb\",\n",
    "                      onFilename));\n",
    "}\n",
    "\n",
    "string[] LoadWordsFromFile(string filename) {\n",
    "    var text = Load(filename);\n",
    "    return SplitIntoWords(text);\n",
    "}\n",
    "\n",
    "\n",
    "CountWordsInFiles(\"..\", \".ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dass in diesem Beispiel Funktionseinheiten/Funktionen mit demselben Namen auf zwei Ebenen existieren - `CountWordsInFiles` - ist beabsichtigt. Es passiert ja grundsätzlich dasselbe, nur eben auf unterschiedlichen Abstraktionsebenen. Warum sollte also die Benennung nicht dieselbe sein. Eine Verwechslung ist ausgeschlossen durch die unterschiedlichen Parameter: mehr Parameter deuten auf mehr Details bzw. größere Konkrethei hin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Jo-Jo-Komposition\n",
    "\n",
    "\n",
    "#### Dark Logic\n",
    "logik in der integration?\n",
    "\n",
    "#### Stratified Design\n",
    "\n",
    "#### Offen für Erweiterung, geschlossen für Veränderung\n",
    "\n",
    "logik soll nicht verändert werden?\n",
    "\n",
    "### 3-dimensionale Datenflüsse\n",
    "mehrere ein/ausgänge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "file_extension": ".cs",
   "mimetype": "text/x-csharp",
   "name": "C#",
   "pygments_lexer": "csharp",
   "version": "8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
